# Semantic Analysis on Tech Product Reviews

This repository contains the full implementation, code, data (where permitted), and LaTeX report for our NLP course project: **Sentiment and Semantic Analysis of Technology Product Reviews**, with a special focus on Apple and Samsung.

## ğŸ” Project Overview

We performed multi-class sentiment classification (positive, neutral, negative) on real-world product reviews from the Amazon 5-core Electronics dataset. Our work includes:

- Preprocessing and cleaning ~17,000 reviews
- Fine-tuning transformer models (e.g., RoBERTa, XLNet, DeBERTa)
- Deep learning with RNN variants (LSTM, GRU, BiLSTM + Attention)
- FastText baseline
- Classical ML models
- Topic modeling with LDA, LSA, NMF, and BERTopic

We also compared our current work with a previous sentiment analysis task we conducted on manually labeled Reddit comments related to the 2024 U.S. Election.

## ğŸ“ Directory Structure

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ transformers/
â”‚   â”œâ”€â”€ deep_learning/
â”‚   â”œâ”€â”€ classical_ml/
â”‚   â”œâ”€â”€ topic_modeling/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ semantic_tech_real.csv
â”‚   â”œâ”€â”€ semantic_tech_10k.csv
â”‚   â””â”€â”€ reddit_us_election.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_transformer_checkpoints/
â”‚   â”œâ”€â”€ fasttext.bin
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ NLP_project.pdf
â”‚   â””â”€â”€ presentation_slides/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ cluster_logs/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ“Š Results

### ğŸ“ˆ Transformer Performance (Tech Dataset)

| Model              | Accuracy | F1-score |
|-------------------|----------|----------|
| CardiffNLP        | 75.98%   | 75.46%   |
| DeBERTa-v3-large  | 75.26%   | 75.32%   |
| RoBERTa           | 72.60%   | 72.23%   |

### ğŸ” Deep Learning

| Model                        | Accuracy | F1-score |
|-----------------------------|----------|----------|
| BiLSTM + Attention + GloVe  | 70.00%   | 66.00%   |
| GRU + GloVe                 | 70.84%   | 70.99%   |

### âš¡ FastText Baseline

- Accuracy: 66.15%
- Macro F1: 62.63%

### ğŸ“š Topic Modeling (Example from LDA)

| Topic | Top Keywords |
|-------|--------------|
| 1     | cable, usb, adapter, sound, iphone |
| 2     | laptop, lenovo, windows, mouse, computer |
| ...   | ... |

## ğŸ§  Tools & Libraries

- HuggingFace Transformers
- TensorFlow & Keras
- Scikit-learn
- FastText (Facebook AI)
- NLTK & Gensim
- BERTopic, SVD, NMF
- Google Colab & University HPC Cluster

## ğŸ› ï¸ Reproducibility

- All notebooks are modular and self-contained.
- Pretrained models and log files are provided where possible.
- Run `requirements.txt` to install dependencies.
- Check `report/NLP_project.pdf` for methodology and results.

## ğŸ‘¥ Authors

- **Mohammadkazem Rajabi** â€“ [Email](mailto:Mohammadkazem.rajabi@unipd.studenti.it)
- **Baharehsadat Khatami** â€“ [Email](mailto:Baharehsadat.khatami@unipd.studenti.it)

Special thanks to **Amir Sadeghi** for contributing to the annotation of the Reddit dataset.

## ğŸ“„ License

This repository is for academic and research purposes only. If you use this project, please cite our report and acknowledge our work.
