{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4fdc1e25c0f045fd9134636cac80a92a",
      "d2a3afd625cd413382ecae9962d92396",
      "29ae55dbb21e4da98be102a46c5595c0",
      "89bc4308dec442208fe4ca935ac59438",
      "62fcdfdb03024fa58da3de4111144972",
      "8aa2d723212e448ea0bb6466c58820bb",
      "816d2c383e2f41b09c2eca8d5d045b18",
      "086a7ab4e9664e0d89a2aac45bddbb9b",
      "b994b77fa4ce446f984a874d570d89eb",
      "0d865dca352240248c250e9758bc3eae",
      "0a4adb1c08a24a749ea9ce5907b2a60c",
      "0d69e355ac1f40b09c9fba17644e16d5",
      "5ba62e5acf7740bb918fe3c53f05158a",
      "31b46a3d89da4dcbbe35d0f8e39cd7a1",
      "e070863a37e74767ab3a56b752fa6edc",
      "d02ead29dc964ac6b107e1756a553bb8",
      "40f4f2faeb5a48388966c3b40c209957",
      "71bd2de4bb874d118a666d4674db08e9",
      "ae5c111479014768ac983ea4ebc89cf8",
      "933d1f43336f41a1a1bedd8c565692c7",
      "a3be6b61a49c4ef5baac5929bca0fa8b",
      "fb189bcae604461a994853fe2e220f6e",
      "49534982b745430c91ecb7360638b3d4",
      "4d3e117f935c4c2f919a977a4493c239",
      "78b07530eaee41cb9bc311ff04cfc1fd",
      "2995d11ec6994b1693c978d787c43a10",
      "8c19b36c92f34772967c713bd40a4f23",
      "f1c22792c182463b9a75cafdf1a4faad",
      "706c148dd2834cd1ab7e5bd389500054",
      "0f6b6deb40494b47935f71e2d73f197c",
      "0d9aacc3649f42279a7eef1f5c1035a4",
      "ba55bf6976f745ee8af19903a3e808ae",
      "7b69a6278d7040af9af88b8a8d9beac4",
      "d8fa1f2283cf4858b4caaea308aa4bec",
      "ec385a3e64e44f688eb21439a485830b",
      "de6a204d89b349fa9201331f38a15614",
      "eab7c68ebbb942d483f2985c23eb8f05",
      "2890b767395d43b5a98827ef432b1e69",
      "f8837011fbb14035b518b7395afdcbb4",
      "86ee356daae24810807ead336803f61c",
      "5340696179da4de9ac57914a43068ce8",
      "406e466c06794f24ae1069b95719fefa",
      "1d7e2626a22845dd96d0cc93f7676b81",
      "3653062fa8dc4535aa77aad10637e205",
      "ff7769fe3b4d4f16bc63677f47ae8361",
      "cec857744d9f439396fdf8495cbad384",
      "e255549017774041aec4a81f28f21d7c",
      "bbe3f7f407f94c7590c7445dbf3a4ff4",
      "95987a3a7a404c01964c7ee19ff30602",
      "604881dcc3584cafb0ac2fb300259331",
      "97dd8e07f21b4d0089f5f2cdd6244889",
      "2a9372e4a03043ddab3d626183361076",
      "a52547a506e248ef9a3d7ce5e6bd52e8",
      "560c7d59d8bf4bb98da16529deb852a1",
      "8298605804f14562aaf64373f4cfc201",
      "b76e5f2e862e4f5d9ea47abbb6fad3b5",
      "3300b363073341e1bae3f54fe2db01df",
      "bb63ae7e8cd04b789034cc736da9123e",
      "f325b19c7dbb4bdfbf69601e6073371f",
      "9000b40864bb4cdf816305b37d335565",
      "17b7516ef67a4e09a99906d678c2618c",
      "537a5960933d4a7c9b7587aaf1343daf",
      "af4ba55fda8b48abaf1eeee4ff6d801b",
      "c7dc93e5cc3743e784b9049f87c4108b",
      "efe35122927f4c55a51ddcf26730593a",
      "67700de74d3e42c886c91754f29d36f4",
      "3b80acf8af8043dc8045f40082d6a589",
      "baa3c4a744494a91936e678e518c053d",
      "8004b78050c545f8ade418bcab880e6a",
      "09ab59fba3b94f1196d624add205b49a",
      "dec706c45202433db1e7b44a969a352e",
      "56796d63dffe49a1a1b19531aeaef4ea",
      "7c1a8ddb169c429287c14cc01d9aca4e",
      "ac9e0412d24147e291f7aa60d8885b56",
      "8fc5ee4406cc4ac882da9813e3e1b176",
      "6a01a0b1afbb489ea5ea3478e9808ece",
      "f5ef6cbd9ef94d69b7573e8f3050d851"
     ]
    },
    "id": "y2xdItCNFxxM",
    "outputId": "4282c9c0-f844-4c29-b1c0-8a563f91983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "📥 Loading 'yelp_review_full' dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdc1e25c0f045fd9134636cac80a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d69e355ac1f40b09c9fba17644e16d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49534982b745430c91ecb7360638b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fa1f2283cf4858b4caaea308aa4bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7769fe3b4d4f16bc63677f47ae8361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76e5f2e862e4f5d9ea47abbb6fad3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b80acf8af8043dc8045f40082d6a589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12559 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final dataset shape: (12559, 4)\n",
      "💾 Saved as 'apple_samsung_yelp_sentiment.csv'\n",
      "\n",
      "📊 Sentiment distribution:\n",
      "sentiment\n",
      "-1    6171\n",
      " 1    3835\n",
      " 0    2553\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📌 Brand distribution:\n",
      "brand\n",
      "samsung    8191\n",
      "apple      3150\n",
      "general    1218\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install HuggingFace datasets\n",
    "!pip install datasets\n",
    "\n",
    "# STEP 2: Import libraries\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"📥 Loading 'yelp_review_full' dataset...\")\n",
    "dataset = load_dataset(\"yelp_review_full\", split=\"train[:50000]\")  # Adjust size if needed\n",
    "\n",
    "# STEP 3: Define Apple & Samsung keywords\n",
    "apple_keywords = [\n",
    "    \"apple\", \"iphone\", \"ipad\", \"macbook\", \"mac\", \"airpods\", \"apple watch\", \"ios\"\n",
    "]\n",
    "samsung_keywords = [\n",
    "    \"samsung\", \"galaxy\", \"note\", \"s22\", \"s21\", \"tab\", \"buds\", \"samsung watch\", \"android\"\n",
    "]\n",
    "product_keywords = [\n",
    "    \"smartphone\", \"tablet\", \"laptop\", \"phone\", \"headphones\", \"wearable\"\n",
    "]\n",
    "\n",
    "all_keywords = set(apple_keywords + samsung_keywords + product_keywords)\n",
    "all_keywords = [k.lower() for k in all_keywords]\n",
    "\n",
    "# STEP 4: Filter for relevant reviews\n",
    "def is_tech_related(example):\n",
    "    text = example[\"text\"].lower()\n",
    "    return any(keyword in text for keyword in all_keywords)\n",
    "\n",
    "filtered = dataset.filter(is_tech_related)\n",
    "\n",
    "# STEP 5: Tag each review with brand\n",
    "def tag_brand(example):\n",
    "    text = example[\"text\"].lower()\n",
    "    if any(word in text for word in apple_keywords):\n",
    "        return \"apple\"\n",
    "    elif any(word in text for word in samsung_keywords):\n",
    "        return \"samsung\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "filtered = filtered.map(lambda x: {\"brand\": tag_brand(x)})\n",
    "\n",
    "# STEP 6: Convert to DataFrame\n",
    "df = pd.DataFrame(filtered)\n",
    "\n",
    "# STEP 7: Map star ratings (0–4) to sentiment\n",
    "# In yelp_review_full: 0=1 star, 1=2 stars, ..., 4=5 stars\n",
    "def map_star_to_sentiment(label):\n",
    "    if label in [0, 1]:\n",
    "        return -1\n",
    "    elif label == 2:\n",
    "        return 0\n",
    "    elif label in [3, 4]:\n",
    "        return 1\n",
    "\n",
    "df[\"sentiment\"] = df[\"label\"].apply(map_star_to_sentiment)\n",
    "\n",
    "# Optional: Keep only relevant columns\n",
    "df = df[[\"text\", \"label\", \"brand\", \"sentiment\"]]\n",
    "df = df.rename(columns={\"text\": \"review_text\", \"label\": \"star_rating\"})\n",
    "\n",
    "# STEP 8: Save to CSV\n",
    "df.to_csv(\"apple_samsung_yelp_sentiment.csv\", index=False)\n",
    "print(f\"\\n✅ Final dataset shape: {df.shape}\")\n",
    "print(\"💾 Saved as 'apple_samsung_yelp_sentiment.csv'\")\n",
    "print(\"\\n📊 Sentiment distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "print(\"\\n📌 Brand distribution:\")\n",
    "print(df[\"brand\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jF_TPUEeKuZ",
    "outputId": "2d790df1-8e1a-4cc1-89ee-7d4784626c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM3kqvBveyKW"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"apple_samsung_yelp_sentiment.csv\", engine=\"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tlxSawNqe20v",
    "outputId": "975f9488-b6a4-448b-d459-84c96729ca53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧭 Sentiment Class Distribution:\n",
      "sentiment\n",
      "-1.0    2704\n",
      " 1.0    1691\n",
      " 0.0    1174\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Brand Distribution:\n",
      "brand\n",
      "samsung    3694\n",
      "apple      1357\n",
      "general     518\n",
      "sam           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Average words per review by sentiment:\n",
      "sentiment\n",
      "-1.0    223.492973\n",
      " 0.0    194.685690\n",
      " 1.0    177.657008\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "🔍 Example (Negative):\n",
      "Brand: general\n",
      "Review: Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\n",
      "\n",
      "🔍 Example (Neutral):\n",
      "Brand: samsung\n",
      "Review: OK, what is with all of these \\\"CASH ONLY\\\" places in Pittsburgh? I can appreciate that some smaller businesses might have trouble installing a credit card system in their store/resturant, but could you perhaps provide an ATM?  In the past, this would deter me from eating at this place. \\n\\nLooking at a standard breakfast menu, I decided to go with a tuna melt instead. What I got was a cold tuna salad sandwich with a slice of cheese on toast. I had ordered a melt being in the mood for a warm meal, but to no avail. One day later I can't even remember what my side was. I suppose it didn't leave much of an impression on me.  I have to say that the dessert was really good! The cherry pecan pie! I have not seen this concoction anywhere else but this was awesome! The cherries were not the sweet canned variety, but a pie worthy tart topped with sugar. I think I want to make this pie with my parents next harvest of our cherry tree!\\n\\nMy first impression is \\\"Eh.\\\"  I am learning how crazy Pittsburghers are over breakfast! Seriously, waiting 30 minutes for a table at a tiny diner with a menu that reads as follows:  \\n\\n\\\"2 eggs and toast $x.xx\\\"\\n\\\"2 eggs, meat, and toast $x.xx\\\"\\n\\\"2 eggs and pancake $x.xx\\\"\\n\\nI'd rather go to a Denny's and order the \\\"create your own Grand Slam!\\\"\n",
      "\n",
      "🔍 Example (Positive):\n",
      "Brand: samsung\n",
      "Review: This place should have a lot more reviews - but I'm glad it doesn't, they don't need to get any busier.\\n\\nIts been there ages, and looks it. If you're all about ambiance, don't bother. If you pretend you're in a movie set in Pittsburgh 30 years ago it works pretty well. The service is sometimes hit or miss. Most of girls are good, one is very slow, one is amazing. They are all friendly and usually a few different people will check in to make sure that you're happy. Everything is made fresh so be prepared that nothing comes flying out of that kitchen - busy times it can take a good while to get food. \\n\\nThe food is AWESOME! Worth any little complaints I might think up before it gets there. Once its on the table, I forget them all.\\n\\n-Fish Sandwiich\\n-Salmon (huge and delicious)\\n-Flounder\\n-Shrimp a few ways (\\\"Norfolk\\\" style is oily for my taste, and I never had it growing up in Norfolk.)\\n-Hawkins St Special\\n-Prime Rib (sized for two, watch it)\\n\\nThe prices are low, the portions are large, and just about everything on the menu  is delicious. I'm not one to pick a place because they give you a lot of food, but if you like a good value and don't want to compromise on taste, this place is a gem.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"apple_samsung_yelp_sentiment.csv\")\n",
    "\n",
    "# Word count per review\n",
    "df[\"word_count\"] = df[\"review_text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# 1. Sentiment Distribution\n",
    "print(\"\\n🧭 Sentiment Class Distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "sns.countplot(x=\"sentiment\", data=df)\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment (-1 = Negative, 0 = Neutral, 1 = Positive)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Brand Distribution\n",
    "print(\"\\n📌 Brand Distribution:\")\n",
    "print(df[\"brand\"].value_counts())\n",
    "\n",
    "sns.countplot(x=\"brand\", data=df)\n",
    "plt.title(\"Brand Distribution\")\n",
    "plt.xlabel(\"Brand Mentioned\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Word count analysis\n",
    "sns.histplot(data=df, x=\"word_count\", bins=40, kde=True)\n",
    "plt.title(\"Word Count per Review\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Word count by sentiment\n",
    "sns.boxplot(x=\"sentiment\", y=\"word_count\", data=df)\n",
    "plt.title(\"Review Length by Sentiment\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Word Count\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Average words per sentiment\n",
    "print(\"\\n📝 Average words per review by sentiment:\")\n",
    "print(df.groupby(\"sentiment\")[\"word_count\"].mean())\n",
    "\n",
    "# 6. Example reviews per sentiment class\n",
    "for sentiment in [-1, 0, 1]:\n",
    "    sample = df[df[\"sentiment\"] == sentiment].iloc[0]\n",
    "    print(f\"\\n🔍 Example ({'Negative' if sentiment == -1 else 'Neutral' if sentiment == 0 else 'Positive'}):\")\n",
    "    print(f\"Brand: {sample['brand']}\")\n",
    "    print(\"Review:\", sample['review_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "RTX74KtIfADp",
    "outputId": "74ec6208-c276-4008-9ee8-de8f5dbf90f3"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Expected 8 fields in line 3, saw 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-12e5cb004fd5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"apple_samsung_yelp_sentiment.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0malldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rows_to_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exclude_implicit_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_rows_to_cols\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\". \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alert_malformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;31m# see gh-13320\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_alert_malformed\u001b[0;34m(self, msg, row_num)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \"\"\"\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_bad_lines\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadLineHandleMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_bad_lines\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadLineHandleMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             warnings.warn(\n",
      "\u001b[0;31mParserError\u001b[0m: Expected 8 fields in line 3, saw 9"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "df = pd.read_csv(\"apple_samsung_yelp_sentiment.csv\", quoting=csv.QUOTE_NONE, engine=\"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6oSdRnMkAZm",
    "outputId": "e22efc95-8764-4a44-bd2d-91b35f192ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review_text', 'star_rating', 'brand', 'sentiment'], dtype='object')\n",
      "                                         review_text  star_rating    brand  \\\n",
      "0  Unfortunately, the frustration of being Dr. Go...            1  general   \n",
      "1  I don't know what Dr. Goldberg was like before...            0    apple   \n",
      "2  Owning a driving range inside the city limits ...            0    apple   \n",
      "\n",
      "   sentiment  \n",
      "0         -1  \n",
      "1         -1  \n",
      "2         -1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"apple_samsung_yelp_sentiment.csv\", on_bad_lines='skip', engine=\"python\")\n",
    "print(df.columns)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1zSL053kmlW",
    "outputId": "50275b86-d34b-4b7a-9584-26886cbd840f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()                             # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)                # remove non-letters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()             # remove extra whitespace\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]    # remove stop words\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['cleaned_text'] = df['review_text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gy0tR5Tmluji"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0cI6Mbwl_q_"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7d7b6b59f8884605acdd3c1189709dd3",
      "06f6b4b0657d444182045958a2af0932",
      "165995611b5d46ea962171c72c05f70d",
      "fe71a89815b642708c146ddb4f29cedb",
      "9af4bfc93062421a9d7ee53abda24eab",
      "223a6132591d46c7a064b51c7994ff2c",
      "477a132aeea04865b7bbe4200eb79de8",
      "1e717116caca4806903b6b37c5325946",
      "6d3ab53a0fe240c5bb3366596f71f915",
      "1ad29916cc1c40e8a0a422101ffa11eb",
      "18bead9436d0435793fc7ba13b1fa8fe",
      "5ca4685e5c1149ad916673290cc5dcd9",
      "1278358323db4b6f8658497e3da26179",
      "49c2cfbb2e6e4d6388dc493837f4abfd",
      "7370465403e44f23b541880984e3b485",
      "dd85d52012cb435abe4c5ca44367f920",
      "289660a670984924b64f0a143f13b471",
      "e00a0eac109b409fad5cd265e97f0b3f",
      "0856599ed77a48cba7b4e58e624e4a53",
      "581370ead3444d858c6fa58a40cae67f",
      "304853770c084cd3bb79464fbf09e090",
      "cc6b549f8c36441ba33fd231559a6719",
      "f3dc2a988709458dabee45223bccbc1f",
      "3a5eb3be374e45ff922ae186d03d39c3",
      "8abebd8be1e94433af72b5176409e343",
      "46f2278ccf2e48d88fb9de0f27aa008b",
      "88e4a69a0e5c453b818e30ba795982ba",
      "edff73966c68489f9d023c45bee6129b",
      "19b2908181444f49a47accfd76a609c8",
      "b2e0c70216ac4ee5807436c3d91f9d57",
      "698fee70d6d246e3990aaaa323099ada",
      "b89efc62b2a34c3f98a6abd97a2908d2",
      "6a8f38ab78d346a4b0ccf912984ad383",
      "c241265e66724e3087581de5ecab5614",
      "bc6c7074c67a4ca6be9c1188ab797b7d",
      "a982ed14fbb44fc5a5b8ae87da9342e3",
      "442668125c404fe48d0019020bc0fd7a",
      "29b3d9d0b72f431fac13f13759443fa8",
      "6590b8ba7972411cb16c9131d6655eb4",
      "4f53c0ca6250464cb6f34a10fa3ad81c",
      "89341ebd4b2b431bbf3caa9383a055c4",
      "6885647d56e84016acaaae7dc60d395b",
      "e2e85def41394355a8681e18f7c162e3",
      "666fb9116e214fd4a1eb948f2484ba94",
      "5f6381d5b68c44e995e7ff23c658d87c",
      "2a46ebe50bbf4c85b15e590816a1c790",
      "a8fd570f1d8340c79bad8675eb1791aa",
      "4ac22fe01f6745b2821795aa8560caf2",
      "67d9624588084866aea924801692a74e",
      "6980d3bb938a45bd980f810044817e65",
      "a223dd0b91d8436bb2296c5354ba910f",
      "d7699c61b053472bb451bb7220be53ac",
      "a0adee10401c43d59c4c6c3fe08cb756",
      "2305b04110e24bc6b4797f7f256cb8c5",
      "62b1b3ccee894924bcbb199f8034bd12",
      "dbda9ca7759345f595fb269001a124b6",
      "91970c650a7846cb96dc7dbfd83a2e87",
      "da9491c002914cffb793ca963a10f13c",
      "40fb6ffb3f4845ec86c61dc671b7c1af",
      "111189905d2c4db79cd1afb308820fd0",
      "a797d794478343908a8deb6b6b7e4bea",
      "f8cbe34d7299441d809451197ed38d24",
      "097ebe46ef7e4a439c4887fae4174171",
      "44071e102e01405ca716bf3bb1e0531d",
      "7d67c8b989fb4cc0a85ed8f0415667a8",
      "04d02fddf2734674a70215727ed5dba1",
      "e3757cce67f7469ca51135be5a7905cc",
      "ace5798f3cd0406bbe87a7fe2603cbd2",
      "a707626ce20343dd8ffd1d6a6ff4a4ad",
      "c0eae78faeaf442b9e70ac5c6498a243",
      "ff313bae66d640a895c45778664d2abc",
      "366318c5294640728ac9e372fc082c3c",
      "68346b02e6db458d8d0dd1ea931112bb",
      "5a2863e0f10e480db9dbc26c36973f14",
      "93a0582115724cc38f71c46931591172",
      "7ba1d7a9d62644fe862746b43da7a9e9",
      "fb413089c60a4a1d9c9aae95d03fe5bd",
      "5bb93787b4404b69b272dd324b3c9b65",
      "9aa3960b0b3c4ef98912c170f01e6100",
      "e470b5e325534ef08cdd9adf8c5db7c2",
      "192b22666bb94c8494d3eca1484cc6e7",
      "ad229e25b4954942a7954c591e972818",
      "d8e0552c66764b1d99788340ac20b2cb",
      "f8f2a20ba816415d9b0b083a30eb5a7c",
      "82082649029b42b59fa8bf667a1a606b",
      "97502f39c1864cbe8d611750f7b51826",
      "62f3a4f6f04b4d6a97b38457346b8e01",
      "d65eacb974cb44e9897bb9c900f2bc63"
     ]
    },
    "id": "qy1Yqknglfum",
    "outputId": "8f27233e-a353-4443-b3db-f059207bbfea"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7b6b59f8884605acdd3c1189709dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca4685e5c1149ad916673290cc5dcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dc2a988709458dabee45223bccbc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c241265e66724e3087581de5ecab5614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6381d5b68c44e995e7ff23c658d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda9ca7759345f595fb269001a124b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3757cce67f7469ca51135be5a7905cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb93787b4404b69b272dd324b3c9b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:46<00:00,  5.33it/s, loss=0.476]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.40it/s, loss=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.41it/s, loss=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.41it/s, loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.40it/s, loss=0.366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:45<00:00,  5.39it/s, loss=0.00595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:45<00:00,  5.38it/s, loss=0.00203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.40it/s, loss=0.00119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.40it/s, loss=0.00708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.39it/s, loss=0.00171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.39it/s, loss=0.000846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [01:44<00:00,  5.41it/s, loss=0.000412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: {'accuracy': 0.7174129353233831, 'precision': 0.7183719843934986, 'recall': 0.7174129353233831, 'f1': 0.7176456397091261}\n",
      "Test: {'accuracy': 0.7153662420382165, 'precision': 0.730757283903042, 'recall': 0.7153662420382165, 'f1': 0.7209264839608907}\n"
     ]
    }
   ],
   "source": [
    "# 📦 All-in-One Cell: DistilBERT Fine-Tuning on Apple/Samsung Yelp Sentiment Dataset\n",
    "\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ⚙️ Device config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 🚀 Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")  # <-- adjust path if needed\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# ✂️ Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df[\"label\"])\n",
    "\n",
    "# 🤗 Hugging Face Dataset\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 🔧 Model & DataLoader\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3).to(device)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 🎯 Train loop\n",
    "for epoch in range(12):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        out.loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=out.loss.item())\n",
    "\n",
    "# 📊 Eval function\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = {k: v.to(device) for k, v in b.items()}\n",
    "            o = model(**b)\n",
    "            pred = torch.argmax(o.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += b[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "# ✅ Run evaluation\n",
    "print(\"\\nValidation:\", evaluate(val_loader))\n",
    "print(\"Test:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUThJdcAcpjW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmM7rdPFr3y_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771,
     "referenced_widgets": [
      "e72a2b98becb48cebecb599a0982c227",
      "7f7b971df5374e22bb102c9e3790531c",
      "b3a8545c10ac4ce79bb61a7dc62827fa",
      "2c43b86391c546dea41b9ba2402c55db",
      "c293aec33de74d1d87bcd0806846ebab",
      "7c17e1b82fb14cbba568e888085c3f12",
      "c8126573bfca4c9f983fcca0a1a9bf0a",
      "fda9d49a39b44225af02a82c5b038d42",
      "f1f5927d9a804030b4931aed98a585e0",
      "e55e7e25d7744507856f15da85d40d3d",
      "94e840ac8c5942ddad90d630344dba89",
      "b15a65524bb8488a8fb58d16401ec13b",
      "97c80e9d10b2476d9f8d06e4d9a2bdc2",
      "f653bb9ab25d4de1aa056cae5f929c4c",
      "8937800f530147ce92c6441dc1b8d770",
      "97e065738d9b4aa0838b63f912dd0a3e",
      "a25c19f7c1ef4758b50fa9964ac3c5ed",
      "a3729af5453346fe9f8c397af5cef5bb",
      "530d175585624ac195777a91882484b7",
      "3b98e674b5aa4605839609d3b1f51dfa",
      "8927ba863863471aa586238ad56a6279",
      "ece0e92b1616430d8f19e2d8996980c1",
      "2db74a107d74411e951e33da7cadf7a1",
      "e913af1e196c4821b063331d5f62c729",
      "8b1e8fa04679457fa2c1ae904e4a07e0",
      "60f5671cfa90491da2302339f2f7f83c",
      "9b962e75e01f4ce7bd81955eff9202d3",
      "38745939b31e4acfbcd150c8235ebfc8",
      "98e63e121e37493dbaa22c086810d769",
      "a55389ea2f7b410dac3ca378908ed05f",
      "7450f93748e94a3a8545b29ecaedecb7",
      "6d558d740ff24252a46e3876b7720439",
      "b2bfd186b185490e889efcdcdca9e657",
      "36aa1d4c27e8435b97f46e567a3bbc70",
      "e54486f474924792a7e5fa76510b6184",
      "5c2db23742984e4681f936873c65d476",
      "e867478b3252482baab06d103a99c60f",
      "54d31f7b5bdd422aa10996b34da6eeaf",
      "30af178e73b3425787aa0f73fe9fdd99",
      "fdcb959f13374e07a741f4c51c50865b",
      "d297220bf2d349ada2377bb7e230e2f0",
      "269daa11220640df9b6a31d23d5d3247",
      "c3f31bc2029b4d90bf6d9b13afb09396",
      "6ea4529046d44d13a11cb70c368d48a9",
      "76ccbf2ce6ac4af7acf5038809e626bc",
      "4bd64c2ad20e4b76a66c3e8afd148371",
      "59e2e5b952d343539a4156cc3766f6e8",
      "4c3e6517f16940c1bf53cfed14b82403",
      "3ba57ab09e944534a02f5a7f8bbe7810",
      "ffdc987d2a234a04b52406cb378452f4",
      "a4e0b695664b460ea04b0c7c0d0be0fe",
      "6c2aeebb67594c5fa3cdb8fad6ebb2ab",
      "40eafbcf05b1485892e54450235d9466",
      "f1c9b839de0e421cacf2dbcb84be9e11",
      "d56631b2490f43ccb3dc723dfe181bcf",
      "311971685ce2414bb887c3d987f0963c",
      "66faf108f9844df28a97042a126c7f70",
      "edef6657946f46ffb4d62ca20c01597e",
      "80e550a69b25412baf8e8828bcf06244",
      "c422842e8e50467b921c3c381ffd373a",
      "898dede343e6421796e22049caca3d4d",
      "68636c5714254c39b7f5cab187c94681",
      "a38112d824a7402ca5e03c4db91cc6dc",
      "fb85dd93230e402bbad66e566a01136c",
      "32afd710744b4a54916336a9930af221",
      "ca97182fd8544e77b2440ff5bc1df7cf",
      "9bc3206d23cf489881d9347ab9d60c5d",
      "51a8028931f34ce19ee35f20c364a0a3",
      "6fc13627a21644f6aca36f69fa6097c8",
      "d2e4a016e79e4630ac169f6b862d7aec",
      "751dcb17f35d4296a2ade0479eecf258",
      "1af2abdcd40340298070133512bb457e",
      "0a28c907a03a459088d32d5470eef99e",
      "6400f99af81d4debbb83e6a7927d0f41",
      "d01e56a9972e4ba3a68176f85c4057e7",
      "566ba0331ac044099812354a9cbb7d8f",
      "84741b97a54d4cc7801c5d43768d11c7",
      "124f1b856bc64f50ad33d7c9ddfa8c72",
      "2180db4fb24e4e9581fc0120188ef824",
      "527d435f069445afb88d32227d98e60a",
      "1214a83b9f2547aa9333973015db3d11",
      "dadc3d0239564d0bb236028dab7853d0",
      "634c5c3ce50041a5a25f337c6a76fa6f",
      "380716bd80224c509b299e69208d13af",
      "a5872699019447349ba918178ff963d3",
      "53f6038148a741db909d870a0ca31418",
      "583ce4be2f5f4a26aabb92b683bbca37",
      "b4575f46a9da42f4ae34f6a651be8c44",
      "7e60c896253044bf9a69b6f15775b5ee",
      "89eb8936fbfb4754912a192c049ce194",
      "bb9917cc56184af08967df535c7c92f1",
      "90ada312cad24af489d69ff7ff0d580b",
      "a63afcb01c8b4f61aac16facc4a8f1a5",
      "359743b316dc4d57a539b76769ecbe60",
      "fd22d305216e432b8d4f51fde7d94478",
      "c7ed45bb76534dcebf0b1c5415a7b948",
      "9832a2d79a4440a689531cf72a5241ca",
      "0e8759182f154d0e81a6b2a742b785a6",
      "9aab3be366e14f61beb37a662c2680a7"
     ]
    },
    "id": "7To3Z52qn0_S",
    "outputId": "f3cb335c-8d33-497b-9060-f8ff311a24d4"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "CUDA available: True\n",
      "Device name: Tesla T4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72a2b98becb48cebecb599a0982c227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15a65524bb8488a8fb58d16401ec13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db74a107d74411e951e33da7cadf7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36aa1d4c27e8435b97f46e567a3bbc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ccbf2ce6ac4af7acf5038809e626bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311971685ce2414bb887c3d987f0963c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc3206d23cf489881d9347ab9d60c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124f1b856bc64f50ad33d7c9ddfa8c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e60c896253044bf9a69b6f15775b5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 566/566 [03:32<00:00,  2.66it/s, loss=0.0971]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 566/566 [03:31<00:00,  2.68it/s, loss=1.31]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 566/566 [03:31<00:00,  2.67it/s, loss=0.00978]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 566/566 [03:31<00:00,  2.67it/s, loss=0.0414]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 566/566 [03:31<00:00,  2.67it/s, loss=0.224]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 566/566 [03:31<00:00,  2.68it/s, loss=0.00778]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 566/566 [03:31<00:00,  2.68it/s, loss=2.85]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 566/566 [03:31<00:00,  2.67it/s, loss=0.00716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'accuracy': 0.727363184079602, 'precision': 0.738492953594758, 'recall': 0.727363184079602, 'f1': 0.7314656760123917}\n",
      "Test Results: {'accuracy': 0.7503980891719745, 'precision': 0.765173001059298, 'recall': 0.7503980891719745, 'f1': 0.756605194764293}\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa Fine-Tuning: Apple/Samsung Yelp Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Debugging Mode\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "# CUDA Check\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load Yelp Dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "# Clean text\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Split into train/val/test\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "def prepare_hf_dataset(data):\n",
    "    return Dataset.from_pandas(data[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_dataset = prepare_hf_dataset(train_data)\n",
    "val_dataset = prepare_hf_dataset(val_data)\n",
    "test_dataset = prepare_hf_dataset(test_data)\n",
    "\n",
    "# Tokenizer and tokenization\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Prepare for PyTorch\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(device)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 8\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "def evaluate(loader):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "val_results = evaluate(val_loader)\n",
    "test_results = evaluate(test_loader)\n",
    "\n",
    "print(\"Validation Results:\", val_results)\n",
    "print(\"Test Results:\", test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771,
     "referenced_widgets": [
      "31a0a274088546e59cd0a34dd302e8b5",
      "9e3d6f3e58b2488a938ecec6cbce75f4",
      "8d7f3b90be434bd8ba1152df9c813f16",
      "c7cf71f3de604e2fa8c7ae8b147bf212",
      "b54724cb8dcb44d6b7d1016bbc4d9fc8",
      "0ef9aeac5e9a4e25ba3ee9f3a730ba92",
      "62874b27f8cf42e394f5b7daa6707281",
      "aedc0a4aed614c4d8e25c4a4befc3e76",
      "95b77d107da04923b6729a022dc3d3a7",
      "3764b513e1314fc9af3827e58df01c69",
      "1a5eedeb848842f39d5cb8864746558a",
      "27cc4a358320439f91abe2056594ba6c",
      "12c2e1ee80024b18971467430c4e78a8",
      "915985cf13b34319a0c396c0a0335bf4",
      "b5f3158e08b24f81827cfb8a59d21639",
      "a0291040d5944cdb8663e1f283597e6c",
      "a16b5e0d223b4ddea84be3746eb2bf9b",
      "90f88a2f6a3349e5884e58f892d7ef43",
      "5f27c53e21c74106995b9191ab26b581",
      "46bc216151574e4e864e2ac7349a2a08",
      "6ba767420ae046da8cfbfa365915e9ee",
      "b77fe200b8104998a7ae406b51ff513f",
      "00f8e519faaa46758c222049733e889e",
      "feff6f25b88e43aeab366248f83ec88d",
      "170a2ccc6c27413eb663bdaf90224f3f",
      "b3114382dbd24e3e805dedd50b5c57fa",
      "0dce8b47347b4b96bad65defdc168fa6",
      "eab50d807b6b422992152941769e3f76",
      "9f543a6d15754070a31c3e02e5474e79",
      "98ab361629244fce95692ecb73aa2616",
      "7723d5af2867482d9ae1e83b497abf6d",
      "68131548fe09461d9364e9f5714b69bc",
      "7fcdb69c419e414b984e7b3a04e64b2d",
      "e943cb4553af4ca4a119d7e38d711b9b",
      "c46a600a6447486cab4b126b80990c8a",
      "b2faf61ca54b494bb13ad592f1277ff1",
      "d0d0bba6913d4930abb12b7da87e58d2",
      "2d7e5bbc53704fe48e245c8b357cc263",
      "f0fb7e46fe36466aa00b704945ea79de",
      "50ba01f1e18147d1b85f6289a979482c",
      "0a35432d8f6e4287a5c52726e7b90777",
      "d73759e7445b444f9b98154219155caa",
      "bbd8afc2a24543f4bf2f3ae8532a83e1",
      "f436c1016d714186a1064fd5a00cea24",
      "df796245d4fc4e12b7f5452b5346c554",
      "57ceefeea13f4665ac59ade633a87613",
      "2549fff6fd38418e9d435612f0021e02",
      "5fc0b83649a94a5cb5188b12f3f2ca47",
      "9523134020854ade8894e3da3870a247",
      "6b6da16236734c5b929ef3b2757d3392",
      "1853bd05b92a49abbce4adedb975479e",
      "6a47500f60ed456cba7a20bec9952ec3",
      "62de1edb1f4048b3aeec3fd784d7ac73",
      "7ad3749a77ee47e6a54a1b93eb59af72",
      "0a1e9df31bba4e3d913045505faacfda"
     ]
    },
    "id": "-OwDf6uNr5LT",
    "outputId": "d9c4660f-87e5-4adc-b055-89a419e44da1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: Tesla T4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a0a274088546e59cd0a34dd302e8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cc4a358320439f91abe2056594ba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f8e519faaa46758c222049733e889e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e943cb4553af4ca4a119d7e38d711b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/566 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df796245d4fc4e12b7f5452b5346c554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:40<00:00,  2.02it/s, loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:38<00:00,  2.03it/s, loss=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:38<00:00,  2.03it/s, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:38<00:00,  2.03it/s, loss=0.184]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c7ebb178c0cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Results:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Results:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c7ebb178c0cf>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Results:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "# XLNet Fine-Tuning: Apple/Samsung Yelp Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# CUDA Check\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to HF datasets\n",
    "def prepare_hf_dataset(data):\n",
    "    return Dataset.from_pandas(data[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_dataset = prepare_hf_dataset(train_data)\n",
    "val_dataset = prepare_hf_dataset(val_data)\n",
    "test_dataset = prepare_hf_dataset(test_data)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=3).to(device)\n",
    "\n",
    "# Dataloaders and optimizer\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(4):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "\n",
    "print(\"Validation Results:\", evaluate(val_loader))\n",
    "print(\"Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "04dcbc893af84157827c4a62f83687c4",
      "6282635fd55345e29bf5302c6d0c774a",
      "2f485d52cf03449f80443d0dd832496e",
      "af3cbfbc9c33441889b92d05f3228139",
      "19942cc2e224402498d7f3af2a8328ee",
      "398f2dd3f57f43a5836028472982c667",
      "3065abbed0bb4ef38ddae33fc35d0967",
      "3c03c3b954dc4917b7c677eda62a9fe3",
      "3fb56c02a33f430694abad4025b1e543",
      "84760c635c054bb28e2ac3a4d2f7307e",
      "b0885b4f04ac44f9841fccbc6a2a50a6",
      "7bcfa3087fec4c70b28ae9de50d0a169",
      "fb28248dc0ca4c76849c5156f796ca2c",
      "d4dbf7050a544ec783d6b14eccaa1d8e",
      "40e7d8010b4146a68d8e8f8124ecf47a",
      "84bfcb1f07c3404b81fee485ddce935a",
      "23c6612ff7cb4d22b5e470a0957c7cef",
      "3ab133632a4845bea78e23b76f2ea901",
      "41a6869c78e7450f927143a73b389b42",
      "e470bba85f2f42f9b01c029984b09d73",
      "f4b9a50508834aad97d2641ac8bdd8cc",
      "efaf71a8778b4fed9691e566ce24b7c9",
      "13eb654954d34a24a06f883c4af340f8",
      "cf69602fbee84d83bd04f6581b3aad46",
      "c34010ed32f1411ea5ee190fc967f760",
      "0d9ec1b957724e02b47c3875e93fa3de",
      "79b46f14c35945c6bfc4177f94bcd764",
      "2fb5a23975da4ba8822ecdaa49dad646",
      "732169d23cf24c53b8ce4a272bd9e0d6",
      "dca924d989684c7d803cb30b8d90c8b8",
      "d5c718acd9484446bfd659b904509247",
      "4b299b49fdfe4b00afe25aba05cd83ce",
      "50997f11280944d5a72cae1dfea3f0b4",
      "9be08344fea84166a5564a9e6b7ae371",
      "024ce709689f47bc9edd461ca20cf08a",
      "2f1eacb13aa14cfd833e3b58eb3f1014",
      "df539a1dce0343628172c7dd7bcdf814",
      "ac08eb9e3d4a40aba149a39d4c952066",
      "8217022fec764e65a82bd5ebf8a4ce7e",
      "41c0888c89364e5886c2a5d5df5aa60b",
      "b62adeebb9054a7fb904968abc0f3668",
      "78b1d22789a64e7f8f0a7413c35e8584",
      "1261c33c1cdf4a2c8b72eb4442264a73",
      "80b2cddb95b2484e9485c0f1fac0ce2b",
      "079875426c724516a1eb92f9c58f8d3e",
      "28565286de0c4b80a096b8a9da4eb8c3",
      "df69bfe775e4489f9fb86e68ac509e0b",
      "4d81e25bd6e3498dbbe965fb5790467a",
      "41486dd2e7a1441e800ab898da114b6b",
      "8ca02c0c2869453494311d1ca56711dd",
      "0b087725d5794241b94d8be5d9f98b8a",
      "f31a2aa518e84dd4a176510605aa1c91",
      "6b6ac0e03cb64a778f17d1cc9e39b682",
      "1522300615914441b50e9cfe87bf5b6e",
      "2185f42ff414420fb9a49a8cb408b059",
      "59a6ba9be08f4ec3ba93713049ea9ccb",
      "b8349ba549444bac8843a664c619170a",
      "6bfb789faccf4399bdfb6138cb07f42d",
      "4646b057c8c34337af00f2d8e3b590e4",
      "0f4efa757d894df4a11829260f6b9388",
      "1fa52ee5c0494f63998145e8c5b7c6dc",
      "e172bbb521b748b4b9aa24d943ba208d",
      "b4794bd0dd844d8195ab5873b08ca986",
      "810b82c4fa81471e9f95a2c1cd5fc020",
      "aff76f281a4a4b39b12c261d87ec923d",
      "9d1cd6879fb7417bb7ff6b7c10980206",
      "81253541fd804194bb778a1f1f49ecfc",
      "c8432df57cee449da26bb297016a6855",
      "a9fc94ff3eea4d6c96f883ccec229b70",
      "5a39a7a653ba4e8f98b53c81b7a833a0",
      "15f8626c1fcf4dadb33ed3401abb640a",
      "67c833a153a64708adbe6f508c0822ac",
      "3ba82efd2ae84749a546863f0cd2d9f1",
      "bbd04d059b6044898c7af2cf72e500e3",
      "65f50fcd414541a6897c26c8f680443b",
      "07c0cfecc0b74835ba79c30bf3524d14",
      "1ab1438a47ff48bb9d92098fd790fed1",
      "354a3e5df0004490a8f757c31320bbd9",
      "7a814e12d45f4d998f7a5a6b13c1d916",
      "a55e46e3595c42b09fe9c381b90b6cd1",
      "c07f312f53ec4cdcb85f7de40c01484e",
      "7de0ee025790478682bb6cb93ed08c07",
      "3fb19bdc6f2b4ed3ad8d51fcf32dbc14",
      "5b4e146b810f4ec1b1340a64f245be07",
      "50f1d71c156a42548f1c51bae1d908e3",
      "385de6eabb6649398981822f0bd92a0b",
      "c0aca4847c734760bcb6bccb13a7ed6d",
      "c92106963b8447d499c753fda0972145"
     ]
    },
    "id": "4MlksmXrwlA8",
    "outputId": "03a0838a-683d-469e-99fb-ae9908d07062"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: Tesla T4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dcbc893af84157827c4a62f83687c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcfa3087fec4c70b28ae9de50d0a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13eb654954d34a24a06f883c4af340f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be08344fea84166a5564a9e6b7ae371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079875426c724516a1eb92f9c58f8d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a6ba9be08f4ec3ba93713049ea9ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81253541fd804194bb778a1f1f49ecfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354a3e5df0004490a8f757c31320bbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/566 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/566 [00:00<?, ?it/s, loss=1.04]\u001b[A\n",
      "  0%|          | 1/566 [00:00<06:15,  1.51it/s, loss=1.04]\u001b[A\n",
      "  0%|          | 1/566 [00:02<06:15,  1.51it/s, loss=1.08]\u001b[A\n",
      "  0%|          | 2/566 [00:02<10:01,  1.07s/it, loss=1.08]\u001b[A\n",
      "  0%|          | 2/566 [00:02<10:01,  1.07s/it, loss=1.07]\u001b[A\n",
      "  1%|          | 3/566 [00:02<06:34,  1.43it/s, loss=1.07]\u001b[A\n",
      "  1%|          | 3/566 [00:02<06:34,  1.43it/s, loss=1.03]\u001b[A\n",
      "  1%|          | 4/566 [00:02<04:56,  1.89it/s, loss=1.03]\u001b[A\n",
      "  1%|          | 4/566 [00:02<04:56,  1.89it/s, loss=1.12]\u001b[A\n",
      "  1%|          | 5/566 [00:02<04:07,  2.27it/s, loss=1.12]\u001b[A\n",
      "  1%|          | 5/566 [00:03<04:07,  2.27it/s, loss=1.05]\u001b[A\n",
      "  1%|          | 6/566 [00:03<03:34,  2.61it/s, loss=1.05]\u001b[A\n",
      "  1%|          | 6/566 [00:03<03:34,  2.61it/s, loss=1.04]\u001b[A\n",
      "  1%|          | 7/566 [00:03<03:13,  2.89it/s, loss=1.04]\u001b[A\n",
      "  1%|          | 7/566 [00:03<03:13,  2.89it/s, loss=1.01]\u001b[A\n",
      "  1%|▏         | 8/566 [00:03<02:58,  3.12it/s, loss=1.01]\u001b[A\n",
      "  1%|▏         | 8/566 [00:03<02:58,  3.12it/s, loss=1.03]\u001b[A\n",
      "  2%|▏         | 9/566 [00:03<02:49,  3.28it/s, loss=1.03]\u001b[A\n",
      "  2%|▏         | 9/566 [00:04<02:49,  3.28it/s, loss=0.995]\u001b[A\n",
      "  2%|▏         | 10/566 [00:04<02:43,  3.40it/s, loss=0.995]\u001b[A\n",
      "  2%|▏         | 10/566 [00:04<02:43,  3.40it/s, loss=0.98] \u001b[A\n",
      "  2%|▏         | 11/566 [00:04<02:39,  3.48it/s, loss=0.98]\u001b[A\n",
      "  2%|▏         | 11/566 [00:04<02:39,  3.48it/s, loss=1.04]\u001b[A\n",
      "  2%|▏         | 12/566 [00:04<02:36,  3.53it/s, loss=1.04]\u001b[A\n",
      "  2%|▏         | 12/566 [00:04<02:36,  3.53it/s, loss=0.999]\u001b[A\n",
      "  2%|▏         | 13/566 [00:04<02:34,  3.58it/s, loss=0.999]\u001b[A\n",
      "  2%|▏         | 13/566 [00:05<02:34,  3.58it/s, loss=1.02] \u001b[A\n",
      "  2%|▏         | 14/566 [00:05<02:33,  3.60it/s, loss=1.02]\u001b[A\n",
      "  2%|▏         | 14/566 [00:05<02:33,  3.60it/s, loss=0.859]\u001b[A\n",
      "  3%|▎         | 15/566 [00:05<02:32,  3.61it/s, loss=0.859]\u001b[A\n",
      "  3%|▎         | 15/566 [00:05<02:32,  3.61it/s, loss=1.07] \u001b[A\n",
      "  3%|▎         | 16/566 [00:05<02:31,  3.64it/s, loss=1.07]\u001b[A\n",
      "  3%|▎         | 16/566 [00:06<02:31,  3.64it/s, loss=1.1] \u001b[A\n",
      "  3%|▎         | 17/566 [00:06<02:31,  3.64it/s, loss=1.1]\u001b[A\n",
      "  3%|▎         | 17/566 [00:06<02:31,  3.64it/s, loss=1.12]\u001b[A\n",
      "  3%|▎         | 18/566 [00:06<02:29,  3.67it/s, loss=1.12]\u001b[A\n",
      "  3%|▎         | 18/566 [00:06<02:29,  3.67it/s, loss=1.06]\u001b[A\n",
      "  3%|▎         | 19/566 [00:06<02:30,  3.65it/s, loss=1.06]\u001b[A\n",
      "  3%|▎         | 19/566 [00:06<02:30,  3.65it/s, loss=1.02]\u001b[A\n",
      "  4%|▎         | 20/566 [00:06<02:30,  3.64it/s, loss=1.02]\u001b[A\n",
      "  4%|▎         | 20/566 [00:07<02:30,  3.64it/s, loss=0.909]\u001b[A\n",
      "  4%|▎         | 21/566 [00:07<02:29,  3.65it/s, loss=0.909]\u001b[A\n",
      "  4%|▎         | 21/566 [00:07<02:29,  3.65it/s, loss=1.06] \u001b[A\n",
      "  4%|▍         | 22/566 [00:07<02:28,  3.67it/s, loss=1.06]\u001b[A\n",
      "  4%|▍         | 22/566 [00:07<02:28,  3.67it/s, loss=1.04]\u001b[A\n",
      "  4%|▍         | 23/566 [00:07<02:29,  3.63it/s, loss=1.04]\u001b[A\n",
      "  4%|▍         | 23/566 [00:08<02:29,  3.63it/s, loss=1.18]\u001b[A\n",
      "  4%|▍         | 24/566 [00:08<02:29,  3.61it/s, loss=1.18]\u001b[A\n",
      "  4%|▍         | 24/566 [00:08<02:29,  3.61it/s, loss=0.964]\u001b[A\n",
      "  4%|▍         | 25/566 [00:08<02:29,  3.62it/s, loss=0.964]\u001b[A\n",
      "  4%|▍         | 25/566 [00:08<02:29,  3.62it/s, loss=0.885]\u001b[A\n",
      "  5%|▍         | 26/566 [00:08<02:29,  3.62it/s, loss=0.885]\u001b[A\n",
      "  5%|▍         | 26/566 [00:08<02:29,  3.62it/s, loss=0.874]\u001b[A\n",
      "  5%|▍         | 27/566 [00:08<02:28,  3.62it/s, loss=0.874]\u001b[A\n",
      "  5%|▍         | 27/566 [00:09<02:28,  3.62it/s, loss=0.995]\u001b[A\n",
      "  5%|▍         | 28/566 [00:09<02:29,  3.60it/s, loss=0.995]\u001b[A\n",
      "  5%|▍         | 28/566 [00:09<02:29,  3.60it/s, loss=0.976]\u001b[A\n",
      "  5%|▌         | 29/566 [00:09<02:29,  3.60it/s, loss=0.976]\u001b[A\n",
      "  5%|▌         | 29/566 [00:09<02:29,  3.60it/s, loss=1.01] \u001b[A\n",
      "  5%|▌         | 30/566 [00:09<02:28,  3.62it/s, loss=1.01]\u001b[A\n",
      "  5%|▌         | 30/566 [00:09<02:28,  3.62it/s, loss=1.01]\u001b[A\n",
      "  5%|▌         | 31/566 [00:09<02:28,  3.59it/s, loss=1.01]\u001b[A\n",
      "  5%|▌         | 31/566 [00:10<02:28,  3.59it/s, loss=1.01]\u001b[A\n",
      "  6%|▌         | 32/566 [00:10<02:27,  3.62it/s, loss=1.01]\u001b[A\n",
      "  6%|▌         | 32/566 [00:10<02:27,  3.62it/s, loss=1.07]\u001b[A\n",
      "  6%|▌         | 33/566 [00:10<02:27,  3.62it/s, loss=1.07]\u001b[A\n",
      "  6%|▌         | 33/566 [00:10<02:27,  3.62it/s, loss=0.933]\u001b[A\n",
      "  6%|▌         | 34/566 [00:10<02:26,  3.63it/s, loss=0.933]\u001b[A\n",
      "  6%|▌         | 34/566 [00:11<02:26,  3.63it/s, loss=0.955]\u001b[A\n",
      "  6%|▌         | 35/566 [00:11<02:26,  3.63it/s, loss=0.955]\u001b[A\n",
      "  6%|▌         | 35/566 [00:11<02:26,  3.63it/s, loss=1.05] \u001b[A\n",
      "  6%|▋         | 36/566 [00:11<02:24,  3.66it/s, loss=1.05]\u001b[A\n",
      "  6%|▋         | 36/566 [00:11<02:24,  3.66it/s, loss=0.868]\u001b[A\n",
      "  7%|▋         | 37/566 [00:11<02:26,  3.61it/s, loss=0.868]\u001b[A\n",
      "  7%|▋         | 37/566 [00:11<02:26,  3.61it/s, loss=0.978]\u001b[A\n",
      "  7%|▋         | 38/566 [00:11<02:25,  3.62it/s, loss=0.978]\u001b[A\n",
      "  7%|▋         | 38/566 [00:12<02:25,  3.62it/s, loss=1.08] \u001b[A\n",
      "  7%|▋         | 39/566 [00:12<02:25,  3.61it/s, loss=1.08]\u001b[A\n",
      "  7%|▋         | 39/566 [00:12<02:25,  3.61it/s, loss=0.956]\u001b[A\n",
      "  7%|▋         | 40/566 [00:12<02:25,  3.61it/s, loss=0.956]\u001b[A\n",
      "  7%|▋         | 40/566 [00:12<02:25,  3.61it/s, loss=0.922]\u001b[A\n",
      "  7%|▋         | 41/566 [00:12<02:26,  3.59it/s, loss=0.922]\u001b[A\n",
      "  7%|▋         | 41/566 [00:12<02:26,  3.59it/s, loss=0.887]\u001b[A\n",
      "  7%|▋         | 42/566 [00:12<02:25,  3.60it/s, loss=0.887]\u001b[A\n",
      "  7%|▋         | 42/566 [00:13<02:25,  3.60it/s, loss=1.04] \u001b[A\n",
      "  8%|▊         | 43/566 [00:13<02:23,  3.65it/s, loss=1.04]\u001b[A\n",
      "  8%|▊         | 43/566 [00:13<02:23,  3.65it/s, loss=1.04]\u001b[A\n",
      "  8%|▊         | 44/566 [00:13<02:23,  3.64it/s, loss=1.04]\u001b[A\n",
      "  8%|▊         | 44/566 [00:13<02:23,  3.64it/s, loss=0.937]\u001b[A\n",
      "  8%|▊         | 45/566 [00:13<02:24,  3.60it/s, loss=0.937]\u001b[A\n",
      "  8%|▊         | 45/566 [00:14<02:24,  3.60it/s, loss=0.92] \u001b[A\n",
      "  8%|▊         | 46/566 [00:14<02:24,  3.59it/s, loss=0.92]\u001b[A\n",
      "  8%|▊         | 46/566 [00:14<02:24,  3.59it/s, loss=0.682]\u001b[A\n",
      "  8%|▊         | 47/566 [00:14<02:24,  3.59it/s, loss=0.682]\u001b[A\n",
      "  8%|▊         | 47/566 [00:14<02:24,  3.59it/s, loss=0.89] \u001b[A\n",
      "  8%|▊         | 48/566 [00:14<02:24,  3.58it/s, loss=0.89]\u001b[A\n",
      "  8%|▊         | 48/566 [00:14<02:24,  3.58it/s, loss=1.04]\u001b[A\n",
      "  9%|▊         | 49/566 [00:14<02:24,  3.59it/s, loss=1.04]\u001b[A\n",
      "  9%|▊         | 49/566 [00:15<02:24,  3.59it/s, loss=0.696]\u001b[A\n",
      "  9%|▉         | 50/566 [00:15<02:23,  3.59it/s, loss=0.696]\u001b[A\n",
      "  9%|▉         | 50/566 [00:15<02:23,  3.59it/s, loss=0.92] \u001b[A\n",
      "  9%|▉         | 51/566 [00:15<02:23,  3.58it/s, loss=0.92]\u001b[A\n",
      "  9%|▉         | 51/566 [00:15<02:23,  3.58it/s, loss=1.35]\u001b[A\n",
      "  9%|▉         | 52/566 [00:15<02:23,  3.58it/s, loss=1.35]\u001b[A\n",
      "  9%|▉         | 52/566 [00:16<02:23,  3.58it/s, loss=0.805]\u001b[A\n",
      "  9%|▉         | 53/566 [00:16<02:22,  3.60it/s, loss=0.805]\u001b[A\n",
      "  9%|▉         | 53/566 [00:16<02:22,  3.60it/s, loss=0.799]\u001b[A\n",
      " 10%|▉         | 54/566 [00:16<02:22,  3.59it/s, loss=0.799]\u001b[A\n",
      " 10%|▉         | 54/566 [00:16<02:22,  3.59it/s, loss=0.963]\u001b[A\n",
      " 10%|▉         | 55/566 [00:16<02:23,  3.55it/s, loss=0.963]\u001b[A\n",
      " 10%|▉         | 55/566 [00:16<02:23,  3.55it/s, loss=0.855]\u001b[A\n",
      " 10%|▉         | 56/566 [00:16<02:23,  3.55it/s, loss=0.855]\u001b[A\n",
      " 10%|▉         | 56/566 [00:17<02:23,  3.55it/s, loss=0.899]\u001b[A\n",
      " 10%|█         | 57/566 [00:17<02:22,  3.57it/s, loss=0.899]\u001b[A\n",
      " 10%|█         | 57/566 [00:17<02:22,  3.57it/s, loss=0.972]\u001b[A\n",
      " 10%|█         | 58/566 [00:17<02:22,  3.56it/s, loss=0.972]\u001b[A\n",
      " 10%|█         | 58/566 [00:17<02:22,  3.56it/s, loss=0.796]\u001b[A\n",
      " 10%|█         | 59/566 [00:17<02:22,  3.56it/s, loss=0.796]\u001b[A\n",
      " 10%|█         | 59/566 [00:18<02:22,  3.56it/s, loss=0.749]\u001b[A\n",
      " 11%|█         | 60/566 [00:18<02:22,  3.55it/s, loss=0.749]\u001b[A\n",
      " 11%|█         | 60/566 [00:18<02:22,  3.55it/s, loss=0.767]\u001b[A\n",
      " 11%|█         | 61/566 [00:18<02:22,  3.55it/s, loss=0.767]\u001b[A\n",
      " 11%|█         | 61/566 [00:18<02:22,  3.55it/s, loss=0.969]\u001b[A\n",
      " 11%|█         | 62/566 [00:18<02:22,  3.54it/s, loss=0.969]\u001b[A\n",
      " 11%|█         | 62/566 [00:18<02:22,  3.54it/s, loss=0.622]\u001b[A\n",
      " 11%|█         | 63/566 [00:18<02:23,  3.50it/s, loss=0.622]\u001b[A\n",
      " 11%|█         | 63/566 [00:19<02:23,  3.50it/s, loss=1.16] \u001b[A\n",
      " 11%|█▏        | 64/566 [00:19<02:22,  3.53it/s, loss=1.16]\u001b[A\n",
      " 11%|█▏        | 64/566 [00:19<02:22,  3.53it/s, loss=0.856]\u001b[A\n",
      " 11%|█▏        | 65/566 [00:19<02:21,  3.55it/s, loss=0.856]\u001b[A\n",
      " 11%|█▏        | 65/566 [00:19<02:21,  3.55it/s, loss=0.59] \u001b[A\n",
      " 12%|█▏        | 66/566 [00:19<02:20,  3.55it/s, loss=0.59]\u001b[A\n",
      " 12%|█▏        | 66/566 [00:19<02:20,  3.55it/s, loss=0.813]\u001b[A\n",
      " 12%|█▏        | 67/566 [00:20<02:20,  3.55it/s, loss=0.813]\u001b[A\n",
      " 12%|█▏        | 67/566 [00:20<02:20,  3.55it/s, loss=1.01] \u001b[A\n",
      " 12%|█▏        | 68/566 [00:20<02:20,  3.54it/s, loss=1.01]\u001b[A\n",
      " 12%|█▏        | 68/566 [00:20<02:20,  3.54it/s, loss=0.786]\u001b[A\n",
      " 12%|█▏        | 69/566 [00:20<02:19,  3.55it/s, loss=0.786]\u001b[A\n",
      " 12%|█▏        | 69/566 [00:20<02:19,  3.55it/s, loss=0.729]\u001b[A\n",
      " 12%|█▏        | 70/566 [00:20<02:20,  3.54it/s, loss=0.729]\u001b[A\n",
      " 12%|█▏        | 70/566 [00:21<02:20,  3.54it/s, loss=0.55] \u001b[A\n",
      " 13%|█▎        | 71/566 [00:21<02:19,  3.54it/s, loss=0.55]\u001b[A\n",
      " 13%|█▎        | 71/566 [00:21<02:19,  3.54it/s, loss=0.987]\u001b[A\n",
      " 13%|█▎        | 72/566 [00:21<02:20,  3.52it/s, loss=0.987]\u001b[A\n",
      " 13%|█▎        | 72/566 [00:21<02:20,  3.52it/s, loss=0.886]\u001b[A\n",
      " 13%|█▎        | 73/566 [00:21<02:19,  3.53it/s, loss=0.886]\u001b[A\n",
      " 13%|█▎        | 73/566 [00:21<02:19,  3.53it/s, loss=0.793]\u001b[A\n",
      " 13%|█▎        | 74/566 [00:21<02:19,  3.53it/s, loss=0.793]\u001b[A\n",
      " 13%|█▎        | 74/566 [00:22<02:19,  3.53it/s, loss=1.22] \u001b[A\n",
      " 13%|█▎        | 75/566 [00:22<02:18,  3.55it/s, loss=1.22]\u001b[A\n",
      " 13%|█▎        | 75/566 [00:22<02:18,  3.55it/s, loss=0.604]\u001b[A\n",
      " 13%|█▎        | 76/566 [00:22<02:17,  3.55it/s, loss=0.604]\u001b[A\n",
      " 13%|█▎        | 76/566 [00:22<02:17,  3.55it/s, loss=0.803]\u001b[A\n",
      " 14%|█▎        | 77/566 [00:22<02:17,  3.55it/s, loss=0.803]\u001b[A\n",
      " 14%|█▎        | 77/566 [00:23<02:17,  3.55it/s, loss=0.751]\u001b[A\n",
      " 14%|█▍        | 78/566 [00:23<02:17,  3.55it/s, loss=0.751]\u001b[A\n",
      " 14%|█▍        | 78/566 [00:23<02:17,  3.55it/s, loss=0.827]\u001b[A\n",
      " 14%|█▍        | 79/566 [00:23<02:16,  3.56it/s, loss=0.827]\u001b[A\n",
      " 14%|█▍        | 79/566 [00:23<02:16,  3.56it/s, loss=0.569]\u001b[A\n",
      " 14%|█▍        | 80/566 [00:23<02:16,  3.55it/s, loss=0.569]\u001b[A\n",
      " 14%|█▍        | 80/566 [00:23<02:16,  3.55it/s, loss=1.07] \u001b[A\n",
      " 14%|█▍        | 81/566 [00:23<02:16,  3.56it/s, loss=1.07]\u001b[A\n",
      " 14%|█▍        | 81/566 [00:24<02:16,  3.56it/s, loss=1.28]\u001b[A\n",
      " 14%|█▍        | 82/566 [00:24<02:16,  3.55it/s, loss=1.28]\u001b[A\n",
      " 14%|█▍        | 82/566 [00:24<02:16,  3.55it/s, loss=1.05]\u001b[A\n",
      " 15%|█▍        | 83/566 [00:24<02:16,  3.54it/s, loss=1.05]\u001b[A\n",
      " 15%|█▍        | 83/566 [00:24<02:16,  3.54it/s, loss=0.681]\u001b[A\n",
      " 15%|█▍        | 84/566 [00:24<02:16,  3.54it/s, loss=0.681]\u001b[A\n",
      " 15%|█▍        | 84/566 [00:25<02:16,  3.54it/s, loss=0.709]\u001b[A\n",
      " 15%|█▌        | 85/566 [00:25<02:16,  3.53it/s, loss=0.709]\u001b[A\n",
      " 15%|█▌        | 85/566 [00:25<02:16,  3.53it/s, loss=1.06] \u001b[A\n",
      " 15%|█▌        | 86/566 [00:25<02:16,  3.52it/s, loss=1.06]\u001b[A\n",
      " 15%|█▌        | 86/566 [00:25<02:16,  3.52it/s, loss=0.998]\u001b[A\n",
      " 15%|█▌        | 87/566 [00:25<02:15,  3.54it/s, loss=0.998]\u001b[A\n",
      " 15%|█▌        | 87/566 [00:25<02:15,  3.54it/s, loss=0.846]\u001b[A\n",
      " 16%|█▌        | 88/566 [00:25<02:13,  3.57it/s, loss=0.846]\u001b[A\n",
      " 16%|█▌        | 88/566 [00:26<02:13,  3.57it/s, loss=0.781]\u001b[A\n",
      " 16%|█▌        | 89/566 [00:26<02:13,  3.58it/s, loss=0.781]\u001b[A\n",
      " 16%|█▌        | 89/566 [00:26<02:13,  3.58it/s, loss=0.994]\u001b[A\n",
      " 16%|█▌        | 90/566 [00:26<02:13,  3.57it/s, loss=0.994]\u001b[A\n",
      " 16%|█▌        | 90/566 [00:26<02:13,  3.57it/s, loss=0.808]\u001b[A\n",
      " 16%|█▌        | 91/566 [00:26<02:13,  3.56it/s, loss=0.808]\u001b[A\n",
      " 16%|█▌        | 91/566 [00:27<02:13,  3.56it/s, loss=0.777]\u001b[A\n",
      " 16%|█▋        | 92/566 [00:27<02:12,  3.57it/s, loss=0.777]\u001b[A\n",
      " 16%|█▋        | 92/566 [00:27<02:12,  3.57it/s, loss=0.963]\u001b[A\n",
      " 16%|█▋        | 93/566 [00:27<02:12,  3.57it/s, loss=0.963]\u001b[A\n",
      " 16%|█▋        | 93/566 [00:27<02:12,  3.57it/s, loss=0.962]\u001b[A\n",
      " 17%|█▋        | 94/566 [00:27<02:11,  3.59it/s, loss=0.962]\u001b[A\n",
      " 17%|█▋        | 94/566 [00:27<02:11,  3.59it/s, loss=0.493]\u001b[A\n",
      " 17%|█▋        | 95/566 [00:27<02:11,  3.58it/s, loss=0.493]\u001b[A\n",
      " 17%|█▋        | 95/566 [00:28<02:11,  3.58it/s, loss=0.853]\u001b[A\n",
      " 17%|█▋        | 96/566 [00:28<02:11,  3.57it/s, loss=0.853]\u001b[A\n",
      " 17%|█▋        | 96/566 [00:28<02:11,  3.57it/s, loss=0.664]\u001b[A\n",
      " 17%|█▋        | 97/566 [00:28<02:11,  3.57it/s, loss=0.664]\u001b[A\n",
      " 17%|█▋        | 97/566 [00:28<02:11,  3.57it/s, loss=0.636]\u001b[A\n",
      " 17%|█▋        | 98/566 [00:28<02:10,  3.60it/s, loss=0.636]\u001b[A\n",
      " 17%|█▋        | 98/566 [00:28<02:10,  3.60it/s, loss=0.706]\u001b[A\n",
      " 17%|█▋        | 99/566 [00:28<02:09,  3.61it/s, loss=0.706]\u001b[A\n",
      " 17%|█▋        | 99/566 [00:29<02:09,  3.61it/s, loss=0.984]\u001b[A\n",
      " 18%|█▊        | 100/566 [00:29<02:09,  3.61it/s, loss=0.984]\u001b[A\n",
      " 18%|█▊        | 100/566 [00:29<02:09,  3.61it/s, loss=0.869]\u001b[A\n",
      " 18%|█▊        | 101/566 [00:29<02:09,  3.59it/s, loss=0.869]\u001b[A\n",
      " 18%|█▊        | 101/566 [00:29<02:09,  3.59it/s, loss=0.7]  \u001b[A\n",
      " 18%|█▊        | 102/566 [00:29<02:08,  3.61it/s, loss=0.7]\u001b[A\n",
      " 18%|█▊        | 102/566 [00:30<02:08,  3.61it/s, loss=0.998]\u001b[A\n",
      " 18%|█▊        | 103/566 [00:30<02:08,  3.61it/s, loss=0.998]\u001b[A\n",
      " 18%|█▊        | 103/566 [00:30<02:08,  3.61it/s, loss=0.473]\u001b[A\n",
      " 18%|█▊        | 104/566 [00:30<02:07,  3.61it/s, loss=0.473]\u001b[A\n",
      " 18%|█▊        | 104/566 [00:30<02:07,  3.61it/s, loss=0.71] \u001b[A\n",
      " 19%|█▊        | 105/566 [00:30<02:07,  3.61it/s, loss=0.71]\u001b[A\n",
      " 19%|█▊        | 105/566 [00:30<02:07,  3.61it/s, loss=0.804]\u001b[A\n",
      " 19%|█▊        | 106/566 [00:30<02:06,  3.63it/s, loss=0.804]\u001b[A\n",
      " 19%|█▊        | 106/566 [00:31<02:06,  3.63it/s, loss=0.68] \u001b[A\n",
      " 19%|█▉        | 107/566 [00:31<02:07,  3.60it/s, loss=0.68]\u001b[A\n",
      " 19%|█▉        | 107/566 [00:31<02:07,  3.60it/s, loss=0.811]\u001b[A\n",
      " 19%|█▉        | 108/566 [00:31<02:06,  3.61it/s, loss=0.811]\u001b[A\n",
      " 19%|█▉        | 108/566 [00:31<02:06,  3.61it/s, loss=0.883]\u001b[A\n",
      " 19%|█▉        | 109/566 [00:31<02:07,  3.59it/s, loss=0.883]\u001b[A\n",
      " 19%|█▉        | 109/566 [00:32<02:07,  3.59it/s, loss=0.773]\u001b[A\n",
      " 19%|█▉        | 110/566 [00:32<02:06,  3.61it/s, loss=0.773]\u001b[A\n",
      " 19%|█▉        | 110/566 [00:32<02:06,  3.61it/s, loss=0.681]\u001b[A\n",
      " 20%|█▉        | 111/566 [00:32<02:06,  3.60it/s, loss=0.681]\u001b[A\n",
      " 20%|█▉        | 111/566 [00:32<02:06,  3.60it/s, loss=0.68] \u001b[A\n",
      " 20%|█▉        | 112/566 [00:32<02:06,  3.60it/s, loss=0.68]\u001b[A\n",
      " 20%|█▉        | 112/566 [00:32<02:06,  3.60it/s, loss=0.643]\u001b[A\n",
      " 20%|█▉        | 113/566 [00:32<02:06,  3.58it/s, loss=0.643]\u001b[A\n",
      " 20%|█▉        | 113/566 [00:33<02:06,  3.58it/s, loss=0.594]\u001b[A\n",
      " 20%|██        | 114/566 [00:33<02:05,  3.61it/s, loss=0.594]\u001b[A\n",
      " 20%|██        | 114/566 [00:33<02:05,  3.61it/s, loss=0.753]\u001b[A\n",
      " 20%|██        | 115/566 [00:33<02:04,  3.63it/s, loss=0.753]\u001b[A\n",
      " 20%|██        | 115/566 [00:33<02:04,  3.63it/s, loss=0.783]\u001b[A\n",
      " 20%|██        | 116/566 [00:33<02:05,  3.59it/s, loss=0.783]\u001b[A\n",
      " 20%|██        | 116/566 [00:33<02:05,  3.59it/s, loss=0.607]\u001b[A\n",
      " 21%|██        | 117/566 [00:33<02:04,  3.60it/s, loss=0.607]\u001b[A\n",
      " 21%|██        | 117/566 [00:34<02:04,  3.60it/s, loss=0.752]\u001b[A\n",
      " 21%|██        | 118/566 [00:34<02:04,  3.61it/s, loss=0.752]\u001b[A\n",
      " 21%|██        | 118/566 [00:34<02:04,  3.61it/s, loss=0.649]\u001b[A\n",
      " 21%|██        | 119/566 [00:34<02:02,  3.64it/s, loss=0.649]\u001b[A\n",
      " 21%|██        | 119/566 [00:34<02:02,  3.64it/s, loss=0.808]\u001b[A\n",
      " 21%|██        | 120/566 [00:34<02:03,  3.61it/s, loss=0.808]\u001b[A\n",
      " 21%|██        | 120/566 [00:35<02:03,  3.61it/s, loss=0.547]\u001b[A\n",
      " 21%|██▏       | 121/566 [00:35<02:03,  3.62it/s, loss=0.547]\u001b[A\n",
      " 21%|██▏       | 121/566 [00:35<02:03,  3.62it/s, loss=0.944]\u001b[A\n",
      " 22%|██▏       | 122/566 [00:35<02:02,  3.64it/s, loss=0.944]\u001b[A\n",
      " 22%|██▏       | 122/566 [00:35<02:02,  3.64it/s, loss=0.653]\u001b[A\n",
      " 22%|██▏       | 123/566 [00:35<02:01,  3.65it/s, loss=0.653]\u001b[A\n",
      " 22%|██▏       | 123/566 [00:35<02:01,  3.65it/s, loss=0.75] \u001b[A\n",
      " 22%|██▏       | 124/566 [00:35<02:00,  3.65it/s, loss=0.75]\u001b[A\n",
      " 22%|██▏       | 124/566 [00:36<02:00,  3.65it/s, loss=0.664]\u001b[A\n",
      " 22%|██▏       | 125/566 [00:36<02:01,  3.64it/s, loss=0.664]\u001b[A\n",
      " 22%|██▏       | 125/566 [00:36<02:01,  3.64it/s, loss=0.755]\u001b[A\n",
      " 22%|██▏       | 126/566 [00:36<02:00,  3.65it/s, loss=0.755]\u001b[A\n",
      " 22%|██▏       | 126/566 [00:36<02:00,  3.65it/s, loss=0.572]\u001b[A\n",
      " 22%|██▏       | 127/566 [00:36<02:00,  3.65it/s, loss=0.572]\u001b[A\n",
      " 22%|██▏       | 127/566 [00:36<02:00,  3.65it/s, loss=0.346]\u001b[A\n",
      " 23%|██▎       | 128/566 [00:36<01:59,  3.66it/s, loss=0.346]\u001b[A\n",
      " 23%|██▎       | 128/566 [00:37<01:59,  3.66it/s, loss=0.517]\u001b[A\n",
      " 23%|██▎       | 129/566 [00:37<01:59,  3.66it/s, loss=0.517]\u001b[A\n",
      " 23%|██▎       | 129/566 [00:37<01:59,  3.66it/s, loss=1.08] \u001b[A\n",
      " 23%|██▎       | 130/566 [00:37<01:58,  3.67it/s, loss=1.08]\u001b[A\n",
      " 23%|██▎       | 130/566 [00:37<01:58,  3.67it/s, loss=0.576]\u001b[A\n",
      " 23%|██▎       | 131/566 [00:37<01:59,  3.66it/s, loss=0.576]\u001b[A\n",
      " 23%|██▎       | 131/566 [00:38<01:59,  3.66it/s, loss=0.333]\u001b[A\n",
      " 23%|██▎       | 132/566 [00:38<01:58,  3.68it/s, loss=0.333]\u001b[A\n",
      " 23%|██▎       | 132/566 [00:38<01:58,  3.68it/s, loss=1.11] \u001b[A\n",
      " 23%|██▎       | 133/566 [00:38<01:57,  3.68it/s, loss=1.11]\u001b[A\n",
      " 23%|██▎       | 133/566 [00:38<01:57,  3.68it/s, loss=1.08]\u001b[A\n",
      " 24%|██▎       | 134/566 [00:38<01:57,  3.68it/s, loss=1.08]\u001b[A\n",
      " 24%|██▎       | 134/566 [00:38<01:57,  3.68it/s, loss=1.08]\u001b[A\n",
      " 24%|██▍       | 135/566 [00:38<01:57,  3.67it/s, loss=1.08]\u001b[A\n",
      " 24%|██▍       | 135/566 [00:39<01:57,  3.67it/s, loss=0.863]\u001b[A\n",
      " 24%|██▍       | 136/566 [00:39<01:57,  3.66it/s, loss=0.863]\u001b[A\n",
      " 24%|██▍       | 136/566 [00:39<01:57,  3.66it/s, loss=0.752]\u001b[A\n",
      " 24%|██▍       | 137/566 [00:39<01:57,  3.64it/s, loss=0.752]\u001b[A\n",
      " 24%|██▍       | 137/566 [00:39<01:57,  3.64it/s, loss=0.548]\u001b[A\n",
      " 24%|██▍       | 138/566 [00:39<01:57,  3.65it/s, loss=0.548]\u001b[A\n",
      " 24%|██▍       | 138/566 [00:39<01:57,  3.65it/s, loss=0.576]\u001b[A\n",
      " 25%|██▍       | 139/566 [00:40<01:56,  3.65it/s, loss=0.576]\u001b[A\n",
      " 25%|██▍       | 139/566 [00:40<01:56,  3.65it/s, loss=1.26] \u001b[A\n",
      " 25%|██▍       | 140/566 [00:40<01:55,  3.68it/s, loss=1.26]\u001b[A\n",
      " 25%|██▍       | 140/566 [00:40<01:55,  3.68it/s, loss=0.602]\u001b[A\n",
      " 25%|██▍       | 141/566 [00:40<01:55,  3.69it/s, loss=0.602]\u001b[A\n",
      " 25%|██▍       | 141/566 [00:40<01:55,  3.69it/s, loss=0.786]\u001b[A\n",
      " 25%|██▌       | 142/566 [00:40<01:55,  3.67it/s, loss=0.786]\u001b[A\n",
      " 25%|██▌       | 142/566 [00:41<01:55,  3.67it/s, loss=0.694]\u001b[A\n",
      " 25%|██▌       | 143/566 [00:41<01:55,  3.67it/s, loss=0.694]\u001b[A\n",
      " 25%|██▌       | 143/566 [00:41<01:55,  3.67it/s, loss=0.648]\u001b[A\n",
      " 25%|██▌       | 144/566 [00:41<01:55,  3.66it/s, loss=0.648]\u001b[A\n",
      " 25%|██▌       | 144/566 [00:41<01:55,  3.66it/s, loss=0.78] \u001b[A\n",
      " 26%|██▌       | 145/566 [00:41<01:54,  3.68it/s, loss=0.78]\u001b[A\n",
      " 26%|██▌       | 145/566 [00:41<01:54,  3.68it/s, loss=0.691]\u001b[A\n",
      " 26%|██▌       | 146/566 [00:41<01:54,  3.67it/s, loss=0.691]\u001b[A\n",
      " 26%|██▌       | 146/566 [00:42<01:54,  3.67it/s, loss=0.938]\u001b[A\n",
      " 26%|██▌       | 147/566 [00:42<01:53,  3.69it/s, loss=0.938]\u001b[A\n",
      " 26%|██▌       | 147/566 [00:42<01:53,  3.69it/s, loss=0.607]\u001b[A\n",
      " 26%|██▌       | 148/566 [00:42<01:53,  3.68it/s, loss=0.607]\u001b[A\n",
      " 26%|██▌       | 148/566 [00:42<01:53,  3.68it/s, loss=0.665]\u001b[A\n",
      " 26%|██▋       | 149/566 [00:42<01:53,  3.68it/s, loss=0.665]\u001b[A\n",
      " 26%|██▋       | 149/566 [00:42<01:53,  3.68it/s, loss=0.612]\u001b[A\n",
      " 27%|██▋       | 150/566 [00:42<01:53,  3.68it/s, loss=0.612]\u001b[A\n",
      " 27%|██▋       | 150/566 [00:43<01:53,  3.68it/s, loss=0.598]\u001b[A\n",
      " 27%|██▋       | 151/566 [00:43<01:52,  3.68it/s, loss=0.598]\u001b[A\n",
      " 27%|██▋       | 151/566 [00:43<01:52,  3.68it/s, loss=0.694]\u001b[A\n",
      " 27%|██▋       | 152/566 [00:43<01:52,  3.68it/s, loss=0.694]\u001b[A\n",
      " 27%|██▋       | 152/566 [00:43<01:52,  3.68it/s, loss=0.875]\u001b[A\n",
      " 27%|██▋       | 153/566 [00:43<01:52,  3.68it/s, loss=0.875]\u001b[A\n",
      " 27%|██▋       | 153/566 [00:44<01:52,  3.68it/s, loss=0.47] \u001b[A\n",
      " 27%|██▋       | 154/566 [00:44<01:51,  3.68it/s, loss=0.47]\u001b[A\n",
      " 27%|██▋       | 154/566 [00:44<01:51,  3.68it/s, loss=0.985]\u001b[A\n",
      " 27%|██▋       | 155/566 [00:44<01:51,  3.67it/s, loss=0.985]\u001b[A\n",
      " 27%|██▋       | 155/566 [00:44<01:51,  3.67it/s, loss=0.456]\u001b[A\n",
      " 28%|██▊       | 156/566 [00:44<01:51,  3.67it/s, loss=0.456]\u001b[A\n",
      " 28%|██▊       | 156/566 [00:44<01:51,  3.67it/s, loss=0.763]\u001b[A\n",
      " 28%|██▊       | 157/566 [00:44<01:51,  3.66it/s, loss=0.763]\u001b[A\n",
      " 28%|██▊       | 157/566 [00:45<01:51,  3.66it/s, loss=0.678]\u001b[A\n",
      " 28%|██▊       | 158/566 [00:45<01:50,  3.69it/s, loss=0.678]\u001b[A\n",
      " 28%|██▊       | 158/566 [00:45<01:50,  3.69it/s, loss=0.859]\u001b[A\n",
      " 28%|██▊       | 159/566 [00:45<01:50,  3.67it/s, loss=0.859]\u001b[A\n",
      " 28%|██▊       | 159/566 [00:45<01:50,  3.67it/s, loss=0.574]\u001b[A\n",
      " 28%|██▊       | 160/566 [00:45<01:50,  3.69it/s, loss=0.574]\u001b[A\n",
      " 28%|██▊       | 160/566 [00:45<01:50,  3.69it/s, loss=0.571]\u001b[A\n",
      " 28%|██▊       | 161/566 [00:45<01:49,  3.69it/s, loss=0.571]\u001b[A\n",
      " 28%|██▊       | 161/566 [00:46<01:49,  3.69it/s, loss=0.669]\u001b[A\n",
      " 29%|██▊       | 162/566 [00:46<01:49,  3.69it/s, loss=0.669]\u001b[A\n",
      " 29%|██▊       | 162/566 [00:46<01:49,  3.69it/s, loss=0.607]\u001b[A\n",
      " 29%|██▉       | 163/566 [00:46<01:48,  3.72it/s, loss=0.607]\u001b[A\n",
      " 29%|██▉       | 163/566 [00:46<01:48,  3.72it/s, loss=0.721]\u001b[A\n",
      " 29%|██▉       | 164/566 [00:46<01:47,  3.72it/s, loss=0.721]\u001b[A\n",
      " 29%|██▉       | 164/566 [00:47<01:47,  3.72it/s, loss=0.888]\u001b[A\n",
      " 29%|██▉       | 165/566 [00:47<01:47,  3.73it/s, loss=0.888]\u001b[A\n",
      " 29%|██▉       | 165/566 [00:47<01:47,  3.73it/s, loss=1.62] \u001b[A\n",
      " 29%|██▉       | 166/566 [00:47<01:46,  3.74it/s, loss=1.62]\u001b[A\n",
      " 29%|██▉       | 166/566 [00:47<01:46,  3.74it/s, loss=1.13]\u001b[A\n",
      " 30%|██▉       | 167/566 [00:47<01:46,  3.74it/s, loss=1.13]\u001b[A\n",
      " 30%|██▉       | 167/566 [00:47<01:46,  3.74it/s, loss=1.34]\u001b[A\n",
      " 30%|██▉       | 168/566 [00:47<01:46,  3.73it/s, loss=1.34]\u001b[A\n",
      " 30%|██▉       | 168/566 [00:48<01:46,  3.73it/s, loss=0.781]\u001b[A\n",
      " 30%|██▉       | 169/566 [00:48<01:46,  3.73it/s, loss=0.781]\u001b[A\n",
      " 30%|██▉       | 169/566 [00:48<01:46,  3.73it/s, loss=0.827]\u001b[A\n",
      " 30%|███       | 170/566 [00:48<01:45,  3.75it/s, loss=0.827]\u001b[A\n",
      " 30%|███       | 170/566 [00:48<01:45,  3.75it/s, loss=0.806]\u001b[A\n",
      " 30%|███       | 171/566 [00:48<01:45,  3.73it/s, loss=0.806]\u001b[A\n",
      " 30%|███       | 171/566 [00:48<01:45,  3.73it/s, loss=0.657]\u001b[A\n",
      " 30%|███       | 172/566 [00:48<01:45,  3.74it/s, loss=0.657]\u001b[A\n",
      " 30%|███       | 172/566 [00:49<01:45,  3.74it/s, loss=0.665]\u001b[A\n",
      " 31%|███       | 173/566 [00:49<01:45,  3.74it/s, loss=0.665]\u001b[A\n",
      " 31%|███       | 173/566 [00:49<01:45,  3.74it/s, loss=0.806]\u001b[A\n",
      " 31%|███       | 174/566 [00:49<01:45,  3.72it/s, loss=0.806]\u001b[A\n",
      " 31%|███       | 174/566 [00:49<01:45,  3.72it/s, loss=0.745]\u001b[A\n",
      " 31%|███       | 175/566 [00:49<01:45,  3.72it/s, loss=0.745]\u001b[A\n",
      " 31%|███       | 175/566 [00:49<01:45,  3.72it/s, loss=0.689]\u001b[A\n",
      " 31%|███       | 176/566 [00:49<01:44,  3.72it/s, loss=0.689]\u001b[A\n",
      " 31%|███       | 176/566 [00:50<01:44,  3.72it/s, loss=0.671]\u001b[A\n",
      " 31%|███▏      | 177/566 [00:50<01:44,  3.71it/s, loss=0.671]\u001b[A\n",
      " 31%|███▏      | 177/566 [00:50<01:44,  3.71it/s, loss=0.72] \u001b[A\n",
      " 31%|███▏      | 178/566 [00:50<01:44,  3.71it/s, loss=0.72]\u001b[A\n",
      " 31%|███▏      | 178/566 [00:50<01:44,  3.71it/s, loss=0.578]\u001b[A\n",
      " 32%|███▏      | 179/566 [00:50<01:44,  3.71it/s, loss=0.578]\u001b[A\n",
      " 32%|███▏      | 179/566 [00:51<01:44,  3.71it/s, loss=0.385]\u001b[A\n",
      " 32%|███▏      | 180/566 [00:51<01:44,  3.71it/s, loss=0.385]\u001b[A\n",
      " 32%|███▏      | 180/566 [00:51<01:44,  3.71it/s, loss=0.431]\u001b[A\n",
      " 32%|███▏      | 181/566 [00:51<01:43,  3.71it/s, loss=0.431]\u001b[A\n",
      " 32%|███▏      | 181/566 [00:51<01:43,  3.71it/s, loss=0.652]\u001b[A\n",
      " 32%|███▏      | 182/566 [00:51<01:43,  3.71it/s, loss=0.652]\u001b[A\n",
      " 32%|███▏      | 182/566 [00:51<01:43,  3.71it/s, loss=0.611]\u001b[A\n",
      " 32%|███▏      | 183/566 [00:51<01:42,  3.72it/s, loss=0.611]\u001b[A\n",
      " 32%|███▏      | 183/566 [00:52<01:42,  3.72it/s, loss=0.815]\u001b[A\n",
      " 33%|███▎      | 184/566 [00:52<01:42,  3.72it/s, loss=0.815]\u001b[A\n",
      " 33%|███▎      | 184/566 [00:52<01:42,  3.72it/s, loss=1.06] \u001b[A\n",
      " 33%|███▎      | 185/566 [00:52<01:42,  3.72it/s, loss=1.06]\u001b[A\n",
      " 33%|███▎      | 185/566 [00:52<01:42,  3.72it/s, loss=0.612]\u001b[A\n",
      " 33%|███▎      | 186/566 [00:52<01:42,  3.72it/s, loss=0.612]\u001b[A\n",
      " 33%|███▎      | 186/566 [00:52<01:42,  3.72it/s, loss=0.751]\u001b[A\n",
      " 33%|███▎      | 187/566 [00:52<01:41,  3.74it/s, loss=0.751]\u001b[A\n",
      " 33%|███▎      | 187/566 [00:53<01:41,  3.74it/s, loss=0.766]\u001b[A\n",
      " 33%|███▎      | 188/566 [00:53<01:41,  3.74it/s, loss=0.766]\u001b[A\n",
      " 33%|███▎      | 188/566 [00:53<01:41,  3.74it/s, loss=0.762]\u001b[A\n",
      " 33%|███▎      | 189/566 [00:53<01:40,  3.74it/s, loss=0.762]\u001b[A\n",
      " 33%|███▎      | 189/566 [00:53<01:40,  3.74it/s, loss=0.258]\u001b[A\n",
      " 34%|███▎      | 190/566 [00:53<01:40,  3.73it/s, loss=0.258]\u001b[A\n",
      " 34%|███▎      | 190/566 [00:54<01:40,  3.73it/s, loss=0.545]\u001b[A\n",
      " 34%|███▎      | 191/566 [00:54<01:40,  3.73it/s, loss=0.545]\u001b[A\n",
      " 34%|███▎      | 191/566 [00:54<01:40,  3.73it/s, loss=0.727]\u001b[A\n",
      " 34%|███▍      | 192/566 [00:54<01:40,  3.73it/s, loss=0.727]\u001b[A\n",
      " 34%|███▍      | 192/566 [00:54<01:40,  3.73it/s, loss=0.643]\u001b[A\n",
      " 34%|███▍      | 193/566 [00:54<01:39,  3.74it/s, loss=0.643]\u001b[A\n",
      " 34%|███▍      | 193/566 [00:54<01:39,  3.74it/s, loss=0.796]\u001b[A\n",
      " 34%|███▍      | 194/566 [00:54<01:39,  3.74it/s, loss=0.796]\u001b[A\n",
      " 34%|███▍      | 194/566 [00:55<01:39,  3.74it/s, loss=0.968]\u001b[A\n",
      " 34%|███▍      | 195/566 [00:55<01:39,  3.73it/s, loss=0.968]\u001b[A\n",
      " 34%|███▍      | 195/566 [00:55<01:39,  3.73it/s, loss=0.813]\u001b[A\n",
      " 35%|███▍      | 196/566 [00:55<01:38,  3.74it/s, loss=0.813]\u001b[A\n",
      " 35%|███▍      | 196/566 [00:55<01:38,  3.74it/s, loss=0.74] \u001b[A\n",
      " 35%|███▍      | 197/566 [00:55<01:38,  3.76it/s, loss=0.74]\u001b[A\n",
      " 35%|███▍      | 197/566 [00:55<01:38,  3.76it/s, loss=0.606]\u001b[A\n",
      " 35%|███▍      | 198/566 [00:55<01:37,  3.77it/s, loss=0.606]\u001b[A\n",
      " 35%|███▍      | 198/566 [00:56<01:37,  3.77it/s, loss=0.661]\u001b[A\n",
      " 35%|███▌      | 199/566 [00:56<01:37,  3.77it/s, loss=0.661]\u001b[A\n",
      " 35%|███▌      | 199/566 [00:56<01:37,  3.77it/s, loss=0.738]\u001b[A\n",
      " 35%|███▌      | 200/566 [00:56<01:36,  3.80it/s, loss=0.738]\u001b[A\n",
      " 35%|███▌      | 200/566 [00:56<01:36,  3.80it/s, loss=0.627]\u001b[A\n",
      " 36%|███▌      | 201/566 [00:56<01:37,  3.76it/s, loss=0.627]\u001b[A\n",
      " 36%|███▌      | 201/566 [00:56<01:37,  3.76it/s, loss=0.6]  \u001b[A\n",
      " 36%|███▌      | 202/566 [00:56<01:37,  3.74it/s, loss=0.6]\u001b[A\n",
      " 36%|███▌      | 202/566 [00:57<01:37,  3.74it/s, loss=1]  \u001b[A\n",
      " 36%|███▌      | 203/566 [00:57<01:36,  3.75it/s, loss=1]\u001b[A\n",
      " 36%|███▌      | 203/566 [00:57<01:36,  3.75it/s, loss=0.644]\u001b[A\n",
      " 36%|███▌      | 204/566 [00:57<01:36,  3.76it/s, loss=0.644]\u001b[A\n",
      " 36%|███▌      | 204/566 [00:57<01:36,  3.76it/s, loss=0.677]\u001b[A\n",
      " 36%|███▌      | 205/566 [00:57<01:36,  3.73it/s, loss=0.677]\u001b[A\n",
      " 36%|███▌      | 205/566 [00:58<01:36,  3.73it/s, loss=0.595]\u001b[A\n",
      " 36%|███▋      | 206/566 [00:58<01:36,  3.73it/s, loss=0.595]\u001b[A\n",
      " 36%|███▋      | 206/566 [00:58<01:36,  3.73it/s, loss=0.454]\u001b[A\n",
      " 37%|███▋      | 207/566 [00:58<01:35,  3.74it/s, loss=0.454]\u001b[A\n",
      " 37%|███▋      | 207/566 [00:58<01:35,  3.74it/s, loss=1.15] \u001b[A\n",
      " 37%|███▋      | 208/566 [00:58<01:35,  3.76it/s, loss=1.15]\u001b[A\n",
      " 37%|███▋      | 208/566 [00:58<01:35,  3.76it/s, loss=0.763]\u001b[A\n",
      " 37%|███▋      | 209/566 [00:58<01:35,  3.75it/s, loss=0.763]\u001b[A\n",
      " 37%|███▋      | 209/566 [00:59<01:35,  3.75it/s, loss=0.681]\u001b[A\n",
      " 37%|███▋      | 210/566 [00:59<01:34,  3.77it/s, loss=0.681]\u001b[A\n",
      " 37%|███▋      | 210/566 [00:59<01:34,  3.77it/s, loss=0.704]\u001b[A\n",
      " 37%|███▋      | 211/566 [00:59<01:34,  3.78it/s, loss=0.704]\u001b[A\n",
      " 37%|███▋      | 211/566 [00:59<01:34,  3.78it/s, loss=0.567]\u001b[A\n",
      " 37%|███▋      | 212/566 [00:59<01:33,  3.80it/s, loss=0.567]\u001b[A\n",
      " 37%|███▋      | 212/566 [00:59<01:33,  3.80it/s, loss=0.48] \u001b[A\n",
      " 38%|███▊      | 213/566 [00:59<01:33,  3.77it/s, loss=0.48]\u001b[A\n",
      " 38%|███▊      | 213/566 [01:00<01:33,  3.77it/s, loss=0.727]\u001b[A\n",
      " 38%|███▊      | 214/566 [01:00<01:33,  3.76it/s, loss=0.727]\u001b[A\n",
      " 38%|███▊      | 214/566 [01:00<01:33,  3.76it/s, loss=0.711]\u001b[A\n",
      " 38%|███▊      | 215/566 [01:00<01:33,  3.76it/s, loss=0.711]\u001b[A\n",
      " 38%|███▊      | 215/566 [01:00<01:33,  3.76it/s, loss=0.789]\u001b[A\n",
      " 38%|███▊      | 216/566 [01:00<01:32,  3.79it/s, loss=0.789]\u001b[A\n",
      " 38%|███▊      | 216/566 [01:00<01:32,  3.79it/s, loss=0.809]\u001b[A\n",
      " 38%|███▊      | 217/566 [01:00<01:32,  3.76it/s, loss=0.809]\u001b[A\n",
      " 38%|███▊      | 217/566 [01:01<01:32,  3.76it/s, loss=0.596]\u001b[A\n",
      " 39%|███▊      | 218/566 [01:01<01:32,  3.75it/s, loss=0.596]\u001b[A\n",
      " 39%|███▊      | 218/566 [01:01<01:32,  3.75it/s, loss=0.441]\u001b[A\n",
      " 39%|███▊      | 219/566 [01:01<01:32,  3.75it/s, loss=0.441]\u001b[A\n",
      " 39%|███▊      | 219/566 [01:01<01:32,  3.75it/s, loss=1.07] \u001b[A\n",
      " 39%|███▉      | 220/566 [01:01<01:31,  3.77it/s, loss=1.07]\u001b[A\n",
      " 39%|███▉      | 220/566 [01:02<01:31,  3.77it/s, loss=0.537]\u001b[A\n",
      " 39%|███▉      | 221/566 [01:02<01:31,  3.78it/s, loss=0.537]\u001b[A\n",
      " 39%|███▉      | 221/566 [01:02<01:31,  3.78it/s, loss=0.589]\u001b[A\n",
      " 39%|███▉      | 222/566 [01:02<01:30,  3.79it/s, loss=0.589]\u001b[A\n",
      " 39%|███▉      | 222/566 [01:02<01:30,  3.79it/s, loss=0.709]\u001b[A\n",
      " 39%|███▉      | 223/566 [01:02<01:30,  3.77it/s, loss=0.709]\u001b[A\n",
      " 39%|███▉      | 223/566 [01:02<01:30,  3.77it/s, loss=0.922]\u001b[A\n",
      " 40%|███▉      | 224/566 [01:02<01:30,  3.77it/s, loss=0.922]\u001b[A\n",
      " 40%|███▉      | 224/566 [01:03<01:30,  3.77it/s, loss=0.417]\u001b[A\n",
      " 40%|███▉      | 225/566 [01:03<01:30,  3.75it/s, loss=0.417]\u001b[A\n",
      " 40%|███▉      | 225/566 [01:03<01:30,  3.75it/s, loss=0.617]\u001b[A\n",
      " 40%|███▉      | 226/566 [01:03<01:29,  3.78it/s, loss=0.617]\u001b[A\n",
      " 40%|███▉      | 226/566 [01:03<01:29,  3.78it/s, loss=0.614]\u001b[A\n",
      " 40%|████      | 227/566 [01:03<01:29,  3.79it/s, loss=0.614]\u001b[A\n",
      " 40%|████      | 227/566 [01:03<01:29,  3.79it/s, loss=0.95] \u001b[A\n",
      " 40%|████      | 228/566 [01:03<01:29,  3.79it/s, loss=0.95]\u001b[A\n",
      " 40%|████      | 228/566 [01:04<01:29,  3.79it/s, loss=0.611]\u001b[A\n",
      " 40%|████      | 229/566 [01:04<01:29,  3.78it/s, loss=0.611]\u001b[A\n",
      " 40%|████      | 229/566 [01:04<01:29,  3.78it/s, loss=0.922]\u001b[A\n",
      " 41%|████      | 230/566 [01:04<01:28,  3.78it/s, loss=0.922]\u001b[A\n",
      " 41%|████      | 230/566 [01:04<01:28,  3.78it/s, loss=0.502]\u001b[A\n",
      " 41%|████      | 231/566 [01:04<01:28,  3.79it/s, loss=0.502]\u001b[A\n",
      " 41%|████      | 231/566 [01:04<01:28,  3.79it/s, loss=0.649]\u001b[A\n",
      " 41%|████      | 232/566 [01:04<01:28,  3.79it/s, loss=0.649]\u001b[A\n",
      " 41%|████      | 232/566 [01:05<01:28,  3.79it/s, loss=0.726]\u001b[A\n",
      " 41%|████      | 233/566 [01:05<01:27,  3.78it/s, loss=0.726]\u001b[A\n",
      " 41%|████      | 233/566 [01:05<01:27,  3.78it/s, loss=0.371]\u001b[A\n",
      " 41%|████▏     | 234/566 [01:05<01:27,  3.79it/s, loss=0.371]\u001b[A\n",
      " 41%|████▏     | 234/566 [01:05<01:27,  3.79it/s, loss=0.84] \u001b[A\n",
      " 42%|████▏     | 235/566 [01:05<01:27,  3.77it/s, loss=0.84]\u001b[A\n",
      " 42%|████▏     | 235/566 [01:05<01:27,  3.77it/s, loss=0.749]\u001b[A\n",
      " 42%|████▏     | 236/566 [01:05<01:27,  3.79it/s, loss=0.749]\u001b[A\n",
      " 42%|████▏     | 236/566 [01:06<01:27,  3.79it/s, loss=0.717]\u001b[A\n",
      " 42%|████▏     | 237/566 [01:06<01:26,  3.81it/s, loss=0.717]\u001b[A\n",
      " 42%|████▏     | 237/566 [01:06<01:26,  3.81it/s, loss=0.959]\u001b[A\n",
      " 42%|████▏     | 238/566 [01:06<01:26,  3.80it/s, loss=0.959]\u001b[A\n",
      " 42%|████▏     | 238/566 [01:06<01:26,  3.80it/s, loss=0.588]\u001b[A\n",
      " 42%|████▏     | 239/566 [01:06<01:26,  3.78it/s, loss=0.588]\u001b[A\n",
      " 42%|████▏     | 239/566 [01:07<01:26,  3.78it/s, loss=0.677]\u001b[A\n",
      " 42%|████▏     | 240/566 [01:07<01:26,  3.78it/s, loss=0.677]\u001b[A\n",
      " 42%|████▏     | 240/566 [01:07<01:26,  3.78it/s, loss=0.798]\u001b[A\n",
      " 43%|████▎     | 241/566 [01:07<01:25,  3.81it/s, loss=0.798]\u001b[A\n",
      " 43%|████▎     | 241/566 [01:07<01:25,  3.81it/s, loss=0.649]\u001b[A\n",
      " 43%|████▎     | 242/566 [01:07<01:25,  3.79it/s, loss=0.649]\u001b[A\n",
      " 43%|████▎     | 242/566 [01:07<01:25,  3.79it/s, loss=0.425]\u001b[A\n",
      " 43%|████▎     | 243/566 [01:07<01:24,  3.80it/s, loss=0.425]\u001b[A\n",
      " 43%|████▎     | 243/566 [01:08<01:24,  3.80it/s, loss=0.772]\u001b[A\n",
      " 43%|████▎     | 244/566 [01:08<01:26,  3.72it/s, loss=0.772]\u001b[A\n",
      " 43%|████▎     | 244/566 [01:08<01:26,  3.72it/s, loss=0.674]\u001b[A\n",
      " 43%|████▎     | 245/566 [01:08<01:29,  3.60it/s, loss=0.674]\u001b[A\n",
      " 43%|████▎     | 245/566 [01:08<01:29,  3.60it/s, loss=0.699]\u001b[A\n",
      " 43%|████▎     | 246/566 [01:08<01:36,  3.33it/s, loss=0.699]\u001b[A\n",
      " 43%|████▎     | 246/566 [01:09<01:36,  3.33it/s, loss=0.669]\u001b[A\n",
      " 44%|████▎     | 247/566 [01:09<01:38,  3.25it/s, loss=0.669]\u001b[A\n",
      " 44%|████▎     | 247/566 [01:09<01:38,  3.25it/s, loss=0.83] \u001b[A\n",
      " 44%|████▍     | 248/566 [01:09<01:40,  3.17it/s, loss=0.83]\u001b[A\n",
      " 44%|████▍     | 248/566 [01:09<01:40,  3.17it/s, loss=0.524]\u001b[A\n",
      " 44%|████▍     | 249/566 [01:09<01:39,  3.18it/s, loss=0.524]\u001b[A\n",
      " 44%|████▍     | 249/566 [01:10<01:39,  3.18it/s, loss=0.486]\u001b[A\n",
      " 44%|████▍     | 250/566 [01:10<01:37,  3.25it/s, loss=0.486]\u001b[A\n",
      " 44%|████▍     | 250/566 [01:10<01:37,  3.25it/s, loss=0.944]\u001b[A\n",
      " 44%|████▍     | 251/566 [01:10<01:33,  3.38it/s, loss=0.944]\u001b[A\n",
      " 44%|████▍     | 251/566 [01:10<01:33,  3.38it/s, loss=0.606]\u001b[A\n",
      " 45%|████▍     | 252/566 [01:10<01:37,  3.21it/s, loss=0.606]\u001b[A\n",
      " 45%|████▍     | 252/566 [01:10<01:37,  3.21it/s, loss=0.527]\u001b[A\n",
      " 45%|████▍     | 253/566 [01:10<01:40,  3.11it/s, loss=0.527]\u001b[A\n",
      " 45%|████▍     | 253/566 [01:11<01:40,  3.11it/s, loss=0.499]\u001b[A\n",
      " 45%|████▍     | 254/566 [01:11<01:36,  3.22it/s, loss=0.499]\u001b[A\n",
      " 45%|████▍     | 254/566 [01:11<01:36,  3.22it/s, loss=0.434]\u001b[A\n",
      " 45%|████▌     | 255/566 [01:11<01:33,  3.34it/s, loss=0.434]\u001b[A\n",
      " 45%|████▌     | 255/566 [01:11<01:33,  3.34it/s, loss=0.526]\u001b[A\n",
      " 45%|████▌     | 256/566 [01:11<01:29,  3.47it/s, loss=0.526]\u001b[A\n",
      " 45%|████▌     | 256/566 [01:12<01:29,  3.47it/s, loss=0.705]\u001b[A\n",
      " 45%|████▌     | 257/566 [01:12<01:27,  3.54it/s, loss=0.705]\u001b[A\n",
      " 45%|████▌     | 257/566 [01:12<01:27,  3.54it/s, loss=0.443]\u001b[A\n",
      " 46%|████▌     | 258/566 [01:12<01:25,  3.59it/s, loss=0.443]\u001b[A\n",
      " 46%|████▌     | 258/566 [01:12<01:25,  3.59it/s, loss=0.453]\u001b[A\n",
      " 46%|████▌     | 259/566 [01:12<01:24,  3.65it/s, loss=0.453]\u001b[A\n",
      " 46%|████▌     | 259/566 [01:12<01:24,  3.65it/s, loss=0.728]\u001b[A\n",
      " 46%|████▌     | 260/566 [01:12<01:23,  3.67it/s, loss=0.728]\u001b[A\n",
      " 46%|████▌     | 260/566 [01:13<01:23,  3.67it/s, loss=0.718]\u001b[A\n",
      " 46%|████▌     | 261/566 [01:13<01:22,  3.70it/s, loss=0.718]\u001b[A\n",
      " 46%|████▌     | 261/566 [01:13<01:22,  3.70it/s, loss=0.582]\u001b[A\n",
      " 46%|████▋     | 262/566 [01:13<01:21,  3.72it/s, loss=0.582]\u001b[A\n",
      " 46%|████▋     | 262/566 [01:13<01:21,  3.72it/s, loss=0.877]\u001b[A\n",
      " 46%|████▋     | 263/566 [01:13<01:22,  3.69it/s, loss=0.877]\u001b[A\n",
      " 46%|████▋     | 263/566 [01:13<01:22,  3.69it/s, loss=0.258]\u001b[A\n",
      " 47%|████▋     | 264/566 [01:13<01:20,  3.73it/s, loss=0.258]\u001b[A\n",
      " 47%|████▋     | 264/566 [01:14<01:20,  3.73it/s, loss=0.877]\u001b[A\n",
      " 47%|████▋     | 265/566 [01:14<01:21,  3.71it/s, loss=0.877]\u001b[A\n",
      " 47%|████▋     | 265/566 [01:14<01:21,  3.71it/s, loss=1.16] \u001b[A\n",
      " 47%|████▋     | 266/566 [01:14<01:20,  3.72it/s, loss=1.16]\u001b[A\n",
      " 47%|████▋     | 266/566 [01:14<01:20,  3.72it/s, loss=0.764]\u001b[A\n",
      " 47%|████▋     | 267/566 [01:14<01:19,  3.75it/s, loss=0.764]\u001b[A\n",
      " 47%|████▋     | 267/566 [01:14<01:19,  3.75it/s, loss=0.518]\u001b[A\n",
      " 47%|████▋     | 268/566 [01:14<01:19,  3.76it/s, loss=0.518]\u001b[A\n",
      " 47%|████▋     | 268/566 [01:15<01:19,  3.76it/s, loss=0.763]\u001b[A\n",
      " 48%|████▊     | 269/566 [01:15<01:18,  3.78it/s, loss=0.763]\u001b[A\n",
      " 48%|████▊     | 269/566 [01:15<01:18,  3.78it/s, loss=0.509]\u001b[A\n",
      " 48%|████▊     | 270/566 [01:15<01:18,  3.77it/s, loss=0.509]\u001b[A\n",
      " 48%|████▊     | 270/566 [01:15<01:18,  3.77it/s, loss=0.648]\u001b[A\n",
      " 48%|████▊     | 271/566 [01:15<01:18,  3.76it/s, loss=0.648]\u001b[A\n",
      " 48%|████▊     | 271/566 [01:16<01:18,  3.76it/s, loss=0.51] \u001b[A\n",
      " 48%|████▊     | 272/566 [01:16<01:18,  3.76it/s, loss=0.51]\u001b[A\n",
      " 48%|████▊     | 272/566 [01:16<01:18,  3.76it/s, loss=0.546]\u001b[A\n",
      " 48%|████▊     | 273/566 [01:16<01:17,  3.79it/s, loss=0.546]\u001b[A\n",
      " 48%|████▊     | 273/566 [01:16<01:17,  3.79it/s, loss=0.532]\u001b[A\n",
      " 48%|████▊     | 274/566 [01:16<01:17,  3.79it/s, loss=0.532]\u001b[A\n",
      " 48%|████▊     | 274/566 [01:16<01:17,  3.79it/s, loss=0.412]\u001b[A\n",
      " 49%|████▊     | 275/566 [01:16<01:17,  3.77it/s, loss=0.412]\u001b[A\n",
      " 49%|████▊     | 275/566 [01:17<01:17,  3.77it/s, loss=0.508]\u001b[A\n",
      " 49%|████▉     | 276/566 [01:17<01:16,  3.80it/s, loss=0.508]\u001b[A\n",
      " 49%|████▉     | 276/566 [01:17<01:16,  3.80it/s, loss=0.411]\u001b[A\n",
      " 49%|████▉     | 277/566 [01:17<01:16,  3.79it/s, loss=0.411]\u001b[A\n",
      " 49%|████▉     | 277/566 [01:17<01:16,  3.79it/s, loss=0.385]\u001b[A\n",
      " 49%|████▉     | 278/566 [01:17<01:15,  3.80it/s, loss=0.385]\u001b[A\n",
      " 49%|████▉     | 278/566 [01:17<01:15,  3.80it/s, loss=0.444]\u001b[A\n",
      " 49%|████▉     | 279/566 [01:17<01:15,  3.78it/s, loss=0.444]\u001b[A\n",
      " 49%|████▉     | 279/566 [01:18<01:15,  3.78it/s, loss=1.04] \u001b[A\n",
      " 49%|████▉     | 280/566 [01:18<01:15,  3.79it/s, loss=1.04]\u001b[A\n",
      " 49%|████▉     | 280/566 [01:18<01:15,  3.79it/s, loss=0.643]\u001b[A\n",
      " 50%|████▉     | 281/566 [01:18<01:15,  3.79it/s, loss=0.643]\u001b[A\n",
      " 50%|████▉     | 281/566 [01:18<01:15,  3.79it/s, loss=0.899]\u001b[A\n",
      " 50%|████▉     | 282/566 [01:18<01:14,  3.80it/s, loss=0.899]\u001b[A\n",
      " 50%|████▉     | 282/566 [01:18<01:14,  3.80it/s, loss=0.696]\u001b[A\n",
      " 50%|█████     | 283/566 [01:18<01:14,  3.80it/s, loss=0.696]\u001b[A\n",
      " 50%|█████     | 283/566 [01:19<01:14,  3.80it/s, loss=0.606]\u001b[A\n",
      " 50%|█████     | 284/566 [01:19<01:14,  3.79it/s, loss=0.606]\u001b[A\n",
      " 50%|█████     | 284/566 [01:19<01:14,  3.79it/s, loss=0.778]\u001b[A\n",
      " 50%|█████     | 285/566 [01:19<01:14,  3.80it/s, loss=0.778]\u001b[A\n",
      " 50%|█████     | 285/566 [01:19<01:14,  3.80it/s, loss=0.822]\u001b[A\n",
      " 51%|█████     | 286/566 [01:19<01:14,  3.78it/s, loss=0.822]\u001b[A\n",
      " 51%|█████     | 286/566 [01:20<01:14,  3.78it/s, loss=0.758]\u001b[A\n",
      " 51%|█████     | 287/566 [01:20<01:14,  3.76it/s, loss=0.758]\u001b[A\n",
      " 51%|█████     | 287/566 [01:20<01:14,  3.76it/s, loss=0.357]\u001b[A\n",
      " 51%|█████     | 288/566 [01:20<01:14,  3.75it/s, loss=0.357]\u001b[A\n",
      " 51%|█████     | 288/566 [01:20<01:14,  3.75it/s, loss=0.817]\u001b[A\n",
      " 51%|█████     | 289/566 [01:20<01:13,  3.75it/s, loss=0.817]\u001b[A\n",
      " 51%|█████     | 289/566 [01:20<01:13,  3.75it/s, loss=0.549]\u001b[A\n",
      " 51%|█████     | 290/566 [01:20<01:13,  3.75it/s, loss=0.549]\u001b[A\n",
      " 51%|█████     | 290/566 [01:21<01:13,  3.75it/s, loss=0.662]\u001b[A\n",
      " 51%|█████▏    | 291/566 [01:21<01:13,  3.75it/s, loss=0.662]\u001b[A\n",
      " 51%|█████▏    | 291/566 [01:21<01:13,  3.75it/s, loss=0.424]\u001b[A\n",
      " 52%|█████▏    | 292/566 [01:21<01:13,  3.72it/s, loss=0.424]\u001b[A\n",
      " 52%|█████▏    | 292/566 [01:21<01:13,  3.72it/s, loss=0.852]\u001b[A\n",
      " 52%|█████▏    | 293/566 [01:21<01:13,  3.73it/s, loss=0.852]\u001b[A\n",
      " 52%|█████▏    | 293/566 [01:21<01:13,  3.73it/s, loss=0.591]\u001b[A\n",
      " 52%|█████▏    | 294/566 [01:21<01:12,  3.74it/s, loss=0.591]\u001b[A\n",
      " 52%|█████▏    | 294/566 [01:22<01:12,  3.74it/s, loss=0.828]\u001b[A\n",
      " 52%|█████▏    | 295/566 [01:22<01:12,  3.74it/s, loss=0.828]\u001b[A\n",
      " 52%|█████▏    | 295/566 [01:22<01:12,  3.74it/s, loss=0.582]\u001b[A\n",
      " 52%|█████▏    | 296/566 [01:22<01:12,  3.72it/s, loss=0.582]\u001b[A\n",
      " 52%|█████▏    | 296/566 [01:22<01:12,  3.72it/s, loss=0.767]\u001b[A\n",
      " 52%|█████▏    | 297/566 [01:22<01:12,  3.73it/s, loss=0.767]\u001b[A\n",
      " 52%|█████▏    | 297/566 [01:22<01:12,  3.73it/s, loss=0.537]\u001b[A\n",
      " 53%|█████▎    | 298/566 [01:22<01:12,  3.72it/s, loss=0.537]\u001b[A\n",
      " 53%|█████▎    | 298/566 [01:23<01:12,  3.72it/s, loss=0.612]\u001b[A\n",
      " 53%|█████▎    | 299/566 [01:23<01:11,  3.73it/s, loss=0.612]\u001b[A\n",
      " 53%|█████▎    | 299/566 [01:23<01:11,  3.73it/s, loss=0.467]\u001b[A\n",
      " 53%|█████▎    | 300/566 [01:23<01:11,  3.74it/s, loss=0.467]\u001b[A\n",
      " 53%|█████▎    | 300/566 [01:23<01:11,  3.74it/s, loss=0.656]\u001b[A\n",
      " 53%|█████▎    | 301/566 [01:23<01:10,  3.74it/s, loss=0.656]\u001b[A\n",
      " 53%|█████▎    | 301/566 [01:24<01:10,  3.74it/s, loss=0.841]\u001b[A\n",
      " 53%|█████▎    | 302/566 [01:24<01:10,  3.74it/s, loss=0.841]\u001b[A\n",
      " 53%|█████▎    | 302/566 [01:24<01:10,  3.74it/s, loss=0.63] \u001b[A\n",
      " 54%|█████▎    | 303/566 [01:24<01:10,  3.75it/s, loss=0.63]\u001b[A\n",
      " 54%|█████▎    | 303/566 [01:24<01:10,  3.75it/s, loss=0.493]\u001b[A\n",
      " 54%|█████▎    | 304/566 [01:24<01:10,  3.74it/s, loss=0.493]\u001b[A\n",
      " 54%|█████▎    | 304/566 [01:24<01:10,  3.74it/s, loss=0.417]\u001b[A\n",
      " 54%|█████▍    | 305/566 [01:24<01:09,  3.78it/s, loss=0.417]\u001b[A\n",
      " 54%|█████▍    | 305/566 [01:25<01:09,  3.78it/s, loss=0.873]\u001b[A\n",
      " 54%|█████▍    | 306/566 [01:25<01:08,  3.78it/s, loss=0.873]\u001b[A\n",
      " 54%|█████▍    | 306/566 [01:25<01:08,  3.78it/s, loss=0.705]\u001b[A\n",
      " 54%|█████▍    | 307/566 [01:25<01:08,  3.77it/s, loss=0.705]\u001b[A\n",
      " 54%|█████▍    | 307/566 [01:25<01:08,  3.77it/s, loss=0.672]\u001b[A\n",
      " 54%|█████▍    | 308/566 [01:25<01:08,  3.77it/s, loss=0.672]\u001b[A\n",
      " 54%|█████▍    | 308/566 [01:25<01:08,  3.77it/s, loss=0.606]\u001b[A\n",
      " 55%|█████▍    | 309/566 [01:25<01:07,  3.79it/s, loss=0.606]\u001b[A\n",
      " 55%|█████▍    | 309/566 [01:26<01:07,  3.79it/s, loss=0.496]\u001b[A\n",
      " 55%|█████▍    | 310/566 [01:26<01:07,  3.77it/s, loss=0.496]\u001b[A\n",
      " 55%|█████▍    | 310/566 [01:26<01:07,  3.77it/s, loss=1.03] \u001b[A\n",
      " 55%|█████▍    | 311/566 [01:26<01:08,  3.75it/s, loss=1.03]\u001b[A\n",
      " 55%|█████▍    | 311/566 [01:26<01:08,  3.75it/s, loss=0.634]\u001b[A\n",
      " 55%|█████▌    | 312/566 [01:26<01:07,  3.75it/s, loss=0.634]\u001b[A\n",
      " 55%|█████▌    | 312/566 [01:26<01:07,  3.75it/s, loss=0.696]\u001b[A\n",
      " 55%|█████▌    | 313/566 [01:26<01:07,  3.77it/s, loss=0.696]\u001b[A\n",
      " 55%|█████▌    | 313/566 [01:27<01:07,  3.77it/s, loss=0.639]\u001b[A\n",
      " 55%|█████▌    | 314/566 [01:27<01:07,  3.74it/s, loss=0.639]\u001b[A\n",
      " 55%|█████▌    | 314/566 [01:27<01:07,  3.74it/s, loss=0.442]\u001b[A\n",
      " 56%|█████▌    | 315/566 [01:27<01:07,  3.72it/s, loss=0.442]\u001b[A\n",
      " 56%|█████▌    | 315/566 [01:27<01:07,  3.72it/s, loss=0.383]\u001b[A\n",
      " 56%|█████▌    | 316/566 [01:27<01:06,  3.73it/s, loss=0.383]\u001b[A\n",
      " 56%|█████▌    | 316/566 [01:28<01:06,  3.73it/s, loss=0.491]\u001b[A\n",
      " 56%|█████▌    | 317/566 [01:28<01:07,  3.71it/s, loss=0.491]\u001b[A\n",
      " 56%|█████▌    | 317/566 [01:28<01:07,  3.71it/s, loss=0.926]\u001b[A\n",
      " 56%|█████▌    | 318/566 [01:28<01:06,  3.73it/s, loss=0.926]\u001b[A\n",
      " 56%|█████▌    | 318/566 [01:28<01:06,  3.73it/s, loss=0.365]\u001b[A\n",
      " 56%|█████▋    | 319/566 [01:28<01:06,  3.72it/s, loss=0.365]\u001b[A\n",
      " 56%|█████▋    | 319/566 [01:28<01:06,  3.72it/s, loss=0.566]\u001b[A\n",
      " 57%|█████▋    | 320/566 [01:28<01:05,  3.74it/s, loss=0.566]\u001b[A\n",
      " 57%|█████▋    | 320/566 [01:29<01:05,  3.74it/s, loss=0.692]\u001b[A\n",
      " 57%|█████▋    | 321/566 [01:29<01:05,  3.74it/s, loss=0.692]\u001b[A\n",
      " 57%|█████▋    | 321/566 [01:29<01:05,  3.74it/s, loss=0.973]\u001b[A\n",
      " 57%|█████▋    | 322/566 [01:29<01:05,  3.75it/s, loss=0.973]\u001b[A\n",
      " 57%|█████▋    | 322/566 [01:29<01:05,  3.75it/s, loss=0.467]\u001b[A\n",
      " 57%|█████▋    | 323/566 [01:29<01:04,  3.76it/s, loss=0.467]\u001b[A\n",
      " 57%|█████▋    | 323/566 [01:29<01:04,  3.76it/s, loss=0.725]\u001b[A\n",
      " 57%|█████▋    | 324/566 [01:29<01:04,  3.75it/s, loss=0.725]\u001b[A\n",
      " 57%|█████▋    | 324/566 [01:30<01:04,  3.75it/s, loss=0.399]\u001b[A\n",
      " 57%|█████▋    | 325/566 [01:30<01:04,  3.73it/s, loss=0.399]\u001b[A\n",
      " 57%|█████▋    | 325/566 [01:30<01:04,  3.73it/s, loss=0.733]\u001b[A\n",
      " 58%|█████▊    | 326/566 [01:30<01:04,  3.74it/s, loss=0.733]\u001b[A\n",
      " 58%|█████▊    | 326/566 [01:30<01:04,  3.74it/s, loss=0.826]\u001b[A\n",
      " 58%|█████▊    | 327/566 [01:30<01:03,  3.74it/s, loss=0.826]\u001b[A\n",
      " 58%|█████▊    | 327/566 [01:30<01:03,  3.74it/s, loss=0.405]\u001b[A\n",
      " 58%|█████▊    | 328/566 [01:30<01:03,  3.74it/s, loss=0.405]\u001b[A\n",
      " 58%|█████▊    | 328/566 [01:31<01:03,  3.74it/s, loss=0.493]\u001b[A\n",
      " 58%|█████▊    | 329/566 [01:31<01:03,  3.74it/s, loss=0.493]\u001b[A\n",
      " 58%|█████▊    | 329/566 [01:31<01:03,  3.74it/s, loss=0.42] \u001b[A\n",
      " 58%|█████▊    | 330/566 [01:31<01:03,  3.74it/s, loss=0.42]\u001b[A\n",
      " 58%|█████▊    | 330/566 [01:31<01:03,  3.74it/s, loss=0.738]\u001b[A\n",
      " 58%|█████▊    | 331/566 [01:31<01:03,  3.73it/s, loss=0.738]\u001b[A\n",
      " 58%|█████▊    | 331/566 [01:32<01:03,  3.73it/s, loss=0.769]\u001b[A\n",
      " 59%|█████▊    | 332/566 [01:32<01:02,  3.73it/s, loss=0.769]\u001b[A\n",
      " 59%|█████▊    | 332/566 [01:32<01:02,  3.73it/s, loss=0.602]\u001b[A\n",
      " 59%|█████▉    | 333/566 [01:32<01:02,  3.72it/s, loss=0.602]\u001b[A\n",
      " 59%|█████▉    | 333/566 [01:32<01:02,  3.72it/s, loss=0.725]\u001b[A\n",
      " 59%|█████▉    | 334/566 [01:32<01:02,  3.72it/s, loss=0.725]\u001b[A\n",
      " 59%|█████▉    | 334/566 [01:32<01:02,  3.72it/s, loss=0.874]\u001b[A\n",
      " 59%|█████▉    | 335/566 [01:32<01:02,  3.72it/s, loss=0.874]\u001b[A\n",
      " 59%|█████▉    | 335/566 [01:33<01:02,  3.72it/s, loss=0.693]\u001b[A\n",
      " 59%|█████▉    | 336/566 [01:33<01:01,  3.72it/s, loss=0.693]\u001b[A\n",
      " 59%|█████▉    | 336/566 [01:33<01:01,  3.72it/s, loss=0.586]\u001b[A\n",
      " 60%|█████▉    | 337/566 [01:33<01:01,  3.70it/s, loss=0.586]\u001b[A\n",
      " 60%|█████▉    | 337/566 [01:33<01:01,  3.70it/s, loss=0.907]\u001b[A\n",
      " 60%|█████▉    | 338/566 [01:33<01:01,  3.68it/s, loss=0.907]\u001b[A\n",
      " 60%|█████▉    | 338/566 [01:33<01:01,  3.68it/s, loss=0.583]\u001b[A\n",
      " 60%|█████▉    | 339/566 [01:33<01:01,  3.72it/s, loss=0.583]\u001b[A\n",
      " 60%|█████▉    | 339/566 [01:34<01:01,  3.72it/s, loss=0.523]\u001b[A\n",
      " 60%|██████    | 340/566 [01:34<01:00,  3.71it/s, loss=0.523]\u001b[A\n",
      " 60%|██████    | 340/566 [01:34<01:00,  3.71it/s, loss=0.972]\u001b[A\n",
      " 60%|██████    | 341/566 [01:34<01:00,  3.71it/s, loss=0.972]\u001b[A\n",
      " 60%|██████    | 341/566 [01:34<01:00,  3.71it/s, loss=0.532]\u001b[A\n",
      " 60%|██████    | 342/566 [01:34<01:00,  3.71it/s, loss=0.532]\u001b[A\n",
      " 60%|██████    | 342/566 [01:35<01:00,  3.71it/s, loss=0.737]\u001b[A\n",
      " 61%|██████    | 343/566 [01:35<01:00,  3.69it/s, loss=0.737]\u001b[A\n",
      " 61%|██████    | 343/566 [01:35<01:00,  3.69it/s, loss=1.04] \u001b[A\n",
      " 61%|██████    | 344/566 [01:35<00:59,  3.71it/s, loss=1.04]\u001b[A\n",
      " 61%|██████    | 344/566 [01:35<00:59,  3.71it/s, loss=0.619]\u001b[A\n",
      " 61%|██████    | 345/566 [01:35<00:59,  3.72it/s, loss=0.619]\u001b[A\n",
      " 61%|██████    | 345/566 [01:35<00:59,  3.72it/s, loss=0.742]\u001b[A\n",
      " 61%|██████    | 346/566 [01:35<00:59,  3.70it/s, loss=0.742]\u001b[A\n",
      " 61%|██████    | 346/566 [01:36<00:59,  3.70it/s, loss=0.683]\u001b[A\n",
      " 61%|██████▏   | 347/566 [01:36<00:59,  3.71it/s, loss=0.683]\u001b[A\n",
      " 61%|██████▏   | 347/566 [01:36<00:59,  3.71it/s, loss=0.938]\u001b[A\n",
      " 61%|██████▏   | 348/566 [01:36<00:58,  3.70it/s, loss=0.938]\u001b[A\n",
      " 61%|██████▏   | 348/566 [01:36<00:58,  3.70it/s, loss=0.781]\u001b[A\n",
      " 62%|██████▏   | 349/566 [01:36<00:58,  3.68it/s, loss=0.781]\u001b[A\n",
      " 62%|██████▏   | 349/566 [01:36<00:58,  3.68it/s, loss=0.554]\u001b[A\n",
      " 62%|██████▏   | 350/566 [01:36<00:58,  3.69it/s, loss=0.554]\u001b[A\n",
      " 62%|██████▏   | 350/566 [01:37<00:58,  3.69it/s, loss=0.907]\u001b[A\n",
      " 62%|██████▏   | 351/566 [01:37<00:58,  3.70it/s, loss=0.907]\u001b[A\n",
      " 62%|██████▏   | 351/566 [01:37<00:58,  3.70it/s, loss=0.893]\u001b[A\n",
      " 62%|██████▏   | 352/566 [01:37<00:58,  3.67it/s, loss=0.893]\u001b[A\n",
      " 62%|██████▏   | 352/566 [01:37<00:58,  3.67it/s, loss=0.847]\u001b[A\n",
      " 62%|██████▏   | 353/566 [01:37<00:58,  3.67it/s, loss=0.847]\u001b[A\n",
      " 62%|██████▏   | 353/566 [01:37<00:58,  3.67it/s, loss=0.52] \u001b[A\n",
      " 63%|██████▎   | 354/566 [01:37<00:57,  3.70it/s, loss=0.52]\u001b[A\n",
      " 63%|██████▎   | 354/566 [01:38<00:57,  3.70it/s, loss=0.959]\u001b[A\n",
      " 63%|██████▎   | 355/566 [01:38<00:56,  3.70it/s, loss=0.959]\u001b[A\n",
      " 63%|██████▎   | 355/566 [01:38<00:56,  3.70it/s, loss=0.736]\u001b[A\n",
      " 63%|██████▎   | 356/566 [01:38<00:56,  3.71it/s, loss=0.736]\u001b[A\n",
      " 63%|██████▎   | 356/566 [01:38<00:56,  3.71it/s, loss=0.51] \u001b[A\n",
      " 63%|██████▎   | 357/566 [01:38<00:56,  3.70it/s, loss=0.51]\u001b[A\n",
      " 63%|██████▎   | 357/566 [01:39<00:56,  3.70it/s, loss=0.613]\u001b[A\n",
      " 63%|██████▎   | 358/566 [01:39<00:56,  3.70it/s, loss=0.613]\u001b[A\n",
      " 63%|██████▎   | 358/566 [01:39<00:56,  3.70it/s, loss=1.39] \u001b[A\n",
      " 63%|██████▎   | 359/566 [01:39<00:55,  3.71it/s, loss=1.39]\u001b[A\n",
      " 63%|██████▎   | 359/566 [01:39<00:55,  3.71it/s, loss=0.771]\u001b[A\n",
      " 64%|██████▎   | 360/566 [01:39<00:55,  3.68it/s, loss=0.771]\u001b[A\n",
      " 64%|██████▎   | 360/566 [01:39<00:55,  3.68it/s, loss=1.08] \u001b[A\n",
      " 64%|██████▍   | 361/566 [01:39<00:55,  3.70it/s, loss=1.08]\u001b[A\n",
      " 64%|██████▍   | 361/566 [01:40<00:55,  3.70it/s, loss=0.507]\u001b[A\n",
      " 64%|██████▍   | 362/566 [01:40<00:55,  3.69it/s, loss=0.507]\u001b[A\n",
      " 64%|██████▍   | 362/566 [01:40<00:55,  3.69it/s, loss=0.976]\u001b[A\n",
      " 64%|██████▍   | 363/566 [01:40<00:54,  3.71it/s, loss=0.976]\u001b[A\n",
      " 64%|██████▍   | 363/566 [01:40<00:54,  3.71it/s, loss=0.645]\u001b[A\n",
      " 64%|██████▍   | 364/566 [01:40<00:54,  3.71it/s, loss=0.645]\u001b[A\n",
      " 64%|██████▍   | 364/566 [01:40<00:54,  3.71it/s, loss=0.812]\u001b[A\n",
      " 64%|██████▍   | 365/566 [01:40<00:54,  3.72it/s, loss=0.812]\u001b[A\n",
      " 64%|██████▍   | 365/566 [01:41<00:54,  3.72it/s, loss=0.708]\u001b[A\n",
      " 65%|██████▍   | 366/566 [01:41<00:53,  3.71it/s, loss=0.708]\u001b[A\n",
      " 65%|██████▍   | 366/566 [01:41<00:53,  3.71it/s, loss=0.608]\u001b[A\n",
      " 65%|██████▍   | 367/566 [01:41<00:53,  3.70it/s, loss=0.608]\u001b[A\n",
      " 65%|██████▍   | 367/566 [01:41<00:53,  3.70it/s, loss=0.859]\u001b[A\n",
      " 65%|██████▌   | 368/566 [01:41<00:53,  3.71it/s, loss=0.859]\u001b[A\n",
      " 65%|██████▌   | 368/566 [01:42<00:53,  3.71it/s, loss=0.631]\u001b[A\n",
      " 65%|██████▌   | 369/566 [01:42<00:53,  3.70it/s, loss=0.631]\u001b[A\n",
      " 65%|██████▌   | 369/566 [01:42<00:53,  3.70it/s, loss=1.07] \u001b[A\n",
      " 65%|██████▌   | 370/566 [01:42<00:52,  3.70it/s, loss=1.07]\u001b[A\n",
      " 65%|██████▌   | 370/566 [01:42<00:52,  3.70it/s, loss=0.72]\u001b[A\n",
      " 66%|██████▌   | 371/566 [01:42<00:52,  3.71it/s, loss=0.72]\u001b[A\n",
      " 66%|██████▌   | 371/566 [01:42<00:52,  3.71it/s, loss=0.687]\u001b[A\n",
      " 66%|██████▌   | 372/566 [01:42<00:52,  3.70it/s, loss=0.687]\u001b[A\n",
      " 66%|██████▌   | 372/566 [01:43<00:52,  3.70it/s, loss=0.619]\u001b[A\n",
      " 66%|██████▌   | 373/566 [01:43<00:52,  3.71it/s, loss=0.619]\u001b[A\n",
      " 66%|██████▌   | 373/566 [01:43<00:52,  3.71it/s, loss=0.454]\u001b[A\n",
      " 66%|██████▌   | 374/566 [01:43<00:51,  3.71it/s, loss=0.454]\u001b[A\n",
      " 66%|██████▌   | 374/566 [01:43<00:51,  3.71it/s, loss=0.722]\u001b[A\n",
      " 66%|██████▋   | 375/566 [01:43<00:51,  3.71it/s, loss=0.722]\u001b[A\n",
      " 66%|██████▋   | 375/566 [01:43<00:51,  3.71it/s, loss=0.767]\u001b[A\n",
      " 66%|██████▋   | 376/566 [01:43<00:51,  3.70it/s, loss=0.767]\u001b[A\n",
      " 66%|██████▋   | 376/566 [01:44<00:51,  3.70it/s, loss=0.804]\u001b[A\n",
      " 67%|██████▋   | 377/566 [01:44<00:51,  3.67it/s, loss=0.804]\u001b[A\n",
      " 67%|██████▋   | 377/566 [01:44<00:51,  3.67it/s, loss=0.61] \u001b[A\n",
      " 67%|██████▋   | 378/566 [01:44<00:51,  3.67it/s, loss=0.61]\u001b[A\n",
      " 67%|██████▋   | 378/566 [01:44<00:51,  3.67it/s, loss=0.627]\u001b[A\n",
      " 67%|██████▋   | 379/566 [01:44<00:51,  3.65it/s, loss=0.627]\u001b[A\n",
      " 67%|██████▋   | 379/566 [01:45<00:51,  3.65it/s, loss=0.432]\u001b[A\n",
      " 67%|██████▋   | 380/566 [01:45<00:50,  3.66it/s, loss=0.432]\u001b[A\n",
      " 67%|██████▋   | 380/566 [01:45<00:50,  3.66it/s, loss=0.536]\u001b[A\n",
      " 67%|██████▋   | 381/566 [01:45<00:50,  3.67it/s, loss=0.536]\u001b[A\n",
      " 67%|██████▋   | 381/566 [01:45<00:50,  3.67it/s, loss=0.74] \u001b[A\n",
      " 67%|██████▋   | 382/566 [01:45<00:49,  3.69it/s, loss=0.74]\u001b[A\n",
      " 67%|██████▋   | 382/566 [01:45<00:49,  3.69it/s, loss=0.866]\u001b[A\n",
      " 68%|██████▊   | 383/566 [01:45<00:49,  3.70it/s, loss=0.866]\u001b[A\n",
      " 68%|██████▊   | 383/566 [01:46<00:49,  3.70it/s, loss=0.644]\u001b[A\n",
      " 68%|██████▊   | 384/566 [01:46<00:49,  3.65it/s, loss=0.644]\u001b[A\n",
      " 68%|██████▊   | 384/566 [01:46<00:49,  3.65it/s, loss=0.991]\u001b[A\n",
      " 68%|██████▊   | 385/566 [01:46<00:49,  3.65it/s, loss=0.991]\u001b[A\n",
      " 68%|██████▊   | 385/566 [01:46<00:49,  3.65it/s, loss=0.456]\u001b[A\n",
      " 68%|██████▊   | 386/566 [01:46<00:49,  3.66it/s, loss=0.456]\u001b[A\n",
      " 68%|██████▊   | 386/566 [01:46<00:49,  3.66it/s, loss=0.663]\u001b[A\n",
      " 68%|██████▊   | 387/566 [01:46<00:48,  3.67it/s, loss=0.663]\u001b[A\n",
      " 68%|██████▊   | 387/566 [01:47<00:48,  3.67it/s, loss=0.805]\u001b[A\n",
      " 69%|██████▊   | 388/566 [01:47<00:48,  3.66it/s, loss=0.805]\u001b[A\n",
      " 69%|██████▊   | 388/566 [01:47<00:48,  3.66it/s, loss=0.407]\u001b[A\n",
      " 69%|██████▊   | 389/566 [01:47<00:48,  3.65it/s, loss=0.407]\u001b[A\n",
      " 69%|██████▊   | 389/566 [01:47<00:48,  3.65it/s, loss=0.631]\u001b[A\n",
      " 69%|██████▉   | 390/566 [01:47<00:48,  3.66it/s, loss=0.631]\u001b[A\n",
      " 69%|██████▉   | 390/566 [01:48<00:48,  3.66it/s, loss=0.775]\u001b[A\n",
      " 69%|██████▉   | 391/566 [01:48<00:47,  3.65it/s, loss=0.775]\u001b[A\n",
      " 69%|██████▉   | 391/566 [01:48<00:47,  3.65it/s, loss=0.468]\u001b[A\n",
      " 69%|██████▉   | 392/566 [01:48<00:47,  3.65it/s, loss=0.468]\u001b[A\n",
      " 69%|██████▉   | 392/566 [01:48<00:47,  3.65it/s, loss=0.714]\u001b[A\n",
      " 69%|██████▉   | 393/566 [01:48<00:47,  3.65it/s, loss=0.714]\u001b[A\n",
      " 69%|██████▉   | 393/566 [01:48<00:47,  3.65it/s, loss=0.434]\u001b[A\n",
      " 70%|██████▉   | 394/566 [01:48<00:47,  3.65it/s, loss=0.434]\u001b[A\n",
      " 70%|██████▉   | 394/566 [01:49<00:47,  3.65it/s, loss=0.614]\u001b[A\n",
      " 70%|██████▉   | 395/566 [01:49<00:46,  3.66it/s, loss=0.614]\u001b[A\n",
      " 70%|██████▉   | 395/566 [01:49<00:46,  3.66it/s, loss=0.338]\u001b[A\n",
      " 70%|██████▉   | 396/566 [01:49<00:46,  3.67it/s, loss=0.338]\u001b[A\n",
      " 70%|██████▉   | 396/566 [01:49<00:46,  3.67it/s, loss=0.534]\u001b[A\n",
      " 70%|███████   | 397/566 [01:49<00:46,  3.65it/s, loss=0.534]\u001b[A\n",
      " 70%|███████   | 397/566 [01:49<00:46,  3.65it/s, loss=0.601]\u001b[A\n",
      " 70%|███████   | 398/566 [01:49<00:45,  3.66it/s, loss=0.601]\u001b[A\n",
      " 70%|███████   | 398/566 [01:50<00:45,  3.66it/s, loss=0.413]\u001b[A\n",
      " 70%|███████   | 399/566 [01:50<00:45,  3.65it/s, loss=0.413]\u001b[A\n",
      " 70%|███████   | 399/566 [01:50<00:45,  3.65it/s, loss=0.733]\u001b[A\n",
      " 71%|███████   | 400/566 [01:50<00:45,  3.68it/s, loss=0.733]\u001b[A\n",
      " 71%|███████   | 400/566 [01:50<00:45,  3.68it/s, loss=0.883]\u001b[A\n",
      " 71%|███████   | 401/566 [01:50<00:45,  3.66it/s, loss=0.883]\u001b[A\n",
      " 71%|███████   | 401/566 [01:51<00:45,  3.66it/s, loss=0.66] \u001b[A\n",
      " 71%|███████   | 402/566 [01:51<00:44,  3.67it/s, loss=0.66]\u001b[A\n",
      " 71%|███████   | 402/566 [01:51<00:44,  3.67it/s, loss=0.424]\u001b[A\n",
      " 71%|███████   | 403/566 [01:51<00:44,  3.65it/s, loss=0.424]\u001b[A\n",
      " 71%|███████   | 403/566 [01:51<00:44,  3.65it/s, loss=0.837]\u001b[A\n",
      " 71%|███████▏  | 404/566 [01:51<00:44,  3.68it/s, loss=0.837]\u001b[A\n",
      " 71%|███████▏  | 404/566 [01:51<00:44,  3.68it/s, loss=0.527]\u001b[A\n",
      " 72%|███████▏  | 405/566 [01:51<00:43,  3.67it/s, loss=0.527]\u001b[A\n",
      " 72%|███████▏  | 405/566 [01:52<00:43,  3.67it/s, loss=0.619]\u001b[A\n",
      " 72%|███████▏  | 406/566 [01:52<00:43,  3.66it/s, loss=0.619]\u001b[A\n",
      " 72%|███████▏  | 406/566 [01:52<00:43,  3.66it/s, loss=0.542]\u001b[A\n",
      " 72%|███████▏  | 407/566 [01:52<00:43,  3.64it/s, loss=0.542]\u001b[A\n",
      " 72%|███████▏  | 407/566 [01:52<00:43,  3.64it/s, loss=0.595]\u001b[A\n",
      " 72%|███████▏  | 408/566 [01:52<00:43,  3.65it/s, loss=0.595]\u001b[A\n",
      " 72%|███████▏  | 408/566 [01:52<00:43,  3.65it/s, loss=0.548]\u001b[A\n",
      " 72%|███████▏  | 409/566 [01:52<00:43,  3.64it/s, loss=0.548]\u001b[A\n",
      " 72%|███████▏  | 409/566 [01:53<00:43,  3.64it/s, loss=0.706]\u001b[A\n",
      " 72%|███████▏  | 410/566 [01:53<00:42,  3.66it/s, loss=0.706]\u001b[A\n",
      " 72%|███████▏  | 410/566 [01:53<00:42,  3.66it/s, loss=0.66] \u001b[A\n",
      " 73%|███████▎  | 411/566 [01:53<00:42,  3.65it/s, loss=0.66]\u001b[A\n",
      " 73%|███████▎  | 411/566 [01:53<00:42,  3.65it/s, loss=0.479]\u001b[A\n",
      " 73%|███████▎  | 412/566 [01:53<00:41,  3.68it/s, loss=0.479]\u001b[A\n",
      " 73%|███████▎  | 412/566 [01:54<00:41,  3.68it/s, loss=0.605]\u001b[A\n",
      " 73%|███████▎  | 413/566 [01:54<00:41,  3.69it/s, loss=0.605]\u001b[A\n",
      " 73%|███████▎  | 413/566 [01:54<00:41,  3.69it/s, loss=0.498]\u001b[A\n",
      " 73%|███████▎  | 414/566 [01:54<00:41,  3.69it/s, loss=0.498]\u001b[A\n",
      " 73%|███████▎  | 414/566 [01:54<00:41,  3.69it/s, loss=0.634]\u001b[A\n",
      " 73%|███████▎  | 415/566 [01:54<00:40,  3.69it/s, loss=0.634]\u001b[A\n",
      " 73%|███████▎  | 415/566 [01:54<00:40,  3.69it/s, loss=0.65] \u001b[A\n",
      " 73%|███████▎  | 416/566 [01:54<00:40,  3.68it/s, loss=0.65]\u001b[A\n",
      " 73%|███████▎  | 416/566 [01:55<00:40,  3.68it/s, loss=0.623]\u001b[A\n",
      " 74%|███████▎  | 417/566 [01:55<00:40,  3.68it/s, loss=0.623]\u001b[A\n",
      " 74%|███████▎  | 417/566 [01:55<00:40,  3.68it/s, loss=0.801]\u001b[A\n",
      " 74%|███████▍  | 418/566 [01:55<00:40,  3.69it/s, loss=0.801]\u001b[A\n",
      " 74%|███████▍  | 418/566 [01:55<00:40,  3.69it/s, loss=0.433]\u001b[A\n",
      " 74%|███████▍  | 419/566 [01:55<00:39,  3.68it/s, loss=0.433]\u001b[A\n",
      " 74%|███████▍  | 419/566 [01:55<00:39,  3.68it/s, loss=0.447]\u001b[A\n",
      " 74%|███████▍  | 420/566 [01:55<00:39,  3.65it/s, loss=0.447]\u001b[A\n",
      " 74%|███████▍  | 420/566 [01:56<00:39,  3.65it/s, loss=0.768]\u001b[A\n",
      " 74%|███████▍  | 421/566 [01:56<00:39,  3.65it/s, loss=0.768]\u001b[A\n",
      " 74%|███████▍  | 421/566 [01:56<00:39,  3.65it/s, loss=0.817]\u001b[A\n",
      " 75%|███████▍  | 422/566 [01:56<00:39,  3.66it/s, loss=0.817]\u001b[A\n",
      " 75%|███████▍  | 422/566 [01:56<00:39,  3.66it/s, loss=0.795]\u001b[A\n",
      " 75%|███████▍  | 423/566 [01:56<00:38,  3.68it/s, loss=0.795]\u001b[A\n",
      " 75%|███████▍  | 423/566 [01:57<00:38,  3.68it/s, loss=0.643]\u001b[A\n",
      " 75%|███████▍  | 424/566 [01:57<00:38,  3.68it/s, loss=0.643]\u001b[A\n",
      " 75%|███████▍  | 424/566 [01:57<00:38,  3.68it/s, loss=0.547]\u001b[A\n",
      " 75%|███████▌  | 425/566 [01:57<00:38,  3.68it/s, loss=0.547]\u001b[A\n",
      " 75%|███████▌  | 425/566 [01:57<00:38,  3.68it/s, loss=0.506]\u001b[A\n",
      " 75%|███████▌  | 426/566 [01:57<00:38,  3.66it/s, loss=0.506]\u001b[A\n",
      " 75%|███████▌  | 426/566 [01:57<00:38,  3.66it/s, loss=0.585]\u001b[A\n",
      " 75%|███████▌  | 427/566 [01:57<00:37,  3.66it/s, loss=0.585]\u001b[A\n",
      " 75%|███████▌  | 427/566 [01:58<00:37,  3.66it/s, loss=0.895]\u001b[A\n",
      " 76%|███████▌  | 428/566 [01:58<00:37,  3.66it/s, loss=0.895]\u001b[A\n",
      " 76%|███████▌  | 428/566 [01:58<00:37,  3.66it/s, loss=0.447]\u001b[A\n",
      " 76%|███████▌  | 429/566 [01:58<00:37,  3.63it/s, loss=0.447]\u001b[A\n",
      " 76%|███████▌  | 429/566 [01:58<00:37,  3.63it/s, loss=0.489]\u001b[A\n",
      " 76%|███████▌  | 430/566 [01:58<00:37,  3.67it/s, loss=0.489]\u001b[A\n",
      " 76%|███████▌  | 430/566 [01:58<00:37,  3.67it/s, loss=0.517]\u001b[A\n",
      " 76%|███████▌  | 431/566 [01:58<00:36,  3.66it/s, loss=0.517]\u001b[A\n",
      " 76%|███████▌  | 431/566 [01:59<00:36,  3.66it/s, loss=1.21] \u001b[A\n",
      " 76%|███████▋  | 432/566 [01:59<00:36,  3.67it/s, loss=1.21]\u001b[A\n",
      " 76%|███████▋  | 432/566 [01:59<00:36,  3.67it/s, loss=0.702]\u001b[A\n",
      " 77%|███████▋  | 433/566 [01:59<00:36,  3.66it/s, loss=0.702]\u001b[A\n",
      " 77%|███████▋  | 433/566 [01:59<00:36,  3.66it/s, loss=0.678]\u001b[A\n",
      " 77%|███████▋  | 434/566 [01:59<00:36,  3.67it/s, loss=0.678]\u001b[A\n",
      " 77%|███████▋  | 434/566 [02:00<00:36,  3.67it/s, loss=0.703]\u001b[A\n",
      " 77%|███████▋  | 435/566 [02:00<00:35,  3.65it/s, loss=0.703]\u001b[A\n",
      " 77%|███████▋  | 435/566 [02:00<00:35,  3.65it/s, loss=0.51] \u001b[A\n",
      " 77%|███████▋  | 436/566 [02:00<00:35,  3.67it/s, loss=0.51]\u001b[A\n",
      " 77%|███████▋  | 436/566 [02:00<00:35,  3.67it/s, loss=0.417]\u001b[A\n",
      " 77%|███████▋  | 437/566 [02:00<00:35,  3.67it/s, loss=0.417]\u001b[A\n",
      " 77%|███████▋  | 437/566 [02:00<00:35,  3.67it/s, loss=0.916]\u001b[A\n",
      " 77%|███████▋  | 438/566 [02:00<00:34,  3.68it/s, loss=0.916]\u001b[A\n",
      " 77%|███████▋  | 438/566 [02:01<00:34,  3.68it/s, loss=0.645]\u001b[A\n",
      " 78%|███████▊  | 439/566 [02:01<00:34,  3.67it/s, loss=0.645]\u001b[A\n",
      " 78%|███████▊  | 439/566 [02:01<00:34,  3.67it/s, loss=0.744]\u001b[A\n",
      " 78%|███████▊  | 440/566 [02:01<00:34,  3.67it/s, loss=0.744]\u001b[A\n",
      " 78%|███████▊  | 440/566 [02:01<00:34,  3.67it/s, loss=0.587]\u001b[A\n",
      " 78%|███████▊  | 441/566 [02:01<00:33,  3.68it/s, loss=0.587]\u001b[A\n",
      " 78%|███████▊  | 441/566 [02:01<00:33,  3.68it/s, loss=0.641]\u001b[A\n",
      " 78%|███████▊  | 442/566 [02:01<00:33,  3.69it/s, loss=0.641]\u001b[A\n",
      " 78%|███████▊  | 442/566 [02:02<00:33,  3.69it/s, loss=0.603]\u001b[A\n",
      " 78%|███████▊  | 443/566 [02:02<00:33,  3.68it/s, loss=0.603]\u001b[A\n",
      " 78%|███████▊  | 443/566 [02:02<00:33,  3.68it/s, loss=0.618]\u001b[A\n",
      " 78%|███████▊  | 444/566 [02:02<00:33,  3.66it/s, loss=0.618]\u001b[A\n",
      " 78%|███████▊  | 444/566 [02:02<00:33,  3.66it/s, loss=0.531]\u001b[A\n",
      " 79%|███████▊  | 445/566 [02:02<00:33,  3.66it/s, loss=0.531]\u001b[A\n",
      " 79%|███████▊  | 445/566 [02:03<00:33,  3.66it/s, loss=0.956]\u001b[A\n",
      " 79%|███████▉  | 446/566 [02:03<00:32,  3.64it/s, loss=0.956]\u001b[A\n",
      " 79%|███████▉  | 446/566 [02:03<00:32,  3.64it/s, loss=0.523]\u001b[A\n",
      " 79%|███████▉  | 447/566 [02:03<00:32,  3.67it/s, loss=0.523]\u001b[A\n",
      " 79%|███████▉  | 447/566 [02:03<00:32,  3.67it/s, loss=0.313]\u001b[A\n",
      " 79%|███████▉  | 448/566 [02:03<00:32,  3.64it/s, loss=0.313]\u001b[A\n",
      " 79%|███████▉  | 448/566 [02:03<00:32,  3.64it/s, loss=0.565]\u001b[A\n",
      " 79%|███████▉  | 449/566 [02:03<00:31,  3.66it/s, loss=0.565]\u001b[A\n",
      " 79%|███████▉  | 449/566 [02:04<00:31,  3.66it/s, loss=0.724]\u001b[A\n",
      " 80%|███████▉  | 450/566 [02:04<00:31,  3.64it/s, loss=0.724]\u001b[A\n",
      " 80%|███████▉  | 450/566 [02:04<00:31,  3.64it/s, loss=0.673]\u001b[A\n",
      " 80%|███████▉  | 451/566 [02:04<00:31,  3.67it/s, loss=0.673]\u001b[A\n",
      " 80%|███████▉  | 451/566 [02:04<00:31,  3.67it/s, loss=0.527]\u001b[A\n",
      " 80%|███████▉  | 452/566 [02:04<00:31,  3.65it/s, loss=0.527]\u001b[A\n",
      " 80%|███████▉  | 452/566 [02:04<00:31,  3.65it/s, loss=1.06] \u001b[A\n",
      " 80%|████████  | 453/566 [02:04<00:30,  3.68it/s, loss=1.06]\u001b[A\n",
      " 80%|████████  | 453/566 [02:05<00:30,  3.68it/s, loss=0.723]\u001b[A\n",
      " 80%|████████  | 454/566 [02:05<00:30,  3.67it/s, loss=0.723]\u001b[A\n",
      " 80%|████████  | 454/566 [02:05<00:30,  3.67it/s, loss=0.417]\u001b[A\n",
      " 80%|████████  | 455/566 [02:05<00:30,  3.66it/s, loss=0.417]\u001b[A\n",
      " 80%|████████  | 455/566 [02:05<00:30,  3.66it/s, loss=0.82] \u001b[A\n",
      " 81%|████████  | 456/566 [02:05<00:30,  3.65it/s, loss=0.82]\u001b[A\n",
      " 81%|████████  | 456/566 [02:06<00:30,  3.65it/s, loss=0.604]\u001b[A\n",
      " 81%|████████  | 457/566 [02:06<00:29,  3.66it/s, loss=0.604]\u001b[A\n",
      " 81%|████████  | 457/566 [02:06<00:29,  3.66it/s, loss=0.428]\u001b[A\n",
      " 81%|████████  | 458/566 [02:06<00:29,  3.65it/s, loss=0.428]\u001b[A\n",
      " 81%|████████  | 458/566 [02:06<00:29,  3.65it/s, loss=0.65] \u001b[A\n",
      " 81%|████████  | 459/566 [02:06<00:29,  3.66it/s, loss=0.65]\u001b[A\n",
      " 81%|████████  | 459/566 [02:06<00:29,  3.66it/s, loss=0.818]\u001b[A\n",
      " 81%|████████▏ | 460/566 [02:06<00:28,  3.67it/s, loss=0.818]\u001b[A\n",
      " 81%|████████▏ | 460/566 [02:07<00:28,  3.67it/s, loss=0.242]\u001b[A\n",
      " 81%|████████▏ | 461/566 [02:07<00:28,  3.70it/s, loss=0.242]\u001b[A\n",
      " 81%|████████▏ | 461/566 [02:07<00:28,  3.70it/s, loss=0.427]\u001b[A\n",
      " 82%|████████▏ | 462/566 [02:07<00:28,  3.69it/s, loss=0.427]\u001b[A\n",
      " 82%|████████▏ | 462/566 [02:07<00:28,  3.69it/s, loss=0.624]\u001b[A\n",
      " 82%|████████▏ | 463/566 [02:07<00:27,  3.69it/s, loss=0.624]\u001b[A\n",
      " 82%|████████▏ | 463/566 [02:07<00:27,  3.69it/s, loss=0.267]\u001b[A\n",
      " 82%|████████▏ | 464/566 [02:07<00:27,  3.69it/s, loss=0.267]\u001b[A\n",
      " 82%|████████▏ | 464/566 [02:08<00:27,  3.69it/s, loss=1.11] \u001b[A\n",
      " 82%|████████▏ | 465/566 [02:08<00:27,  3.69it/s, loss=1.11]\u001b[A\n",
      " 82%|████████▏ | 465/566 [02:08<00:27,  3.69it/s, loss=0.535]\u001b[A\n",
      " 82%|████████▏ | 466/566 [02:08<00:26,  3.72it/s, loss=0.535]\u001b[A\n",
      " 82%|████████▏ | 466/566 [02:08<00:26,  3.72it/s, loss=0.677]\u001b[A\n",
      " 83%|████████▎ | 467/566 [02:08<00:26,  3.70it/s, loss=0.677]\u001b[A\n",
      " 83%|████████▎ | 467/566 [02:09<00:26,  3.70it/s, loss=0.577]\u001b[A\n",
      " 83%|████████▎ | 468/566 [02:09<00:26,  3.69it/s, loss=0.577]\u001b[A\n",
      " 83%|████████▎ | 468/566 [02:09<00:26,  3.69it/s, loss=0.465]\u001b[A\n",
      " 83%|████████▎ | 469/566 [02:09<00:26,  3.67it/s, loss=0.465]\u001b[A\n",
      " 83%|████████▎ | 469/566 [02:09<00:26,  3.67it/s, loss=0.271]\u001b[A\n",
      " 83%|████████▎ | 470/566 [02:09<00:25,  3.70it/s, loss=0.271]\u001b[A\n",
      " 83%|████████▎ | 470/566 [02:09<00:25,  3.70it/s, loss=0.422]\u001b[A\n",
      " 83%|████████▎ | 471/566 [02:09<00:25,  3.71it/s, loss=0.422]\u001b[A\n",
      " 83%|████████▎ | 471/566 [02:10<00:25,  3.71it/s, loss=0.455]\u001b[A\n",
      " 83%|████████▎ | 472/566 [02:10<00:25,  3.69it/s, loss=0.455]\u001b[A\n",
      " 83%|████████▎ | 472/566 [02:10<00:25,  3.69it/s, loss=0.457]\u001b[A\n",
      " 84%|████████▎ | 473/566 [02:10<00:25,  3.69it/s, loss=0.457]\u001b[A\n",
      " 84%|████████▎ | 473/566 [02:10<00:25,  3.69it/s, loss=0.417]\u001b[A\n",
      " 84%|████████▎ | 474/566 [02:10<00:24,  3.68it/s, loss=0.417]\u001b[A\n",
      " 84%|████████▎ | 474/566 [02:10<00:24,  3.68it/s, loss=0.817]\u001b[A\n",
      " 84%|████████▍ | 475/566 [02:10<00:24,  3.68it/s, loss=0.817]\u001b[A\n",
      " 84%|████████▍ | 475/566 [02:11<00:24,  3.68it/s, loss=0.541]\u001b[A\n",
      " 84%|████████▍ | 476/566 [02:11<00:24,  3.66it/s, loss=0.541]\u001b[A\n",
      " 84%|████████▍ | 476/566 [02:11<00:24,  3.66it/s, loss=0.492]\u001b[A\n",
      " 84%|████████▍ | 477/566 [02:11<00:24,  3.68it/s, loss=0.492]\u001b[A\n",
      " 84%|████████▍ | 477/566 [02:11<00:24,  3.68it/s, loss=0.605]\u001b[A\n",
      " 84%|████████▍ | 478/566 [02:11<00:23,  3.69it/s, loss=0.605]\u001b[A\n",
      " 84%|████████▍ | 478/566 [02:12<00:23,  3.69it/s, loss=0.736]\u001b[A\n",
      " 85%|████████▍ | 479/566 [02:12<00:23,  3.69it/s, loss=0.736]\u001b[A\n",
      " 85%|████████▍ | 479/566 [02:12<00:23,  3.69it/s, loss=0.722]\u001b[A\n",
      " 85%|████████▍ | 480/566 [02:12<00:23,  3.65it/s, loss=0.722]\u001b[A\n",
      " 85%|████████▍ | 480/566 [02:12<00:23,  3.65it/s, loss=0.379]\u001b[A\n",
      " 85%|████████▍ | 481/566 [02:12<00:23,  3.63it/s, loss=0.379]\u001b[A\n",
      " 85%|████████▍ | 481/566 [02:12<00:23,  3.63it/s, loss=0.611]\u001b[A\n",
      " 85%|████████▌ | 482/566 [02:12<00:22,  3.66it/s, loss=0.611]\u001b[A\n",
      " 85%|████████▌ | 482/566 [02:13<00:22,  3.66it/s, loss=0.446]\u001b[A\n",
      " 85%|████████▌ | 483/566 [02:13<00:22,  3.67it/s, loss=0.446]\u001b[A\n",
      " 85%|████████▌ | 483/566 [02:13<00:22,  3.67it/s, loss=0.564]\u001b[A\n",
      " 86%|████████▌ | 484/566 [02:13<00:22,  3.65it/s, loss=0.564]\u001b[A\n",
      " 86%|████████▌ | 484/566 [02:13<00:22,  3.65it/s, loss=0.589]\u001b[A\n",
      " 86%|████████▌ | 485/566 [02:13<00:22,  3.66it/s, loss=0.589]\u001b[A\n",
      " 86%|████████▌ | 485/566 [02:13<00:22,  3.66it/s, loss=0.51] \u001b[A\n",
      " 86%|████████▌ | 486/566 [02:13<00:21,  3.67it/s, loss=0.51]\u001b[A\n",
      " 86%|████████▌ | 486/566 [02:14<00:21,  3.67it/s, loss=0.831]\u001b[A\n",
      " 86%|████████▌ | 487/566 [02:14<00:21,  3.67it/s, loss=0.831]\u001b[A\n",
      " 86%|████████▌ | 487/566 [02:14<00:21,  3.67it/s, loss=0.88] \u001b[A\n",
      " 86%|████████▌ | 488/566 [02:14<00:21,  3.67it/s, loss=0.88]\u001b[A\n",
      " 86%|████████▌ | 488/566 [02:14<00:21,  3.67it/s, loss=0.6] \u001b[A\n",
      " 86%|████████▋ | 489/566 [02:14<00:20,  3.69it/s, loss=0.6]\u001b[A\n",
      " 86%|████████▋ | 489/566 [02:15<00:20,  3.69it/s, loss=0.72]\u001b[A\n",
      " 87%|████████▋ | 490/566 [02:15<00:20,  3.69it/s, loss=0.72]\u001b[A\n",
      " 87%|████████▋ | 490/566 [02:15<00:20,  3.69it/s, loss=0.58]\u001b[A\n",
      " 87%|████████▋ | 491/566 [02:15<00:20,  3.71it/s, loss=0.58]\u001b[A\n",
      " 87%|████████▋ | 491/566 [02:15<00:20,  3.71it/s, loss=0.67]\u001b[A\n",
      " 87%|████████▋ | 492/566 [02:15<00:19,  3.70it/s, loss=0.67]\u001b[A\n",
      " 87%|████████▋ | 492/566 [02:15<00:19,  3.70it/s, loss=1.18]\u001b[A\n",
      " 87%|████████▋ | 493/566 [02:15<00:19,  3.70it/s, loss=1.18]\u001b[A\n",
      " 87%|████████▋ | 493/566 [02:16<00:19,  3.70it/s, loss=0.46]\u001b[A\n",
      " 87%|████████▋ | 494/566 [02:16<00:19,  3.71it/s, loss=0.46]\u001b[A\n",
      " 87%|████████▋ | 494/566 [02:16<00:19,  3.71it/s, loss=0.483]\u001b[A\n",
      " 87%|████████▋ | 495/566 [02:16<00:19,  3.72it/s, loss=0.483]\u001b[A\n",
      " 87%|████████▋ | 495/566 [02:16<00:19,  3.72it/s, loss=0.262]\u001b[A\n",
      " 88%|████████▊ | 496/566 [02:16<00:18,  3.71it/s, loss=0.262]\u001b[A\n",
      " 88%|████████▊ | 496/566 [02:16<00:18,  3.71it/s, loss=0.759]\u001b[A\n",
      " 88%|████████▊ | 497/566 [02:16<00:18,  3.71it/s, loss=0.759]\u001b[A\n",
      " 88%|████████▊ | 497/566 [02:17<00:18,  3.71it/s, loss=0.959]\u001b[A\n",
      " 88%|████████▊ | 498/566 [02:17<00:18,  3.74it/s, loss=0.959]\u001b[A\n",
      " 88%|████████▊ | 498/566 [02:17<00:18,  3.74it/s, loss=0.48] \u001b[A\n",
      " 88%|████████▊ | 499/566 [02:17<00:17,  3.75it/s, loss=0.48]\u001b[A\n",
      " 88%|████████▊ | 499/566 [02:17<00:17,  3.75it/s, loss=0.741]\u001b[A\n",
      " 88%|████████▊ | 500/566 [02:17<00:17,  3.73it/s, loss=0.741]\u001b[A\n",
      " 88%|████████▊ | 500/566 [02:17<00:17,  3.73it/s, loss=0.528]\u001b[A\n",
      " 89%|████████▊ | 501/566 [02:17<00:17,  3.71it/s, loss=0.528]\u001b[A\n",
      " 89%|████████▊ | 501/566 [02:18<00:17,  3.71it/s, loss=0.583]\u001b[A\n",
      " 89%|████████▊ | 502/566 [02:18<00:17,  3.68it/s, loss=0.583]\u001b[A\n",
      " 89%|████████▊ | 502/566 [02:18<00:17,  3.68it/s, loss=0.685]\u001b[A\n",
      " 89%|████████▉ | 503/566 [02:18<00:17,  3.70it/s, loss=0.685]\u001b[A\n",
      " 89%|████████▉ | 503/566 [02:18<00:17,  3.70it/s, loss=0.526]\u001b[A\n",
      " 89%|████████▉ | 504/566 [02:18<00:16,  3.68it/s, loss=0.526]\u001b[A\n",
      " 89%|████████▉ | 504/566 [02:19<00:16,  3.68it/s, loss=0.603]\u001b[A\n",
      " 89%|████████▉ | 505/566 [02:19<00:16,  3.66it/s, loss=0.603]\u001b[A\n",
      " 89%|████████▉ | 505/566 [02:19<00:16,  3.66it/s, loss=0.397]\u001b[A\n",
      " 89%|████████▉ | 506/566 [02:19<00:16,  3.67it/s, loss=0.397]\u001b[A\n",
      " 89%|████████▉ | 506/566 [02:19<00:16,  3.67it/s, loss=0.747]\u001b[A\n",
      " 90%|████████▉ | 507/566 [02:19<00:16,  3.68it/s, loss=0.747]\u001b[A\n",
      " 90%|████████▉ | 507/566 [02:19<00:16,  3.68it/s, loss=0.623]\u001b[A\n",
      " 90%|████████▉ | 508/566 [02:19<00:15,  3.70it/s, loss=0.623]\u001b[A\n",
      " 90%|████████▉ | 508/566 [02:20<00:15,  3.70it/s, loss=0.355]\u001b[A\n",
      " 90%|████████▉ | 509/566 [02:20<00:15,  3.68it/s, loss=0.355]\u001b[A\n",
      " 90%|████████▉ | 509/566 [02:20<00:15,  3.68it/s, loss=0.705]\u001b[A\n",
      " 90%|█████████ | 510/566 [02:20<00:15,  3.70it/s, loss=0.705]\u001b[A\n",
      " 90%|█████████ | 510/566 [02:20<00:15,  3.70it/s, loss=0.495]\u001b[A\n",
      " 90%|█████████ | 511/566 [02:20<00:14,  3.70it/s, loss=0.495]\u001b[A\n",
      " 90%|█████████ | 511/566 [02:20<00:14,  3.70it/s, loss=0.737]\u001b[A\n",
      " 90%|█████████ | 512/566 [02:20<00:14,  3.72it/s, loss=0.737]\u001b[A\n",
      " 90%|█████████ | 512/566 [02:21<00:14,  3.72it/s, loss=0.514]\u001b[A\n",
      " 91%|█████████ | 513/566 [02:21<00:14,  3.73it/s, loss=0.514]\u001b[A\n",
      " 91%|█████████ | 513/566 [02:21<00:14,  3.73it/s, loss=0.561]\u001b[A\n",
      " 91%|█████████ | 514/566 [02:21<00:13,  3.72it/s, loss=0.561]\u001b[A\n",
      " 91%|█████████ | 514/566 [02:21<00:13,  3.72it/s, loss=0.422]\u001b[A\n",
      " 91%|█████████ | 515/566 [02:21<00:13,  3.71it/s, loss=0.422]\u001b[A\n",
      " 91%|█████████ | 515/566 [02:22<00:13,  3.71it/s, loss=0.91] \u001b[A\n",
      " 91%|█████████ | 516/566 [02:22<00:13,  3.72it/s, loss=0.91]\u001b[A\n",
      " 91%|█████████ | 516/566 [02:22<00:13,  3.72it/s, loss=0.611]\u001b[A\n",
      " 91%|█████████▏| 517/566 [02:22<00:13,  3.71it/s, loss=0.611]\u001b[A\n",
      " 91%|█████████▏| 517/566 [02:22<00:13,  3.71it/s, loss=0.737]\u001b[A\n",
      " 92%|█████████▏| 518/566 [02:22<00:12,  3.73it/s, loss=0.737]\u001b[A\n",
      " 92%|█████████▏| 518/566 [02:22<00:12,  3.73it/s, loss=0.749]\u001b[A\n",
      " 92%|█████████▏| 519/566 [02:22<00:12,  3.72it/s, loss=0.749]\u001b[A\n",
      " 92%|█████████▏| 519/566 [02:23<00:12,  3.72it/s, loss=0.614]\u001b[A\n",
      " 92%|█████████▏| 520/566 [02:23<00:12,  3.73it/s, loss=0.614]\u001b[A\n",
      " 92%|█████████▏| 520/566 [02:23<00:12,  3.73it/s, loss=0.353]\u001b[A\n",
      " 92%|█████████▏| 521/566 [02:23<00:12,  3.71it/s, loss=0.353]\u001b[A\n",
      " 92%|█████████▏| 521/566 [02:23<00:12,  3.71it/s, loss=0.595]\u001b[A\n",
      " 92%|█████████▏| 522/566 [02:23<00:11,  3.70it/s, loss=0.595]\u001b[A\n",
      " 92%|█████████▏| 522/566 [02:23<00:11,  3.70it/s, loss=0.628]\u001b[A\n",
      " 92%|█████████▏| 523/566 [02:23<00:11,  3.71it/s, loss=0.628]\u001b[A\n",
      " 92%|█████████▏| 523/566 [02:24<00:11,  3.71it/s, loss=0.565]\u001b[A\n",
      " 93%|█████████▎| 524/566 [02:24<00:11,  3.70it/s, loss=0.565]\u001b[A\n",
      " 93%|█████████▎| 524/566 [02:24<00:11,  3.70it/s, loss=0.884]\u001b[A\n",
      " 93%|█████████▎| 525/566 [02:24<00:11,  3.67it/s, loss=0.884]\u001b[A\n",
      " 93%|█████████▎| 525/566 [02:24<00:11,  3.67it/s, loss=0.964]\u001b[A\n",
      " 93%|█████████▎| 526/566 [02:24<00:10,  3.65it/s, loss=0.964]\u001b[A\n",
      " 93%|█████████▎| 526/566 [02:25<00:10,  3.65it/s, loss=0.835]\u001b[A\n",
      " 93%|█████████▎| 527/566 [02:25<00:10,  3.66it/s, loss=0.835]\u001b[A\n",
      " 93%|█████████▎| 527/566 [02:25<00:10,  3.66it/s, loss=0.765]\u001b[A\n",
      " 93%|█████████▎| 528/566 [02:25<00:10,  3.67it/s, loss=0.765]\u001b[A\n",
      " 93%|█████████▎| 528/566 [02:25<00:10,  3.67it/s, loss=0.964]\u001b[A\n",
      " 93%|█████████▎| 529/566 [02:25<00:10,  3.68it/s, loss=0.964]\u001b[A\n",
      " 93%|█████████▎| 529/566 [02:25<00:10,  3.68it/s, loss=0.552]\u001b[A\n",
      " 94%|█████████▎| 530/566 [02:25<00:09,  3.67it/s, loss=0.552]\u001b[A\n",
      " 94%|█████████▎| 530/566 [02:26<00:09,  3.67it/s, loss=0.573]\u001b[A\n",
      " 94%|█████████▍| 531/566 [02:26<00:09,  3.68it/s, loss=0.573]\u001b[A\n",
      " 94%|█████████▍| 531/566 [02:26<00:09,  3.68it/s, loss=0.774]\u001b[A\n",
      " 94%|█████████▍| 532/566 [02:26<00:09,  3.69it/s, loss=0.774]\u001b[A\n",
      " 94%|█████████▍| 532/566 [02:26<00:09,  3.69it/s, loss=0.609]\u001b[A\n",
      " 94%|█████████▍| 533/566 [02:26<00:08,  3.68it/s, loss=0.609]\u001b[A\n",
      " 94%|█████████▍| 533/566 [02:26<00:08,  3.68it/s, loss=0.672]\u001b[A\n",
      " 94%|█████████▍| 534/566 [02:26<00:08,  3.68it/s, loss=0.672]\u001b[A\n",
      " 94%|█████████▍| 534/566 [02:27<00:08,  3.68it/s, loss=0.64] \u001b[A\n",
      " 95%|█████████▍| 535/566 [02:27<00:08,  3.69it/s, loss=0.64]\u001b[A\n",
      " 95%|█████████▍| 535/566 [02:27<00:08,  3.69it/s, loss=0.421]\u001b[A\n",
      " 95%|█████████▍| 536/566 [02:27<00:08,  3.69it/s, loss=0.421]\u001b[A\n",
      " 95%|█████████▍| 536/566 [02:27<00:08,  3.69it/s, loss=0.859]\u001b[A\n",
      " 95%|█████████▍| 537/566 [02:27<00:07,  3.69it/s, loss=0.859]\u001b[A\n",
      " 95%|█████████▍| 537/566 [02:27<00:07,  3.69it/s, loss=0.918]\u001b[A\n",
      " 95%|█████████▌| 538/566 [02:27<00:07,  3.68it/s, loss=0.918]\u001b[A\n",
      " 95%|█████████▌| 538/566 [02:28<00:07,  3.68it/s, loss=0.916]\u001b[A\n",
      " 95%|█████████▌| 539/566 [02:28<00:07,  3.69it/s, loss=0.916]\u001b[A\n",
      " 95%|█████████▌| 539/566 [02:28<00:07,  3.69it/s, loss=0.567]\u001b[A\n",
      " 95%|█████████▌| 540/566 [02:28<00:06,  3.72it/s, loss=0.567]\u001b[A\n",
      " 95%|█████████▌| 540/566 [02:28<00:06,  3.72it/s, loss=0.5]  \u001b[A\n",
      " 96%|█████████▌| 541/566 [02:28<00:06,  3.73it/s, loss=0.5]\u001b[A\n",
      " 96%|█████████▌| 541/566 [02:29<00:06,  3.73it/s, loss=0.479]\u001b[A\n",
      " 96%|█████████▌| 542/566 [02:29<00:06,  3.72it/s, loss=0.479]\u001b[A\n",
      " 96%|█████████▌| 542/566 [02:29<00:06,  3.72it/s, loss=0.764]\u001b[A\n",
      " 96%|█████████▌| 543/566 [02:29<00:06,  3.71it/s, loss=0.764]\u001b[A\n",
      " 96%|█████████▌| 543/566 [02:29<00:06,  3.71it/s, loss=0.893]\u001b[A\n",
      " 96%|█████████▌| 544/566 [02:29<00:05,  3.72it/s, loss=0.893]\u001b[A\n",
      " 96%|█████████▌| 544/566 [02:29<00:05,  3.72it/s, loss=0.537]\u001b[A\n",
      " 96%|█████████▋| 545/566 [02:29<00:05,  3.73it/s, loss=0.537]\u001b[A\n",
      " 96%|█████████▋| 545/566 [02:30<00:05,  3.73it/s, loss=0.659]\u001b[A\n",
      " 96%|█████████▋| 546/566 [02:30<00:05,  3.74it/s, loss=0.659]\u001b[A\n",
      " 96%|█████████▋| 546/566 [02:30<00:05,  3.74it/s, loss=0.544]\u001b[A\n",
      " 97%|█████████▋| 547/566 [02:30<00:05,  3.71it/s, loss=0.544]\u001b[A\n",
      " 97%|█████████▋| 547/566 [02:30<00:05,  3.71it/s, loss=0.363]\u001b[A\n",
      " 97%|█████████▋| 548/566 [02:30<00:04,  3.70it/s, loss=0.363]\u001b[A\n",
      " 97%|█████████▋| 548/566 [02:30<00:04,  3.70it/s, loss=1.06] \u001b[A\n",
      " 97%|█████████▋| 549/566 [02:30<00:04,  3.71it/s, loss=1.06]\u001b[A\n",
      " 97%|█████████▋| 549/566 [02:31<00:04,  3.71it/s, loss=0.498]\u001b[A\n",
      " 97%|█████████▋| 550/566 [02:31<00:04,  3.70it/s, loss=0.498]\u001b[A\n",
      " 97%|█████████▋| 550/566 [02:31<00:04,  3.70it/s, loss=0.385]\u001b[A\n",
      " 97%|█████████▋| 551/566 [02:31<00:04,  3.71it/s, loss=0.385]\u001b[A\n",
      " 97%|█████████▋| 551/566 [02:31<00:04,  3.71it/s, loss=0.717]\u001b[A\n",
      " 98%|█████████▊| 552/566 [02:31<00:03,  3.72it/s, loss=0.717]\u001b[A\n",
      " 98%|█████████▊| 552/566 [02:32<00:03,  3.72it/s, loss=0.937]\u001b[A\n",
      " 98%|█████████▊| 553/566 [02:32<00:03,  3.70it/s, loss=0.937]\u001b[A\n",
      " 98%|█████████▊| 553/566 [02:32<00:03,  3.70it/s, loss=0.441]\u001b[A\n",
      " 98%|█████████▊| 554/566 [02:32<00:03,  3.69it/s, loss=0.441]\u001b[A\n",
      " 98%|█████████▊| 554/566 [02:32<00:03,  3.69it/s, loss=0.833]\u001b[A\n",
      " 98%|█████████▊| 555/566 [02:32<00:03,  3.67it/s, loss=0.833]\u001b[A\n",
      " 98%|█████████▊| 555/566 [02:32<00:03,  3.67it/s, loss=0.578]\u001b[A\n",
      " 98%|█████████▊| 556/566 [02:32<00:02,  3.70it/s, loss=0.578]\u001b[A\n",
      " 98%|█████████▊| 556/566 [02:33<00:02,  3.70it/s, loss=0.345]\u001b[A\n",
      " 98%|█████████▊| 557/566 [02:33<00:02,  3.70it/s, loss=0.345]\u001b[A\n",
      " 98%|█████████▊| 557/566 [02:33<00:02,  3.70it/s, loss=0.488]\u001b[A\n",
      " 99%|█████████▊| 558/566 [02:33<00:02,  3.73it/s, loss=0.488]\u001b[A\n",
      " 99%|█████████▊| 558/566 [02:33<00:02,  3.73it/s, loss=0.315]\u001b[A\n",
      " 99%|█████████▉| 559/566 [02:33<00:01,  3.72it/s, loss=0.315]\u001b[A\n",
      " 99%|█████████▉| 559/566 [02:33<00:01,  3.72it/s, loss=0.394]\u001b[A\n",
      " 99%|█████████▉| 560/566 [02:33<00:01,  3.70it/s, loss=0.394]\u001b[A\n",
      " 99%|█████████▉| 560/566 [02:34<00:01,  3.70it/s, loss=0.624]\u001b[A\n",
      " 99%|█████████▉| 561/566 [02:34<00:01,  3.70it/s, loss=0.624]\u001b[A\n",
      " 99%|█████████▉| 561/566 [02:34<00:01,  3.70it/s, loss=0.72] \u001b[A\n",
      " 99%|█████████▉| 562/566 [02:34<00:01,  3.70it/s, loss=0.72]\u001b[A\n",
      " 99%|█████████▉| 562/566 [02:34<00:01,  3.70it/s, loss=0.636]\u001b[A\n",
      " 99%|█████████▉| 563/566 [02:34<00:00,  3.69it/s, loss=0.636]\u001b[A\n",
      " 99%|█████████▉| 563/566 [02:34<00:00,  3.69it/s, loss=0.53] \u001b[A\n",
      "100%|█████████▉| 564/566 [02:34<00:00,  3.70it/s, loss=0.53]\u001b[A\n",
      "100%|█████████▉| 564/566 [02:35<00:00,  3.70it/s, loss=0.746]\u001b[A\n",
      "100%|█████████▉| 565/566 [02:35<00:00,  3.70it/s, loss=0.746]\u001b[A\n",
      "100%|█████████▉| 565/566 [02:35<00:00,  3.70it/s, loss=0.741]\u001b[A\n",
      "100%|██████████| 566/566 [02:35<00:00,  3.64it/s, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.0238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.0279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.0268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'accuracy': 0.6885572139303483, 'precision': 0.75459749611645, 'recall': 0.6885572139303483, 'f1': 0.7096540049021612}\n",
      "Test Results: {'accuracy': 0.70421974522293, 'precision': 0.7700749843816003, 'recall': 0.70421974522293, 'f1': 0.7246288448950967}\n"
     ]
    }
   ],
   "source": [
    "# DeBERTaV3 Fine-Tuning: Apple/Samsung Yelp Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# CUDA Check\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to HF datasets\n",
    "def prepare_hf_dataset(data):\n",
    "    return Dataset.from_pandas(data[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_dataset = prepare_hf_dataset(train_data)\n",
    "val_dataset = prepare_hf_dataset(val_data)\n",
    "test_dataset = prepare_hf_dataset(test_data)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels=3).to(device)\n",
    "\n",
    "# Dataloaders and optimizer\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(8):  # more epochs since it's a smaller DeBERTa\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"Validation Results:\", evaluate(val_loader))\n",
    "print(\"Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c24VopfgA_ci"
   },
   "outputs": [],
   "source": [
    "# DeBERTaV3 Fine-Tuning: Apple/Samsung Yelp Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# CUDA Check\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to HF datasets\n",
    "def prepare_hf_dataset(data):\n",
    "    return Dataset.from_pandas(data[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_dataset = prepare_hf_dataset(train_data)\n",
    "val_dataset = prepare_hf_dataset(val_data)\n",
    "test_dataset = prepare_hf_dataset(test_data)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels=3).to(device)\n",
    "\n",
    "# Dataloaders and optimizer\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(8):  # more epochs since it's a smaller DeBERTa\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"Validation Results:\", evaluate(val_loader))\n",
    "print(\"Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829,
     "referenced_widgets": [
      "4c2c770edb3d4c59b7b9562cdb920b92",
      "71937fe23fa84aecb66a79a2c9f06771",
      "7acc7faddcee4728b1595fe31bc10c1f",
      "b3957423fb994ac2a49adfa7b3831a98",
      "2410b0954de04f988aa92b1f3903802c",
      "79350356bf224e65b6828ca49e5ecde7",
      "ff4c55643cf04612a8c5c9d98c27ee4c",
      "6d13aec63a19484b8f3a1accc68cdcde",
      "da17f0658c1f4ccd8b381fb0e441550e",
      "53544fc9ffa4401fb7b4db3b9b15c70f",
      "a23060fa122c4169b1e7b03a5ba4a246",
      "3e9be9155b544db8898427327ce7e6e2",
      "4e9a7571e70f41149eaaf33dafbffccc",
      "491b40568e2b434489971af624aec752",
      "95d45a70644b4e2bb9b6f77d912052f5",
      "94caecbe2b604c46bd6d3f13295ca838",
      "119eb21ae8d04df7a48c6c6fecba0db6",
      "348607665823451e8dc6c9a01b6871b5",
      "4b207cdb3d944bc3b279b87c9f9e312a",
      "0c9b4b710bd14baebb4d401105bb077e",
      "dd4f0f7bbcd840a8a9836294c93c977c",
      "d176cea4f4514df9b4c76ab33e44917b",
      "362f9d8a73614a4ca9ae9f8e878372c2",
      "8c1003c6e0d846baa6a4997da72c87df",
      "2f50ee40c0cd48b1a7ad04c617d962db",
      "ad2665be93284a5ab8ee0902760f1bc0",
      "ad8dff9f43ba4becace9f4e639a0b0aa",
      "38d2d509057046fea090bd07074fc124",
      "ee0dd66d19254d8298c2a6c5edd3f4b5",
      "7303782bd2c3427c85b20b61384762e5",
      "68f95a4037464daeb6a802d9a07642dc",
      "054a507fedf14335bbe42a199f73809a",
      "3be60b55f9b54c5d99a40c8e75ca60e2",
      "a4dbee93420d411e9a42c50bbab2049b",
      "bfacf9b397c647348e2ad6a591e6b08d",
      "02bdb6acaeb947eb94099b793f49b8ff",
      "0fc0dd486a4a4a6abc6d0b31edfbb144",
      "29eb6baa655b4f35b05f89bb6a8b8229",
      "7209d0bcf7b74c8aa4770e623276344f",
      "dcd3aca66f864c3494b54fe701de748f",
      "9936775cef57432ebb23094e2de94a11",
      "8c9a181bd8244476a2f5c444989fab84",
      "3cfa3faabc28408eb4c5b087f1deb7f1",
      "65a62744d1d94e96838f5ac6c40df284",
      "96396b02de76463e8f0d9abed2533c39",
      "8b6755f1278b49f5bf348882ce87b7ab",
      "55739e8353404cb69c2c4650ecfb693b",
      "c197274cdebb4189a9f76c3c59de833d",
      "72b8231d39244b199ec8307bd55d4cbf",
      "48864d66991a420c928e51fa7495258b",
      "5ae09c1f28c64ab2a6b5812c2a1c5a32",
      "760b243d064c461c8d0fd10b02258de0",
      "ac7157813d8245f4b2f293b9ba6f622a",
      "1882bcd6f5c14af2959635303ea17e08",
      "5e1db292fc5c4a29b763039bcbcd827a",
      "9623f166977c41358550a94c811446c8",
      "38bfed331ee64e03a60f672b30210a85",
      "cd5c0e910dc44017ae85ad0f8cd7c36e",
      "fdd997738c3a4de2a085282398303e4b",
      "b2326c1612e34827b0e0693eab64d8d9",
      "a78497be13034b0eb78ef6a4f805d99d",
      "153a54cdd5624c3c8b889d88baa6411d",
      "7e1a2a7e6a3748a794c81f7aa446c34e",
      "3783e1f511df461d9205e7f2a94ff57e",
      "4ac9c634796a4bc9aaa8a3ba35fcf5aa",
      "c9d5aef16fda4450b9bf7babf79e9e98",
      "7f9a5395e2384f68a645a15309dd692a",
      "cb4853b57023430a9dfe16b51e22fdba",
      "8bbff2fd1b3e41fb8d102a87a11fbcf8",
      "38e67db69b4c44c8a6b691e9a33c4017",
      "5eb6f3ca11d245feb15b0cd23d11b31d",
      "dba89a55c1e341eda638f7eef3f84cce",
      "ea0b2d605a3642d8886284667acc1a2c",
      "e3a4730ed35c4dfba72b5a3f0a88ceac",
      "53a79988988444eaa60e7929c844b703",
      "5b6b7e368a3942f295408b9986368969",
      "6e84e3c5b5d04a5e99639de9cce7d68c",
      "4ba1f74eea8e4b06a4a36a9594c1215c",
      "c7cee884605c47c980abd63ad8c98af1",
      "93e106ca832b4c14a95c160738289bae",
      "4d6ec9a2c3a347f898e7ab54f4cb647b",
      "52b026b6c77f42a7b96df1bfda9c5e79",
      "b09f5750fc6c4416809a5b317f3da0d8",
      "50cbd9a33bc84bbfa352c1cfb260bf28",
      "40f52f7d213f4da6820144ea96f08e75",
      "f0dcfeac1a964979a92e996bbe481d9d",
      "85474fc1eb9148a7b5eb00d0464ac9f2",
      "d87a4a5f969344b6911a036db2401897"
     ]
    },
    "id": "K5bEnkgaBTXQ",
    "outputId": "a6599db7-d850-477f-d452-b4b682c649f7"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: Tesla T4\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c770edb3d4c59b7b9562cdb920b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9be9155b544db8898427327ce7e6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362f9d8a73614a4ca9ae9f8e878372c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dbee93420d411e9a42c50bbab2049b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96396b02de76463e8f0d9abed2533c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9623f166977c41358550a94c811446c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9a5395e2384f68a645a15309dd692a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/566 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba1f74eea8e4b06a4a36a9594c1215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:27<00:00,  3.83it/s, loss=0.593]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.203]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.615]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:31<00:00,  3.75it/s, loss=0.0112]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:31<00:00,  3.74it/s, loss=0.0316]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:30<00:00,  3.75it/s, loss=0.00231]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:31<00:00,  3.74it/s, loss=0.00404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [02:31<00:00,  3.74it/s, loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'accuracy': 0.7412935323383084, 'precision': 0.755457739699724, 'recall': 0.7412935323383084, 'f1': 0.7472113080965775}\n"
     ]
    }
   ],
   "source": [
    "# DeBERTaV3 Fine-Tuning: Apple/Samsung Yelp Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# CUDA Check\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"label\"], random_state=42)\n",
    "\n",
    "# Convert to HF datasets\n",
    "def prepare_hf_dataset(data):\n",
    "    return Dataset.from_pandas(data[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_dataset = prepare_hf_dataset(train_data)\n",
    "val_dataset = prepare_hf_dataset(val_data)\n",
    "test_dataset = prepare_hf_dataset(test_data)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels=3).to(device)\n",
    "\n",
    "# Dataloaders and optimizer\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(8):  # more epochs since it's a smaller DeBERTa\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    p, r, f, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"Validation Results:\", evaluate(val_loader))\n",
    "print(\"Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "yG1rHiBKdFNp",
    "outputId": "48c89e65-8b21-49ed-edf2-adcc8b134fc6"
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-065e8d1b0626>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q transformers datasets nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d958840ca5d842059b4669b8877001eb",
      "2dc1cf828a594e5295d6f467a5450a4a",
      "1263a89ae23444e1bb8d84b718704257",
      "4965b2f845a546f0b98f4c4cbc1dadeb",
      "5d94e15b679b4892b32567a46bfc454a",
      "bf6593e61c4f423c92dc7b35057bd741",
      "546f5054142c42fe8a24d8adeb9c3256",
      "f2a8bf9a98464692bbfd863439e4a224",
      "2fac3532d6d242d5b5c2f859f939939f",
      "bc05be3604894fa5820964c7bff36b43",
      "ffd836f981b64e7995c385a023d3b317",
      "77075af165a84b399c05b7d4167e186e",
      "0b919ae045884ad4842f5c817540e67a",
      "44a921919cab42429ede135d2ecd5b00",
      "7e8d091b29ec4d6db00af30ed417c956",
      "a8b56fc2dc284821a00233deafb94a34",
      "a33fb0ddb94c4aa0aec28bfe23da167c",
      "85b62d8709794297a816886bf7585899",
      "d46b0e7fae614596bdfe1babd3379329",
      "ebad93bebe424c4cb9ab737ff114a2bb",
      "a971cd8dbf3b43d694be9d645dc9d6cd",
      "96d98fc1e8704d1f9c134b2522a18297",
      "4ee70be91a5c4a0ba5aa046074ad814d",
      "215919265cc74b0d92ccc6149f5a9ba7",
      "3a4c63c6f59b48b4a6e826f359cff74c",
      "2c23c4efc90341368293dbde58b39200",
      "05dcdc13f4834ab68e81528af5089663",
      "6afa149d477240f5895506a21dacc080",
      "98ed60ea3e144967a99bee5e53795798",
      "cf3eb7d098824ae89ef969d35b64008c",
      "c96190280b434368920a934ac40d7938",
      "7553c2349eac49309b7b6f275b033004",
      "b2b80ac8e6694221922ca9faad7754d9",
      "1090dc8100844621ade912348c5daeff",
      "5e104b6445c2496aa05853997cfe6bee",
      "725cbb96d71c417591e19ccadafc1339",
      "6667cdb350464c23a03da0b8bc4b5f67",
      "8d1db41e4c864952a9095e51a8a147cc",
      "530e52acfe4b493598dec13f047c7593",
      "f0bea5611dae4b4bb178e71360f67875",
      "2b9a4cb872c743a9872e3bd0bba0f046",
      "9a5001132418429290a0c973443a676d",
      "0d8d74e38be94247a735854815cd0a6e",
      "01d4e7124b0e434dbb3e73187509346c",
      "55109e3ba016479991343f1a50df2865",
      "6c45e5bad04548db9374d213d8431065",
      "d219fc421afd44808e5fad2ad8a6a223",
      "c2a216d77731409eb2fb7b2d75ec6068",
      "73cdcc27a6dd4ac2b386f4b31fa19c8d",
      "0d57be41f6f54a7cb8ca83137f6c371a",
      "11d52fd70ef444659326f889c85b1756",
      "88ad03b9781240d0ae7fda18bb478386",
      "ef0be19a709f4011af8e2c7b2d1c7ab2",
      "da9d5feb485d4177a101ad3e16d85e00",
      "afb3fd578a1c4f048519396c295a2986",
      "3d9efd07228c445dbef2486a6859f326",
      "bc3d2ab1466a4438a96b19cdca548498",
      "11df9b6e5d56430fbc679da13bc88c76",
      "b36274614d5a4e3b9aa3005a61803bb2",
      "84264938a5514e99a8128756f149147a",
      "0c3c389f780a4bbbb88bbc219de9cf4e",
      "8503ce8fa04d4f78a20edcb739ded15d",
      "4efc9b8c944a4b60ae50abc5c62233ff",
      "b046db2823f9422d92953404f3a328c9",
      "a9fe5b5d47cf46be8fe821f745a1c14b",
      "cd266fc3e9134ba69fa4b31e74835911",
      "e52cedfd76144b62bb02d1ba2e2baca6",
      "5500d0bad0804da28dd78c1289a5e092",
      "64a189e06c8b4ef4b68d465b84cd8d35",
      "80cdba222a444019a38ce982a8604de0",
      "c5c354ff068f48efbca5f8b5ba79d86f",
      "f0f872efc5384baba001a7b0421b72c3",
      "290c0ebab9f545e9920883b0fd2bf798",
      "9ba89321de644d819818a74c164ce2fa",
      "1835d63467734f3590b7e10792de2898",
      "61b79a6204384d25abebd4d61bc57c35",
      "f346d34c00f04af189351582de7eef28",
      "6f1b857c4fb14ee7afd919702e423cf8",
      "56cf6b6e36f24c1aa7516219128818ff",
      "798a69c7fa404979a0abdfa3f3977c13",
      "8d140e22bcd1420a8ae356af009c91de",
      "fb306bbc06504c089ef415d08e6a9158",
      "65853b2091b049a4980f763a9315f605",
      "5acefd1b6bf54aba97136ffef29575b9",
      "a1023a2814ee401ea868cba4b76722f8",
      "18caebfe9dcd4162bff48ac25ea99393",
      "71464f7745404cb88df3dbc0bd5116eb",
      "0e241e2395294d5f91cb1230c168de45"
     ]
    },
    "id": "CwXxpufxcq9s",
    "outputId": "52d35220-6a6d-4053-e65f-cde725e7d954"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/491.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d958840ca5d842059b4669b8877001eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77075af165a84b399c05b7d4167e186e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee70be91a5c4a0ba5aa046074ad814d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1090dc8100844621ade912348c5daeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55109e3ba016479991343f1a50df2865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9efd07228c445dbef2486a6859f326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52cedfd76144b62bb02d1ba2e2baca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1b857c4fb14ee7afd919702e423cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/566 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/566 [00:02<?, ?it/s, loss=1.11]\u001b[A\n",
      "  0%|          | 1/566 [00:02<21:04,  2.24s/it, loss=1.11]\u001b[A\n",
      "  0%|          | 1/566 [00:03<21:04,  2.24s/it, loss=1.09]\u001b[A\n",
      "  0%|          | 2/566 [00:03<13:02,  1.39s/it, loss=1.09]\u001b[A\n",
      "  0%|          | 2/566 [00:03<13:02,  1.39s/it, loss=1.1] \u001b[A\n",
      "  1%|          | 3/566 [00:03<08:53,  1.06it/s, loss=1.1]\u001b[A\n",
      "  1%|          | 3/566 [00:03<08:53,  1.06it/s, loss=1.08]\u001b[A\n",
      "  1%|          | 4/566 [00:03<07:12,  1.30it/s, loss=1.08]\u001b[A\n",
      "  1%|          | 4/566 [00:04<07:12,  1.30it/s, loss=0.986]\u001b[A\n",
      "  1%|          | 5/566 [00:04<06:05,  1.54it/s, loss=0.986]\u001b[A\n",
      "  1%|          | 5/566 [00:04<06:05,  1.54it/s, loss=1.01] \u001b[A\n",
      "  1%|          | 6/566 [00:04<05:26,  1.72it/s, loss=1.01]\u001b[A\n",
      "  1%|          | 6/566 [00:05<05:26,  1.72it/s, loss=1.05]\u001b[A\n",
      "  1%|          | 7/566 [00:05<05:00,  1.86it/s, loss=1.05]\u001b[A\n",
      "  1%|          | 7/566 [00:05<05:00,  1.86it/s, loss=1.07]\u001b[A\n",
      "  1%|▏         | 8/566 [00:05<04:43,  1.97it/s, loss=1.07]\u001b[A\n",
      "  1%|▏         | 8/566 [00:06<04:43,  1.97it/s, loss=0.962]\u001b[A\n",
      "  2%|▏         | 9/566 [00:06<04:31,  2.05it/s, loss=0.962]\u001b[A\n",
      "  2%|▏         | 9/566 [00:06<04:31,  2.05it/s, loss=0.905]\u001b[A\n",
      "  2%|▏         | 10/566 [00:06<04:23,  2.11it/s, loss=0.905]\u001b[A\n",
      "  2%|▏         | 10/566 [00:07<04:23,  2.11it/s, loss=1.07] \u001b[A\n",
      "  2%|▏         | 11/566 [00:07<04:18,  2.15it/s, loss=1.07]\u001b[A\n",
      "  2%|▏         | 11/566 [00:07<04:18,  2.15it/s, loss=0.996]\u001b[A\n",
      "  2%|▏         | 12/566 [00:07<04:15,  2.17it/s, loss=0.996]\u001b[A\n",
      "  2%|▏         | 12/566 [00:07<04:15,  2.17it/s, loss=1.05] \u001b[A\n",
      "  2%|▏         | 13/566 [00:07<04:12,  2.19it/s, loss=1.05]\u001b[A\n",
      "  2%|▏         | 13/566 [00:08<04:12,  2.19it/s, loss=0.973]\u001b[A\n",
      "  2%|▏         | 14/566 [00:08<04:09,  2.21it/s, loss=0.973]\u001b[A\n",
      "  2%|▏         | 14/566 [00:08<04:09,  2.21it/s, loss=0.887]\u001b[A\n",
      "  3%|▎         | 15/566 [00:08<04:08,  2.22it/s, loss=0.887]\u001b[A\n",
      "  3%|▎         | 15/566 [00:09<04:08,  2.22it/s, loss=0.9]  \u001b[A\n",
      "  3%|▎         | 16/566 [00:09<04:06,  2.23it/s, loss=0.9]\u001b[A\n",
      "  3%|▎         | 16/566 [00:09<04:06,  2.23it/s, loss=0.97]\u001b[A\n",
      "  3%|▎         | 17/566 [00:09<04:05,  2.23it/s, loss=0.97]\u001b[A\n",
      "  3%|▎         | 17/566 [00:10<04:05,  2.23it/s, loss=1.03]\u001b[A\n",
      "  3%|▎         | 18/566 [00:10<04:04,  2.24it/s, loss=1.03]\u001b[A\n",
      "  3%|▎         | 18/566 [00:10<04:04,  2.24it/s, loss=1.05]\u001b[A\n",
      "  3%|▎         | 19/566 [00:10<04:04,  2.24it/s, loss=1.05]\u001b[A\n",
      "  3%|▎         | 19/566 [00:11<04:04,  2.24it/s, loss=1.18]\u001b[A\n",
      "  4%|▎         | 20/566 [00:11<04:03,  2.24it/s, loss=1.18]\u001b[A\n",
      "  4%|▎         | 20/566 [00:11<04:03,  2.24it/s, loss=0.992]\u001b[A\n",
      "  4%|▎         | 21/566 [00:11<04:02,  2.24it/s, loss=0.992]\u001b[A\n",
      "  4%|▎         | 21/566 [00:11<04:02,  2.24it/s, loss=1.06] \u001b[A\n",
      "  4%|▍         | 22/566 [00:11<04:03,  2.24it/s, loss=1.06]\u001b[A\n",
      "  4%|▍         | 22/566 [00:12<04:03,  2.24it/s, loss=0.953]\u001b[A\n",
      "  4%|▍         | 23/566 [00:12<04:03,  2.23it/s, loss=0.953]\u001b[A\n",
      "  4%|▍         | 23/566 [00:12<04:03,  2.23it/s, loss=0.919]\u001b[A\n",
      "  4%|▍         | 24/566 [00:12<04:03,  2.23it/s, loss=0.919]\u001b[A\n",
      "  4%|▍         | 24/566 [00:13<04:03,  2.23it/s, loss=0.962]\u001b[A\n",
      "  4%|▍         | 25/566 [00:13<04:02,  2.23it/s, loss=0.962]\u001b[A\n",
      "  4%|▍         | 25/566 [00:13<04:02,  2.23it/s, loss=1.12] \u001b[A\n",
      "  5%|▍         | 26/566 [00:13<04:02,  2.23it/s, loss=1.12]\u001b[A\n",
      "  5%|▍         | 26/566 [00:14<04:02,  2.23it/s, loss=1.04]\u001b[A\n",
      "  5%|▍         | 27/566 [00:14<04:02,  2.22it/s, loss=1.04]\u001b[A\n",
      "  5%|▍         | 27/566 [00:14<04:02,  2.22it/s, loss=0.88]\u001b[A\n",
      "  5%|▍         | 28/566 [00:14<04:01,  2.22it/s, loss=0.88]\u001b[A\n",
      "  5%|▍         | 28/566 [00:15<04:01,  2.22it/s, loss=1.04]\u001b[A\n",
      "  5%|▌         | 29/566 [00:15<04:01,  2.23it/s, loss=1.04]\u001b[A\n",
      "  5%|▌         | 29/566 [00:15<04:01,  2.23it/s, loss=1.08]\u001b[A\n",
      "  5%|▌         | 30/566 [00:15<04:01,  2.22it/s, loss=1.08]\u001b[A\n",
      "  5%|▌         | 30/566 [00:16<04:01,  2.22it/s, loss=0.986]\u001b[A\n",
      "  5%|▌         | 31/566 [00:16<04:00,  2.22it/s, loss=0.986]\u001b[A\n",
      "  5%|▌         | 31/566 [00:16<04:00,  2.22it/s, loss=1.04] \u001b[A\n",
      "  6%|▌         | 32/566 [00:16<04:00,  2.22it/s, loss=1.04]\u001b[A\n",
      "  6%|▌         | 32/566 [00:16<04:00,  2.22it/s, loss=0.989]\u001b[A\n",
      "  6%|▌         | 33/566 [00:16<04:00,  2.22it/s, loss=0.989]\u001b[A\n",
      "  6%|▌         | 33/566 [00:17<04:00,  2.22it/s, loss=0.951]\u001b[A\n",
      "  6%|▌         | 34/566 [00:17<03:59,  2.22it/s, loss=0.951]\u001b[A\n",
      "  6%|▌         | 34/566 [00:17<03:59,  2.22it/s, loss=0.908]\u001b[A\n",
      "  6%|▌         | 35/566 [00:17<03:58,  2.22it/s, loss=0.908]\u001b[A\n",
      "  6%|▌         | 35/566 [00:18<03:58,  2.22it/s, loss=0.987]\u001b[A\n",
      "  6%|▋         | 36/566 [00:18<03:58,  2.22it/s, loss=0.987]\u001b[A\n",
      "  6%|▋         | 36/566 [00:18<03:58,  2.22it/s, loss=1.02] \u001b[A\n",
      "  7%|▋         | 37/566 [00:18<03:58,  2.22it/s, loss=1.02]\u001b[A\n",
      "  7%|▋         | 37/566 [00:19<03:58,  2.22it/s, loss=0.935]\u001b[A\n",
      "  7%|▋         | 38/566 [00:19<03:57,  2.22it/s, loss=0.935]\u001b[A\n",
      "  7%|▋         | 38/566 [00:19<03:57,  2.22it/s, loss=0.851]\u001b[A\n",
      "  7%|▋         | 39/566 [00:19<03:57,  2.22it/s, loss=0.851]\u001b[A\n",
      "  7%|▋         | 39/566 [00:20<03:57,  2.22it/s, loss=0.794]\u001b[A\n",
      "  7%|▋         | 40/566 [00:20<03:57,  2.21it/s, loss=0.794]\u001b[A\n",
      "  7%|▋         | 40/566 [00:20<03:57,  2.21it/s, loss=1.09] \u001b[A\n",
      "  7%|▋         | 41/566 [00:20<03:56,  2.22it/s, loss=1.09]\u001b[A\n",
      "  7%|▋         | 41/566 [00:20<03:56,  2.22it/s, loss=1.03]\u001b[A\n",
      "  7%|▋         | 42/566 [00:20<03:56,  2.22it/s, loss=1.03]\u001b[A\n",
      "  7%|▋         | 42/566 [00:21<03:56,  2.22it/s, loss=1.03]\u001b[A\n",
      "  8%|▊         | 43/566 [00:21<03:54,  2.23it/s, loss=1.03]\u001b[A\n",
      "  8%|▊         | 43/566 [00:21<03:54,  2.23it/s, loss=1.12]\u001b[A\n",
      "  8%|▊         | 44/566 [00:21<03:54,  2.23it/s, loss=1.12]\u001b[A\n",
      "  8%|▊         | 44/566 [00:22<03:54,  2.23it/s, loss=0.814]\u001b[A\n",
      "  8%|▊         | 45/566 [00:22<03:54,  2.23it/s, loss=0.814]\u001b[A\n",
      "  8%|▊         | 45/566 [00:22<03:54,  2.23it/s, loss=1.05] \u001b[A\n",
      "  8%|▊         | 46/566 [00:22<03:54,  2.22it/s, loss=1.05]\u001b[A\n",
      "  8%|▊         | 46/566 [00:23<03:54,  2.22it/s, loss=0.929]\u001b[A\n",
      "  8%|▊         | 47/566 [00:23<03:54,  2.21it/s, loss=0.929]\u001b[A\n",
      "  8%|▊         | 47/566 [00:23<03:54,  2.21it/s, loss=0.774]\u001b[A\n",
      "  8%|▊         | 48/566 [00:23<03:54,  2.21it/s, loss=0.774]\u001b[A\n",
      "  8%|▊         | 48/566 [00:24<03:54,  2.21it/s, loss=0.649]\u001b[A\n",
      "  9%|▊         | 49/566 [00:24<03:54,  2.21it/s, loss=0.649]\u001b[A\n",
      "  9%|▊         | 49/566 [00:24<03:54,  2.21it/s, loss=0.955]\u001b[A\n",
      "  9%|▉         | 50/566 [00:24<03:54,  2.20it/s, loss=0.955]\u001b[A\n",
      "  9%|▉         | 50/566 [00:25<03:54,  2.20it/s, loss=0.763]\u001b[A\n",
      "  9%|▉         | 51/566 [00:25<03:52,  2.21it/s, loss=0.763]\u001b[A\n",
      "  9%|▉         | 51/566 [00:25<03:52,  2.21it/s, loss=0.578]\u001b[A\n",
      "  9%|▉         | 52/566 [00:25<03:53,  2.20it/s, loss=0.578]\u001b[A\n",
      "  9%|▉         | 52/566 [00:25<03:53,  2.20it/s, loss=0.89] \u001b[A\n",
      "  9%|▉         | 53/566 [00:25<03:52,  2.20it/s, loss=0.89]\u001b[A\n",
      "  9%|▉         | 53/566 [00:26<03:52,  2.20it/s, loss=0.644]\u001b[A\n",
      " 10%|▉         | 54/566 [00:26<03:53,  2.20it/s, loss=0.644]\u001b[A\n",
      " 10%|▉         | 54/566 [00:26<03:53,  2.20it/s, loss=0.803]\u001b[A\n",
      " 10%|▉         | 55/566 [00:26<03:52,  2.20it/s, loss=0.803]\u001b[A\n",
      " 10%|▉         | 55/566 [00:27<03:52,  2.20it/s, loss=0.862]\u001b[A\n",
      " 10%|▉         | 56/566 [00:27<03:50,  2.21it/s, loss=0.862]\u001b[A\n",
      " 10%|▉         | 56/566 [00:27<03:50,  2.21it/s, loss=0.947]\u001b[A\n",
      " 10%|█         | 57/566 [00:27<03:51,  2.20it/s, loss=0.947]\u001b[A\n",
      " 10%|█         | 57/566 [00:28<03:51,  2.20it/s, loss=0.815]\u001b[A\n",
      " 10%|█         | 58/566 [00:28<03:51,  2.20it/s, loss=0.815]\u001b[A\n",
      " 10%|█         | 58/566 [00:28<03:51,  2.20it/s, loss=0.761]\u001b[A\n",
      " 10%|█         | 59/566 [00:28<03:51,  2.19it/s, loss=0.761]\u001b[A\n",
      " 10%|█         | 59/566 [00:29<03:51,  2.19it/s, loss=0.793]\u001b[A\n",
      " 11%|█         | 60/566 [00:29<03:50,  2.19it/s, loss=0.793]\u001b[A\n",
      " 11%|█         | 60/566 [00:29<03:50,  2.19it/s, loss=0.62] \u001b[A\n",
      " 11%|█         | 61/566 [00:29<03:51,  2.18it/s, loss=0.62]\u001b[A\n",
      " 11%|█         | 61/566 [00:30<03:51,  2.18it/s, loss=1.06]\u001b[A\n",
      " 11%|█         | 62/566 [00:30<03:50,  2.18it/s, loss=1.06]\u001b[A\n",
      " 11%|█         | 62/566 [00:30<03:50,  2.18it/s, loss=0.687]\u001b[A\n",
      " 11%|█         | 63/566 [00:30<03:50,  2.18it/s, loss=0.687]\u001b[A\n",
      " 11%|█         | 63/566 [00:30<03:50,  2.18it/s, loss=1.3]  \u001b[A\n",
      " 11%|█▏        | 64/566 [00:30<03:49,  2.19it/s, loss=1.3]\u001b[A\n",
      " 11%|█▏        | 64/566 [00:31<03:49,  2.19it/s, loss=0.699]\u001b[A\n",
      " 11%|█▏        | 65/566 [00:31<03:49,  2.19it/s, loss=0.699]\u001b[A\n",
      " 11%|█▏        | 65/566 [00:31<03:49,  2.19it/s, loss=0.744]\u001b[A\n",
      " 12%|█▏        | 66/566 [00:31<03:48,  2.19it/s, loss=0.744]\u001b[A\n",
      " 12%|█▏        | 66/566 [00:32<03:48,  2.19it/s, loss=0.796]\u001b[A\n",
      " 12%|█▏        | 67/566 [00:32<03:47,  2.19it/s, loss=0.796]\u001b[A\n",
      " 12%|█▏        | 67/566 [00:32<03:47,  2.19it/s, loss=0.843]\u001b[A\n",
      " 12%|█▏        | 68/566 [00:32<03:48,  2.18it/s, loss=0.843]\u001b[A\n",
      " 12%|█▏        | 68/566 [00:33<03:48,  2.18it/s, loss=0.692]\u001b[A\n",
      " 12%|█▏        | 69/566 [00:33<03:47,  2.19it/s, loss=0.692]\u001b[A\n",
      " 12%|█▏        | 69/566 [00:33<03:47,  2.19it/s, loss=0.68] \u001b[A\n",
      " 12%|█▏        | 70/566 [00:33<03:47,  2.18it/s, loss=0.68]\u001b[A\n",
      " 12%|█▏        | 70/566 [00:34<03:47,  2.18it/s, loss=0.727]\u001b[A\n",
      " 13%|█▎        | 71/566 [00:34<03:47,  2.17it/s, loss=0.727]\u001b[A\n",
      " 13%|█▎        | 71/566 [00:34<03:47,  2.17it/s, loss=1.16] \u001b[A\n",
      " 13%|█▎        | 72/566 [00:34<03:47,  2.17it/s, loss=1.16]\u001b[A\n",
      " 13%|█▎        | 72/566 [00:35<03:47,  2.17it/s, loss=0.988]\u001b[A\n",
      " 13%|█▎        | 73/566 [00:35<03:47,  2.17it/s, loss=0.988]\u001b[A\n",
      " 13%|█▎        | 73/566 [00:35<03:47,  2.17it/s, loss=0.913]\u001b[A\n",
      " 13%|█▎        | 74/566 [00:35<03:47,  2.17it/s, loss=0.913]\u001b[A\n",
      " 13%|█▎        | 74/566 [00:36<03:47,  2.17it/s, loss=0.765]\u001b[A\n",
      " 13%|█▎        | 75/566 [00:36<03:43,  2.20it/s, loss=0.765]\u001b[A\n",
      " 13%|█▎        | 75/566 [00:36<03:43,  2.20it/s, loss=0.861]\u001b[A\n",
      " 13%|█▎        | 76/566 [00:36<03:44,  2.18it/s, loss=0.861]\u001b[A\n",
      " 13%|█▎        | 76/566 [00:36<03:44,  2.18it/s, loss=0.854]\u001b[A\n",
      " 14%|█▎        | 77/566 [00:36<03:44,  2.18it/s, loss=0.854]\u001b[A\n",
      " 14%|█▎        | 77/566 [00:37<03:44,  2.18it/s, loss=0.602]\u001b[A\n",
      " 14%|█▍        | 78/566 [00:37<03:44,  2.17it/s, loss=0.602]\u001b[A\n",
      " 14%|█▍        | 78/566 [00:37<03:44,  2.17it/s, loss=0.77] \u001b[A\n",
      " 14%|█▍        | 79/566 [00:37<03:44,  2.17it/s, loss=0.77]\u001b[A\n",
      " 14%|█▍        | 79/566 [00:38<03:44,  2.17it/s, loss=0.871]\u001b[A\n",
      " 14%|█▍        | 80/566 [00:38<03:44,  2.16it/s, loss=0.871]\u001b[A\n",
      " 14%|█▍        | 80/566 [00:38<03:44,  2.16it/s, loss=0.596]\u001b[A\n",
      " 14%|█▍        | 81/566 [00:38<03:43,  2.17it/s, loss=0.596]\u001b[A\n",
      " 14%|█▍        | 81/566 [00:39<03:43,  2.17it/s, loss=0.733]\u001b[A\n",
      " 14%|█▍        | 82/566 [00:39<03:42,  2.18it/s, loss=0.733]\u001b[A\n",
      " 14%|█▍        | 82/566 [00:39<03:42,  2.18it/s, loss=0.866]\u001b[A\n",
      " 15%|█▍        | 83/566 [00:39<03:42,  2.17it/s, loss=0.866]\u001b[A\n",
      " 15%|█▍        | 83/566 [00:40<03:42,  2.17it/s, loss=0.808]\u001b[A\n",
      " 15%|█▍        | 84/566 [00:40<03:42,  2.17it/s, loss=0.808]\u001b[A\n",
      " 15%|█▍        | 84/566 [00:40<03:42,  2.17it/s, loss=0.399]\u001b[A\n",
      " 15%|█▌        | 85/566 [00:40<03:42,  2.16it/s, loss=0.399]\u001b[A\n",
      " 15%|█▌        | 85/566 [00:41<03:42,  2.16it/s, loss=0.49] \u001b[A\n",
      " 15%|█▌        | 86/566 [00:41<03:42,  2.16it/s, loss=0.49]\u001b[A\n",
      " 15%|█▌        | 86/566 [00:41<03:42,  2.16it/s, loss=0.727]\u001b[A\n",
      " 15%|█▌        | 87/566 [00:41<03:42,  2.16it/s, loss=0.727]\u001b[A\n",
      " 15%|█▌        | 87/566 [00:42<03:42,  2.16it/s, loss=0.687]\u001b[A\n",
      " 16%|█▌        | 88/566 [00:42<03:42,  2.15it/s, loss=0.687]\u001b[A\n",
      " 16%|█▌        | 88/566 [00:42<03:42,  2.15it/s, loss=0.7]  \u001b[A\n",
      " 16%|█▌        | 89/566 [00:42<03:41,  2.15it/s, loss=0.7]\u001b[A\n",
      " 16%|█▌        | 89/566 [00:42<03:41,  2.15it/s, loss=0.815]\u001b[A\n",
      " 16%|█▌        | 90/566 [00:42<03:41,  2.15it/s, loss=0.815]\u001b[A\n",
      " 16%|█▌        | 90/566 [00:43<03:41,  2.15it/s, loss=0.812]\u001b[A\n",
      " 16%|█▌        | 91/566 [00:43<03:41,  2.15it/s, loss=0.812]\u001b[A\n",
      " 16%|█▌        | 91/566 [00:43<03:41,  2.15it/s, loss=1.14] \u001b[A\n",
      " 16%|█▋        | 92/566 [00:43<03:40,  2.15it/s, loss=1.14]\u001b[A\n",
      " 16%|█▋        | 92/566 [00:44<03:40,  2.15it/s, loss=0.746]\u001b[A\n",
      " 16%|█▋        | 93/566 [00:44<03:39,  2.15it/s, loss=0.746]\u001b[A\n",
      " 16%|█▋        | 93/566 [00:44<03:39,  2.15it/s, loss=0.669]\u001b[A\n",
      " 17%|█▋        | 94/566 [00:44<03:39,  2.15it/s, loss=0.669]\u001b[A\n",
      " 17%|█▋        | 94/566 [00:45<03:39,  2.15it/s, loss=0.868]\u001b[A\n",
      " 17%|█▋        | 95/566 [00:45<03:38,  2.15it/s, loss=0.868]\u001b[A\n",
      " 17%|█▋        | 95/566 [00:45<03:38,  2.15it/s, loss=0.825]\u001b[A\n",
      " 17%|█▋        | 96/566 [00:45<03:38,  2.15it/s, loss=0.825]\u001b[A\n",
      " 17%|█▋        | 96/566 [00:46<03:38,  2.15it/s, loss=0.61] \u001b[A\n",
      " 17%|█▋        | 97/566 [00:46<03:38,  2.15it/s, loss=0.61]\u001b[A\n",
      " 17%|█▋        | 97/566 [00:46<03:38,  2.15it/s, loss=0.753]\u001b[A\n",
      " 17%|█▋        | 98/566 [00:46<03:37,  2.15it/s, loss=0.753]\u001b[A\n",
      " 17%|█▋        | 98/566 [00:47<03:37,  2.15it/s, loss=0.906]\u001b[A\n",
      " 17%|█▋        | 99/566 [00:47<03:37,  2.15it/s, loss=0.906]\u001b[A\n",
      " 17%|█▋        | 99/566 [00:47<03:37,  2.15it/s, loss=0.68] \u001b[A\n",
      " 18%|█▊        | 100/566 [00:47<03:36,  2.15it/s, loss=0.68]\u001b[A\n",
      " 18%|█▊        | 100/566 [00:48<03:36,  2.15it/s, loss=0.861]\u001b[A\n",
      " 18%|█▊        | 101/566 [00:48<03:37,  2.14it/s, loss=0.861]\u001b[A\n",
      " 18%|█▊        | 101/566 [00:48<03:37,  2.14it/s, loss=0.495]\u001b[A\n",
      " 18%|█▊        | 102/566 [00:48<03:35,  2.15it/s, loss=0.495]\u001b[A\n",
      " 18%|█▊        | 102/566 [00:49<03:35,  2.15it/s, loss=0.536]\u001b[A\n",
      " 18%|█▊        | 103/566 [00:49<03:35,  2.15it/s, loss=0.536]\u001b[A\n",
      " 18%|█▊        | 103/566 [00:49<03:35,  2.15it/s, loss=0.567]\u001b[A\n",
      " 18%|█▊        | 104/566 [00:49<03:34,  2.15it/s, loss=0.567]\u001b[A\n",
      " 18%|█▊        | 104/566 [00:49<03:34,  2.15it/s, loss=0.462]\u001b[A\n",
      " 19%|█▊        | 105/566 [00:49<03:34,  2.15it/s, loss=0.462]\u001b[A\n",
      " 19%|█▊        | 105/566 [00:50<03:34,  2.15it/s, loss=0.435]\u001b[A\n",
      " 19%|█▊        | 106/566 [00:50<03:34,  2.15it/s, loss=0.435]\u001b[A\n",
      " 19%|█▊        | 106/566 [00:50<03:34,  2.15it/s, loss=0.958]\u001b[A\n",
      " 19%|█▉        | 107/566 [00:50<03:34,  2.14it/s, loss=0.958]\u001b[A\n",
      " 19%|█▉        | 107/566 [00:51<03:34,  2.14it/s, loss=1.07] \u001b[A\n",
      " 19%|█▉        | 108/566 [00:51<03:33,  2.14it/s, loss=1.07]\u001b[A\n",
      " 19%|█▉        | 108/566 [00:51<03:33,  2.14it/s, loss=0.687]\u001b[A\n",
      " 19%|█▉        | 109/566 [00:51<03:32,  2.15it/s, loss=0.687]\u001b[A\n",
      " 19%|█▉        | 109/566 [00:52<03:32,  2.15it/s, loss=0.716]\u001b[A\n",
      " 19%|█▉        | 110/566 [00:52<03:31,  2.15it/s, loss=0.716]\u001b[A\n",
      " 19%|█▉        | 110/566 [00:52<03:31,  2.15it/s, loss=0.709]\u001b[A\n",
      " 20%|█▉        | 111/566 [00:52<03:31,  2.15it/s, loss=0.709]\u001b[A\n",
      " 20%|█▉        | 111/566 [00:53<03:31,  2.15it/s, loss=0.69] \u001b[A\n",
      " 20%|█▉        | 112/566 [00:53<03:30,  2.15it/s, loss=0.69]\u001b[A\n",
      " 20%|█▉        | 112/566 [00:53<03:30,  2.15it/s, loss=0.7] \u001b[A\n",
      " 20%|█▉        | 113/566 [00:53<03:31,  2.15it/s, loss=0.7]\u001b[A\n",
      " 20%|█▉        | 113/566 [00:54<03:31,  2.15it/s, loss=0.549]\u001b[A\n",
      " 20%|██        | 114/566 [00:54<03:30,  2.14it/s, loss=0.549]\u001b[A\n",
      " 20%|██        | 114/566 [00:54<03:30,  2.14it/s, loss=0.662]\u001b[A\n",
      " 20%|██        | 115/566 [00:54<03:31,  2.13it/s, loss=0.662]\u001b[A\n",
      " 20%|██        | 115/566 [00:55<03:31,  2.13it/s, loss=0.34] \u001b[A\n",
      " 20%|██        | 116/566 [00:55<03:31,  2.13it/s, loss=0.34]\u001b[A\n",
      " 20%|██        | 116/566 [00:55<03:31,  2.13it/s, loss=0.625]\u001b[A\n",
      " 21%|██        | 117/566 [00:55<03:31,  2.12it/s, loss=0.625]\u001b[A\n",
      " 21%|██        | 117/566 [00:56<03:31,  2.12it/s, loss=1.09] \u001b[A\n",
      " 21%|██        | 118/566 [00:56<03:31,  2.12it/s, loss=1.09]\u001b[A\n",
      " 21%|██        | 118/566 [00:56<03:31,  2.12it/s, loss=0.865]\u001b[A\n",
      " 21%|██        | 119/566 [00:56<03:30,  2.12it/s, loss=0.865]\u001b[A\n",
      " 21%|██        | 119/566 [00:56<03:30,  2.12it/s, loss=0.758]\u001b[A\n",
      " 21%|██        | 120/566 [00:56<03:31,  2.11it/s, loss=0.758]\u001b[A\n",
      " 21%|██        | 120/566 [00:57<03:31,  2.11it/s, loss=0.367]\u001b[A\n",
      " 21%|██▏       | 121/566 [00:57<03:30,  2.11it/s, loss=0.367]\u001b[A\n",
      " 21%|██▏       | 121/566 [00:57<03:30,  2.11it/s, loss=0.853]\u001b[A\n",
      " 22%|██▏       | 122/566 [00:57<03:29,  2.12it/s, loss=0.853]\u001b[A\n",
      " 22%|██▏       | 122/566 [00:58<03:29,  2.12it/s, loss=0.47] \u001b[A\n",
      " 22%|██▏       | 123/566 [00:58<03:29,  2.11it/s, loss=0.47]\u001b[A\n",
      " 22%|██▏       | 123/566 [00:58<03:29,  2.11it/s, loss=0.577]\u001b[A\n",
      " 22%|██▏       | 124/566 [00:58<03:28,  2.12it/s, loss=0.577]\u001b[A\n",
      " 22%|██▏       | 124/566 [00:59<03:28,  2.12it/s, loss=0.741]\u001b[A\n",
      " 22%|██▏       | 125/566 [00:59<03:28,  2.11it/s, loss=0.741]\u001b[A\n",
      " 22%|██▏       | 125/566 [00:59<03:28,  2.11it/s, loss=0.658]\u001b[A\n",
      " 22%|██▏       | 126/566 [00:59<03:27,  2.12it/s, loss=0.658]\u001b[A\n",
      " 22%|██▏       | 126/566 [01:00<03:27,  2.12it/s, loss=0.392]\u001b[A\n",
      " 22%|██▏       | 127/566 [01:00<03:26,  2.12it/s, loss=0.392]\u001b[A\n",
      " 22%|██▏       | 127/566 [01:00<03:26,  2.12it/s, loss=0.426]\u001b[A\n",
      " 23%|██▎       | 128/566 [01:00<03:26,  2.12it/s, loss=0.426]\u001b[A\n",
      " 23%|██▎       | 128/566 [01:01<03:26,  2.12it/s, loss=0.572]\u001b[A\n",
      " 23%|██▎       | 129/566 [01:01<03:26,  2.11it/s, loss=0.572]\u001b[A\n",
      " 23%|██▎       | 129/566 [01:01<03:26,  2.11it/s, loss=0.814]\u001b[A\n",
      " 23%|██▎       | 130/566 [01:01<03:26,  2.11it/s, loss=0.814]\u001b[A\n",
      " 23%|██▎       | 130/566 [01:02<03:26,  2.11it/s, loss=0.499]\u001b[A\n",
      " 23%|██▎       | 131/566 [01:02<03:26,  2.11it/s, loss=0.499]\u001b[A\n",
      " 23%|██▎       | 131/566 [01:02<03:26,  2.11it/s, loss=0.38] \u001b[A\n",
      " 23%|██▎       | 132/566 [01:02<03:26,  2.10it/s, loss=0.38]\u001b[A\n",
      " 23%|██▎       | 132/566 [01:03<03:26,  2.10it/s, loss=0.948]\u001b[A\n",
      " 23%|██▎       | 133/566 [01:03<03:25,  2.10it/s, loss=0.948]\u001b[A\n",
      " 23%|██▎       | 133/566 [01:03<03:25,  2.10it/s, loss=0.613]\u001b[A\n",
      " 24%|██▎       | 134/566 [01:03<03:25,  2.10it/s, loss=0.613]\u001b[A\n",
      " 24%|██▎       | 134/566 [01:04<03:25,  2.10it/s, loss=0.828]\u001b[A\n",
      " 24%|██▍       | 135/566 [01:04<03:25,  2.10it/s, loss=0.828]\u001b[A\n",
      " 24%|██▍       | 135/566 [01:04<03:25,  2.10it/s, loss=0.91] \u001b[A\n",
      " 24%|██▍       | 136/566 [01:04<03:23,  2.11it/s, loss=0.91]\u001b[A\n",
      " 24%|██▍       | 136/566 [01:05<03:23,  2.11it/s, loss=0.855]\u001b[A\n",
      " 24%|██▍       | 137/566 [01:05<03:23,  2.11it/s, loss=0.855]\u001b[A\n",
      " 24%|██▍       | 137/566 [01:05<03:23,  2.11it/s, loss=0.816]\u001b[A\n",
      " 24%|██▍       | 138/566 [01:05<03:23,  2.10it/s, loss=0.816]\u001b[A\n",
      " 24%|██▍       | 138/566 [01:05<03:23,  2.10it/s, loss=0.877]\u001b[A\n",
      " 25%|██▍       | 139/566 [01:05<03:22,  2.11it/s, loss=0.877]\u001b[A\n",
      " 25%|██▍       | 139/566 [01:06<03:22,  2.11it/s, loss=0.671]\u001b[A\n",
      " 25%|██▍       | 140/566 [01:06<03:23,  2.10it/s, loss=0.671]\u001b[A\n",
      " 25%|██▍       | 140/566 [01:06<03:23,  2.10it/s, loss=0.735]\u001b[A\n",
      " 25%|██▍       | 141/566 [01:06<03:23,  2.09it/s, loss=0.735]\u001b[A\n",
      " 25%|██▍       | 141/566 [01:07<03:23,  2.09it/s, loss=0.546]\u001b[A\n",
      " 25%|██▌       | 142/566 [01:07<03:22,  2.10it/s, loss=0.546]\u001b[A\n",
      " 25%|██▌       | 142/566 [01:07<03:22,  2.10it/s, loss=0.812]\u001b[A\n",
      " 25%|██▌       | 143/566 [01:07<03:22,  2.09it/s, loss=0.812]\u001b[A\n",
      " 25%|██▌       | 143/566 [01:08<03:22,  2.09it/s, loss=0.759]\u001b[A\n",
      " 25%|██▌       | 144/566 [01:08<03:22,  2.09it/s, loss=0.759]\u001b[A\n",
      " 25%|██▌       | 144/566 [01:08<03:22,  2.09it/s, loss=0.818]\u001b[A\n",
      " 26%|██▌       | 145/566 [01:08<03:21,  2.09it/s, loss=0.818]\u001b[A\n",
      " 26%|██▌       | 145/566 [01:09<03:21,  2.09it/s, loss=0.682]\u001b[A\n",
      " 26%|██▌       | 146/566 [01:09<03:21,  2.09it/s, loss=0.682]\u001b[A\n",
      " 26%|██▌       | 146/566 [01:09<03:21,  2.09it/s, loss=0.613]\u001b[A\n",
      " 26%|██▌       | 147/566 [01:09<03:21,  2.08it/s, loss=0.613]\u001b[A\n",
      " 26%|██▌       | 147/566 [01:10<03:21,  2.08it/s, loss=0.64] \u001b[A\n",
      " 26%|██▌       | 148/566 [01:10<03:21,  2.08it/s, loss=0.64]\u001b[A\n",
      " 26%|██▌       | 148/566 [01:10<03:21,  2.08it/s, loss=0.756]\u001b[A\n",
      " 26%|██▋       | 149/566 [01:10<03:19,  2.09it/s, loss=0.756]\u001b[A\n",
      " 26%|██▋       | 149/566 [01:11<03:19,  2.09it/s, loss=0.831]\u001b[A\n",
      " 27%|██▋       | 150/566 [01:11<03:19,  2.09it/s, loss=0.831]\u001b[A\n",
      " 27%|██▋       | 150/566 [01:11<03:19,  2.09it/s, loss=0.862]\u001b[A\n",
      " 27%|██▋       | 151/566 [01:11<03:18,  2.09it/s, loss=0.862]\u001b[A\n",
      " 27%|██▋       | 151/566 [01:12<03:18,  2.09it/s, loss=0.848]\u001b[A\n",
      " 27%|██▋       | 152/566 [01:12<03:18,  2.09it/s, loss=0.848]\u001b[A\n",
      " 27%|██▋       | 152/566 [01:12<03:18,  2.09it/s, loss=0.813]\u001b[A\n",
      " 27%|██▋       | 153/566 [01:12<03:17,  2.09it/s, loss=0.813]\u001b[A\n",
      " 27%|██▋       | 153/566 [01:13<03:17,  2.09it/s, loss=0.603]\u001b[A\n",
      " 27%|██▋       | 154/566 [01:13<03:16,  2.10it/s, loss=0.603]\u001b[A\n",
      " 27%|██▋       | 154/566 [01:13<03:16,  2.10it/s, loss=0.7]  \u001b[A\n",
      " 27%|██▋       | 155/566 [01:13<03:16,  2.09it/s, loss=0.7]\u001b[A\n",
      " 27%|██▋       | 155/566 [01:14<03:16,  2.09it/s, loss=0.992]\u001b[A\n",
      " 28%|██▊       | 156/566 [01:14<03:17,  2.08it/s, loss=0.992]\u001b[A\n",
      " 28%|██▊       | 156/566 [01:14<03:17,  2.08it/s, loss=0.843]\u001b[A\n",
      " 28%|██▊       | 157/566 [01:14<03:17,  2.07it/s, loss=0.843]\u001b[A\n",
      " 28%|██▊       | 157/566 [01:15<03:17,  2.07it/s, loss=0.761]\u001b[A\n",
      " 28%|██▊       | 158/566 [01:15<03:16,  2.07it/s, loss=0.761]\u001b[A\n",
      " 28%|██▊       | 158/566 [01:15<03:16,  2.07it/s, loss=0.55] \u001b[A\n",
      " 28%|██▊       | 159/566 [01:15<03:17,  2.06it/s, loss=0.55]\u001b[A\n",
      " 28%|██▊       | 159/566 [01:16<03:17,  2.06it/s, loss=0.633]\u001b[A\n",
      " 28%|██▊       | 160/566 [01:16<03:16,  2.06it/s, loss=0.633]\u001b[A\n",
      " 28%|██▊       | 160/566 [01:16<03:16,  2.06it/s, loss=0.925]\u001b[A\n",
      " 28%|██▊       | 161/566 [01:16<03:16,  2.06it/s, loss=0.925]\u001b[A\n",
      " 28%|██▊       | 161/566 [01:17<03:16,  2.06it/s, loss=0.334]\u001b[A\n",
      " 29%|██▊       | 162/566 [01:17<03:15,  2.07it/s, loss=0.334]\u001b[A\n",
      " 29%|██▊       | 162/566 [01:17<03:15,  2.07it/s, loss=0.674]\u001b[A\n",
      " 29%|██▉       | 163/566 [01:17<03:16,  2.05it/s, loss=0.674]\u001b[A\n",
      " 29%|██▉       | 163/566 [01:18<03:16,  2.05it/s, loss=0.654]\u001b[A\n",
      " 29%|██▉       | 164/566 [01:18<03:15,  2.06it/s, loss=0.654]\u001b[A\n",
      " 29%|██▉       | 164/566 [01:18<03:15,  2.06it/s, loss=0.682]\u001b[A\n",
      " 29%|██▉       | 165/566 [01:18<03:14,  2.06it/s, loss=0.682]\u001b[A\n",
      " 29%|██▉       | 165/566 [01:18<03:14,  2.06it/s, loss=0.696]\u001b[A\n",
      " 29%|██▉       | 166/566 [01:18<03:13,  2.07it/s, loss=0.696]\u001b[A\n",
      " 29%|██▉       | 166/566 [01:19<03:13,  2.07it/s, loss=0.383]\u001b[A\n",
      " 30%|██▉       | 167/566 [01:19<03:14,  2.05it/s, loss=0.383]\u001b[A\n",
      " 30%|██▉       | 167/566 [01:19<03:14,  2.05it/s, loss=1.03] \u001b[A\n",
      " 30%|██▉       | 168/566 [01:19<03:13,  2.06it/s, loss=1.03]\u001b[A\n",
      " 30%|██▉       | 168/566 [01:20<03:13,  2.06it/s, loss=0.566]\u001b[A\n",
      " 30%|██▉       | 169/566 [01:20<03:12,  2.06it/s, loss=0.566]\u001b[A\n",
      " 30%|██▉       | 169/566 [01:20<03:12,  2.06it/s, loss=0.674]\u001b[A\n",
      " 30%|███       | 170/566 [01:20<03:12,  2.06it/s, loss=0.674]\u001b[A\n",
      " 30%|███       | 170/566 [01:21<03:12,  2.06it/s, loss=0.992]\u001b[A\n",
      " 30%|███       | 171/566 [01:21<03:11,  2.06it/s, loss=0.992]\u001b[A\n",
      " 30%|███       | 171/566 [01:21<03:11,  2.06it/s, loss=0.463]\u001b[A\n",
      " 30%|███       | 172/566 [01:21<03:10,  2.07it/s, loss=0.463]\u001b[A\n",
      " 30%|███       | 172/566 [01:22<03:10,  2.07it/s, loss=0.966]\u001b[A\n",
      " 31%|███       | 173/566 [01:22<03:10,  2.06it/s, loss=0.966]\u001b[A\n",
      " 31%|███       | 173/566 [01:22<03:10,  2.06it/s, loss=0.554]\u001b[A\n",
      " 31%|███       | 174/566 [01:22<03:10,  2.06it/s, loss=0.554]\u001b[A\n",
      " 31%|███       | 174/566 [01:23<03:10,  2.06it/s, loss=0.921]\u001b[A\n",
      " 31%|███       | 175/566 [01:23<03:10,  2.06it/s, loss=0.921]\u001b[A\n",
      " 31%|███       | 175/566 [01:23<03:10,  2.06it/s, loss=0.952]\u001b[A\n",
      " 31%|███       | 176/566 [01:23<03:10,  2.05it/s, loss=0.952]\u001b[A\n",
      " 31%|███       | 176/566 [01:24<03:10,  2.05it/s, loss=0.852]\u001b[A\n",
      " 31%|███▏      | 177/566 [01:24<03:09,  2.05it/s, loss=0.852]\u001b[A\n",
      " 31%|███▏      | 177/566 [01:24<03:09,  2.05it/s, loss=0.572]\u001b[A\n",
      " 31%|███▏      | 178/566 [01:24<03:08,  2.06it/s, loss=0.572]\u001b[A\n",
      " 31%|███▏      | 178/566 [01:25<03:08,  2.06it/s, loss=0.827]\u001b[A\n",
      " 32%|███▏      | 179/566 [01:25<03:07,  2.06it/s, loss=0.827]\u001b[A\n",
      " 32%|███▏      | 179/566 [01:25<03:07,  2.06it/s, loss=0.498]\u001b[A\n",
      " 32%|███▏      | 180/566 [01:25<03:05,  2.08it/s, loss=0.498]\u001b[A\n",
      " 32%|███▏      | 180/566 [01:26<03:05,  2.08it/s, loss=0.591]\u001b[A\n",
      " 32%|███▏      | 181/566 [01:26<03:05,  2.08it/s, loss=0.591]\u001b[A\n",
      " 32%|███▏      | 181/566 [01:26<03:05,  2.08it/s, loss=0.8]  \u001b[A\n",
      " 32%|███▏      | 182/566 [01:26<03:05,  2.07it/s, loss=0.8]\u001b[A\n",
      " 32%|███▏      | 182/566 [01:27<03:05,  2.07it/s, loss=0.889]\u001b[A\n",
      " 32%|███▏      | 183/566 [01:27<03:05,  2.06it/s, loss=0.889]\u001b[A\n",
      " 32%|███▏      | 183/566 [01:27<03:05,  2.06it/s, loss=0.633]\u001b[A\n",
      " 33%|███▎      | 184/566 [01:27<03:05,  2.06it/s, loss=0.633]\u001b[A\n",
      " 33%|███▎      | 184/566 [01:28<03:05,  2.06it/s, loss=0.529]\u001b[A\n",
      " 33%|███▎      | 185/566 [01:28<03:06,  2.04it/s, loss=0.529]\u001b[A\n",
      " 33%|███▎      | 185/566 [01:28<03:06,  2.04it/s, loss=0.741]\u001b[A\n",
      " 33%|███▎      | 186/566 [01:28<03:06,  2.04it/s, loss=0.741]\u001b[A\n",
      " 33%|███▎      | 186/566 [01:29<03:06,  2.04it/s, loss=0.569]\u001b[A\n",
      " 33%|███▎      | 187/566 [01:29<03:06,  2.03it/s, loss=0.569]\u001b[A\n",
      " 33%|███▎      | 187/566 [01:29<03:06,  2.03it/s, loss=0.5]  \u001b[A\n",
      " 33%|███▎      | 188/566 [01:29<03:06,  2.02it/s, loss=0.5]\u001b[A\n",
      " 33%|███▎      | 188/566 [01:30<03:06,  2.02it/s, loss=0.699]\u001b[A\n",
      " 33%|███▎      | 189/566 [01:30<03:07,  2.01it/s, loss=0.699]\u001b[A\n",
      " 33%|███▎      | 189/566 [01:30<03:07,  2.01it/s, loss=0.718]\u001b[A\n",
      " 34%|███▎      | 190/566 [01:30<03:05,  2.03it/s, loss=0.718]\u001b[A\n",
      " 34%|███▎      | 190/566 [01:31<03:05,  2.03it/s, loss=0.555]\u001b[A\n",
      " 34%|███▎      | 191/566 [01:31<03:04,  2.03it/s, loss=0.555]\u001b[A\n",
      " 34%|███▎      | 191/566 [01:31<03:04,  2.03it/s, loss=0.748]\u001b[A\n",
      " 34%|███▍      | 192/566 [01:31<03:04,  2.03it/s, loss=0.748]\u001b[A\n",
      " 34%|███▍      | 192/566 [01:32<03:04,  2.03it/s, loss=0.749]\u001b[A\n",
      " 34%|███▍      | 193/566 [01:32<03:03,  2.03it/s, loss=0.749]\u001b[A\n",
      " 34%|███▍      | 193/566 [01:32<03:03,  2.03it/s, loss=0.614]\u001b[A\n",
      " 34%|███▍      | 194/566 [01:32<03:02,  2.04it/s, loss=0.614]\u001b[A\n",
      " 34%|███▍      | 194/566 [01:33<03:02,  2.04it/s, loss=0.538]\u001b[A\n",
      " 34%|███▍      | 195/566 [01:33<03:01,  2.04it/s, loss=0.538]\u001b[A\n",
      " 34%|███▍      | 195/566 [01:33<03:01,  2.04it/s, loss=0.697]\u001b[A\n",
      " 35%|███▍      | 196/566 [01:33<03:00,  2.05it/s, loss=0.697]\u001b[A\n",
      " 35%|███▍      | 196/566 [01:34<03:00,  2.05it/s, loss=0.6]  \u001b[A\n",
      " 35%|███▍      | 197/566 [01:34<03:00,  2.05it/s, loss=0.6]\u001b[A\n",
      " 35%|███▍      | 197/566 [01:34<03:00,  2.05it/s, loss=0.545]\u001b[A\n",
      " 35%|███▍      | 198/566 [01:34<02:59,  2.05it/s, loss=0.545]\u001b[A\n",
      " 35%|███▍      | 198/566 [01:35<02:59,  2.05it/s, loss=0.749]\u001b[A\n",
      " 35%|███▌      | 199/566 [01:35<02:59,  2.05it/s, loss=0.749]\u001b[A\n",
      " 35%|███▌      | 199/566 [01:35<02:59,  2.05it/s, loss=0.338]\u001b[A\n",
      " 35%|███▌      | 200/566 [01:35<03:00,  2.03it/s, loss=0.338]\u001b[A\n",
      " 35%|███▌      | 200/566 [01:36<03:00,  2.03it/s, loss=0.453]\u001b[A\n",
      " 36%|███▌      | 201/566 [01:36<02:59,  2.04it/s, loss=0.453]\u001b[A\n",
      " 36%|███▌      | 201/566 [01:36<02:59,  2.04it/s, loss=0.422]\u001b[A\n",
      " 36%|███▌      | 202/566 [01:36<02:59,  2.03it/s, loss=0.422]\u001b[A\n",
      " 36%|███▌      | 202/566 [01:37<02:59,  2.03it/s, loss=0.798]\u001b[A\n",
      " 36%|███▌      | 203/566 [01:37<02:58,  2.03it/s, loss=0.798]\u001b[A\n",
      " 36%|███▌      | 203/566 [01:37<02:58,  2.03it/s, loss=0.839]\u001b[A\n",
      " 36%|███▌      | 204/566 [01:37<02:57,  2.04it/s, loss=0.839]\u001b[A\n",
      " 36%|███▌      | 204/566 [01:38<02:57,  2.04it/s, loss=1.32] \u001b[A\n",
      " 36%|███▌      | 205/566 [01:38<02:57,  2.03it/s, loss=1.32]\u001b[A\n",
      " 36%|███▌      | 205/566 [01:38<02:57,  2.03it/s, loss=0.582]\u001b[A\n",
      " 36%|███▋      | 206/566 [01:38<02:57,  2.03it/s, loss=0.582]\u001b[A\n",
      " 36%|███▋      | 206/566 [01:39<02:57,  2.03it/s, loss=0.342]\u001b[A\n",
      " 37%|███▋      | 207/566 [01:39<02:57,  2.02it/s, loss=0.342]\u001b[A\n",
      " 37%|███▋      | 207/566 [01:39<02:57,  2.02it/s, loss=0.958]\u001b[A\n",
      " 37%|███▋      | 208/566 [01:39<02:57,  2.02it/s, loss=0.958]\u001b[A\n",
      " 37%|███▋      | 208/566 [01:40<02:57,  2.02it/s, loss=0.681]\u001b[A\n",
      " 37%|███▋      | 209/566 [01:40<02:55,  2.03it/s, loss=0.681]\u001b[A\n",
      " 37%|███▋      | 209/566 [01:40<02:55,  2.03it/s, loss=0.796]\u001b[A\n",
      " 37%|███▋      | 210/566 [01:40<02:55,  2.03it/s, loss=0.796]\u001b[A\n",
      " 37%|███▋      | 210/566 [01:41<02:55,  2.03it/s, loss=0.456]\u001b[A\n",
      " 37%|███▋      | 211/566 [01:41<02:55,  2.02it/s, loss=0.456]\u001b[A\n",
      " 37%|███▋      | 211/566 [01:41<02:55,  2.02it/s, loss=0.72] \u001b[A\n",
      " 37%|███▋      | 212/566 [01:41<02:54,  2.03it/s, loss=0.72]\u001b[A\n",
      " 37%|███▋      | 212/566 [01:42<02:54,  2.03it/s, loss=0.797]\u001b[A\n",
      " 38%|███▊      | 213/566 [01:42<02:54,  2.02it/s, loss=0.797]\u001b[A\n",
      " 38%|███▊      | 213/566 [01:42<02:54,  2.02it/s, loss=0.438]\u001b[A\n",
      " 38%|███▊      | 214/566 [01:42<02:54,  2.02it/s, loss=0.438]\u001b[A\n",
      " 38%|███▊      | 214/566 [01:43<02:54,  2.02it/s, loss=0.42] \u001b[A\n",
      " 38%|███▊      | 215/566 [01:43<02:53,  2.02it/s, loss=0.42]\u001b[A\n",
      " 38%|███▊      | 215/566 [01:43<02:53,  2.02it/s, loss=0.549]\u001b[A\n",
      " 38%|███▊      | 216/566 [01:43<02:52,  2.02it/s, loss=0.549]\u001b[A\n",
      " 38%|███▊      | 216/566 [01:43<02:52,  2.02it/s, loss=0.531]\u001b[A\n",
      " 38%|███▊      | 217/566 [01:43<02:50,  2.04it/s, loss=0.531]\u001b[A\n",
      " 38%|███▊      | 217/566 [01:44<02:50,  2.04it/s, loss=0.535]\u001b[A\n",
      " 39%|███▊      | 218/566 [01:44<02:51,  2.03it/s, loss=0.535]\u001b[A\n",
      " 39%|███▊      | 218/566 [01:44<02:51,  2.03it/s, loss=0.577]\u001b[A\n",
      " 39%|███▊      | 219/566 [01:44<02:50,  2.04it/s, loss=0.577]\u001b[A\n",
      " 39%|███▊      | 219/566 [01:45<02:50,  2.04it/s, loss=0.609]\u001b[A\n",
      " 39%|███▉      | 220/566 [01:45<02:49,  2.04it/s, loss=0.609]\u001b[A\n",
      " 39%|███▉      | 220/566 [01:45<02:49,  2.04it/s, loss=0.977]\u001b[A\n",
      " 39%|███▉      | 221/566 [01:45<02:49,  2.04it/s, loss=0.977]\u001b[A\n",
      " 39%|███▉      | 221/566 [01:46<02:49,  2.04it/s, loss=0.874]\u001b[A\n",
      " 39%|███▉      | 222/566 [01:46<02:48,  2.04it/s, loss=0.874]\u001b[A\n",
      " 39%|███▉      | 222/566 [01:46<02:48,  2.04it/s, loss=0.609]\u001b[A\n",
      " 39%|███▉      | 223/566 [01:46<02:47,  2.05it/s, loss=0.609]\u001b[A\n",
      " 39%|███▉      | 223/566 [01:47<02:47,  2.05it/s, loss=0.892]\u001b[A\n",
      " 40%|███▉      | 224/566 [01:47<02:46,  2.05it/s, loss=0.892]\u001b[A\n",
      " 40%|███▉      | 224/566 [01:47<02:46,  2.05it/s, loss=0.635]\u001b[A\n",
      " 40%|███▉      | 225/566 [01:47<02:45,  2.06it/s, loss=0.635]\u001b[A\n",
      " 40%|███▉      | 225/566 [01:48<02:45,  2.06it/s, loss=0.582]\u001b[A\n",
      " 40%|███▉      | 226/566 [01:48<02:45,  2.06it/s, loss=0.582]\u001b[A\n",
      " 40%|███▉      | 226/566 [01:48<02:45,  2.06it/s, loss=0.545]\u001b[A\n",
      " 40%|████      | 227/566 [01:48<02:44,  2.06it/s, loss=0.545]\u001b[A\n",
      " 40%|████      | 227/566 [01:49<02:44,  2.06it/s, loss=0.575]\u001b[A\n",
      " 40%|████      | 228/566 [01:49<02:44,  2.06it/s, loss=0.575]\u001b[A\n",
      " 40%|████      | 228/566 [01:49<02:44,  2.06it/s, loss=0.753]\u001b[A\n",
      " 40%|████      | 229/566 [01:49<02:44,  2.05it/s, loss=0.753]\u001b[A\n",
      " 40%|████      | 229/566 [01:50<02:44,  2.05it/s, loss=0.636]\u001b[A\n",
      " 41%|████      | 230/566 [01:50<02:43,  2.06it/s, loss=0.636]\u001b[A\n",
      " 41%|████      | 230/566 [01:50<02:43,  2.06it/s, loss=0.76] \u001b[A\n",
      " 41%|████      | 231/566 [01:50<02:42,  2.06it/s, loss=0.76]\u001b[A\n",
      " 41%|████      | 231/566 [01:51<02:42,  2.06it/s, loss=0.758]\u001b[A\n",
      " 41%|████      | 232/566 [01:51<02:41,  2.06it/s, loss=0.758]\u001b[A\n",
      " 41%|████      | 232/566 [01:51<02:41,  2.06it/s, loss=0.663]\u001b[A\n",
      " 41%|████      | 233/566 [01:51<02:41,  2.06it/s, loss=0.663]\u001b[A\n",
      " 41%|████      | 233/566 [01:52<02:41,  2.06it/s, loss=0.947]\u001b[A\n",
      " 41%|████▏     | 234/566 [01:52<02:41,  2.06it/s, loss=0.947]\u001b[A\n",
      " 41%|████▏     | 234/566 [01:52<02:41,  2.06it/s, loss=0.505]\u001b[A\n",
      " 42%|████▏     | 235/566 [01:52<02:40,  2.06it/s, loss=0.505]\u001b[A\n",
      " 42%|████▏     | 235/566 [01:53<02:40,  2.06it/s, loss=0.615]\u001b[A\n",
      " 42%|████▏     | 236/566 [01:53<02:40,  2.05it/s, loss=0.615]\u001b[A\n",
      " 42%|████▏     | 236/566 [01:53<02:40,  2.05it/s, loss=0.687]\u001b[A\n",
      " 42%|████▏     | 237/566 [01:53<02:39,  2.06it/s, loss=0.687]\u001b[A\n",
      " 42%|████▏     | 237/566 [01:54<02:39,  2.06it/s, loss=0.635]\u001b[A\n",
      " 42%|████▏     | 238/566 [01:54<02:39,  2.06it/s, loss=0.635]\u001b[A\n",
      " 42%|████▏     | 238/566 [01:54<02:39,  2.06it/s, loss=0.544]\u001b[A\n",
      " 42%|████▏     | 239/566 [01:54<02:38,  2.06it/s, loss=0.544]\u001b[A\n",
      " 42%|████▏     | 239/566 [01:55<02:38,  2.06it/s, loss=0.809]\u001b[A\n",
      " 42%|████▏     | 240/566 [01:55<02:38,  2.06it/s, loss=0.809]\u001b[A\n",
      " 42%|████▏     | 240/566 [01:55<02:38,  2.06it/s, loss=0.805]\u001b[A\n",
      " 43%|████▎     | 241/566 [01:55<02:37,  2.07it/s, loss=0.805]\u001b[A\n",
      " 43%|████▎     | 241/566 [01:56<02:37,  2.07it/s, loss=0.711]\u001b[A\n",
      " 43%|████▎     | 242/566 [01:56<02:37,  2.06it/s, loss=0.711]\u001b[A\n",
      " 43%|████▎     | 242/566 [01:56<02:37,  2.06it/s, loss=0.474]\u001b[A\n",
      " 43%|████▎     | 243/566 [01:56<02:36,  2.06it/s, loss=0.474]\u001b[A\n",
      " 43%|████▎     | 243/566 [01:57<02:36,  2.06it/s, loss=0.362]\u001b[A\n",
      " 43%|████▎     | 244/566 [01:57<02:36,  2.06it/s, loss=0.362]\u001b[A\n",
      " 43%|████▎     | 244/566 [01:57<02:36,  2.06it/s, loss=0.279]\u001b[A\n",
      " 43%|████▎     | 245/566 [01:57<02:35,  2.06it/s, loss=0.279]\u001b[A\n",
      " 43%|████▎     | 245/566 [01:58<02:35,  2.06it/s, loss=0.409]\u001b[A\n",
      " 43%|████▎     | 246/566 [01:58<02:34,  2.06it/s, loss=0.409]\u001b[A\n",
      " 43%|████▎     | 246/566 [01:58<02:34,  2.06it/s, loss=0.771]\u001b[A\n",
      " 44%|████▎     | 247/566 [01:58<02:34,  2.06it/s, loss=0.771]\u001b[A\n",
      " 44%|████▎     | 247/566 [01:59<02:34,  2.06it/s, loss=0.84] \u001b[A\n",
      " 44%|████▍     | 248/566 [01:59<02:34,  2.06it/s, loss=0.84]\u001b[A\n",
      " 44%|████▍     | 248/566 [01:59<02:34,  2.06it/s, loss=0.782]\u001b[A\n",
      " 44%|████▍     | 249/566 [01:59<02:33,  2.07it/s, loss=0.782]\u001b[A\n",
      " 44%|████▍     | 249/566 [02:00<02:33,  2.07it/s, loss=1.04] \u001b[A\n",
      " 44%|████▍     | 250/566 [02:00<02:33,  2.06it/s, loss=1.04]\u001b[A\n",
      " 44%|████▍     | 250/566 [02:00<02:33,  2.06it/s, loss=0.798]\u001b[A\n",
      " 44%|████▍     | 251/566 [02:00<02:32,  2.06it/s, loss=0.798]\u001b[A\n",
      " 44%|████▍     | 251/566 [02:00<02:32,  2.06it/s, loss=0.511]\u001b[A\n",
      " 45%|████▍     | 252/566 [02:00<02:32,  2.05it/s, loss=0.511]\u001b[A\n",
      " 45%|████▍     | 252/566 [02:01<02:32,  2.05it/s, loss=0.71] \u001b[A\n",
      " 45%|████▍     | 253/566 [02:01<02:32,  2.06it/s, loss=0.71]\u001b[A\n",
      " 45%|████▍     | 253/566 [02:01<02:32,  2.06it/s, loss=0.58]\u001b[A\n",
      " 45%|████▍     | 254/566 [02:01<02:31,  2.06it/s, loss=0.58]\u001b[A\n",
      " 45%|████▍     | 254/566 [02:02<02:31,  2.06it/s, loss=0.632]\u001b[A\n",
      " 45%|████▌     | 255/566 [02:02<02:31,  2.06it/s, loss=0.632]\u001b[A\n",
      " 45%|████▌     | 255/566 [02:02<02:31,  2.06it/s, loss=0.771]\u001b[A\n",
      " 45%|████▌     | 256/566 [02:02<02:30,  2.06it/s, loss=0.771]\u001b[A\n",
      " 45%|████▌     | 256/566 [02:03<02:30,  2.06it/s, loss=0.707]\u001b[A\n",
      " 45%|████▌     | 257/566 [02:03<02:29,  2.06it/s, loss=0.707]\u001b[A\n",
      " 45%|████▌     | 257/566 [02:03<02:29,  2.06it/s, loss=0.923]\u001b[A\n",
      " 46%|████▌     | 258/566 [02:03<02:29,  2.06it/s, loss=0.923]\u001b[A\n",
      " 46%|████▌     | 258/566 [02:04<02:29,  2.06it/s, loss=0.633]\u001b[A\n",
      " 46%|████▌     | 259/566 [02:04<02:29,  2.06it/s, loss=0.633]\u001b[A\n",
      " 46%|████▌     | 259/566 [02:04<02:29,  2.06it/s, loss=0.638]\u001b[A\n",
      " 46%|████▌     | 260/566 [02:04<02:28,  2.06it/s, loss=0.638]\u001b[A\n",
      " 46%|████▌     | 260/566 [02:05<02:28,  2.06it/s, loss=0.736]\u001b[A\n",
      " 46%|████▌     | 261/566 [02:05<02:28,  2.06it/s, loss=0.736]\u001b[A\n",
      " 46%|████▌     | 261/566 [02:05<02:28,  2.06it/s, loss=0.857]\u001b[A\n",
      " 46%|████▋     | 262/566 [02:05<02:27,  2.06it/s, loss=0.857]\u001b[A\n",
      " 46%|████▋     | 262/566 [02:06<02:27,  2.06it/s, loss=0.75] \u001b[A\n",
      " 46%|████▋     | 263/566 [02:06<02:27,  2.06it/s, loss=0.75]\u001b[A\n",
      " 46%|████▋     | 263/566 [02:06<02:27,  2.06it/s, loss=0.563]\u001b[A\n",
      " 47%|████▋     | 264/566 [02:06<02:26,  2.06it/s, loss=0.563]\u001b[A\n",
      " 47%|████▋     | 264/566 [02:07<02:26,  2.06it/s, loss=0.375]\u001b[A\n",
      " 47%|████▋     | 265/566 [02:07<02:25,  2.06it/s, loss=0.375]\u001b[A\n",
      " 47%|████▋     | 265/566 [02:07<02:25,  2.06it/s, loss=0.701]\u001b[A\n",
      " 47%|████▋     | 266/566 [02:07<02:25,  2.06it/s, loss=0.701]\u001b[A\n",
      " 47%|████▋     | 266/566 [02:08<02:25,  2.06it/s, loss=0.315]\u001b[A\n",
      " 47%|████▋     | 267/566 [02:08<02:24,  2.07it/s, loss=0.315]\u001b[A\n",
      " 47%|████▋     | 267/566 [02:08<02:24,  2.07it/s, loss=0.533]\u001b[A\n",
      " 47%|████▋     | 268/566 [02:08<02:23,  2.08it/s, loss=0.533]\u001b[A\n",
      " 47%|████▋     | 268/566 [02:09<02:23,  2.08it/s, loss=0.665]\u001b[A\n",
      " 48%|████▊     | 269/566 [02:09<02:23,  2.08it/s, loss=0.665]\u001b[A\n",
      " 48%|████▊     | 269/566 [02:09<02:23,  2.08it/s, loss=0.707]\u001b[A\n",
      " 48%|████▊     | 270/566 [02:09<02:22,  2.07it/s, loss=0.707]\u001b[A\n",
      " 48%|████▊     | 270/566 [02:10<02:22,  2.07it/s, loss=0.468]\u001b[A\n",
      " 48%|████▊     | 271/566 [02:10<02:22,  2.07it/s, loss=0.468]\u001b[A\n",
      " 48%|████▊     | 271/566 [02:10<02:22,  2.07it/s, loss=0.722]\u001b[A\n",
      " 48%|████▊     | 272/566 [02:10<02:22,  2.07it/s, loss=0.722]\u001b[A\n",
      " 48%|████▊     | 272/566 [02:11<02:22,  2.07it/s, loss=0.516]\u001b[A\n",
      " 48%|████▊     | 273/566 [02:11<02:22,  2.06it/s, loss=0.516]\u001b[A\n",
      " 48%|████▊     | 273/566 [02:11<02:22,  2.06it/s, loss=0.527]\u001b[A\n",
      " 48%|████▊     | 274/566 [02:11<02:21,  2.07it/s, loss=0.527]\u001b[A\n",
      " 48%|████▊     | 274/566 [02:12<02:21,  2.07it/s, loss=0.78] \u001b[A\n",
      " 49%|████▊     | 275/566 [02:12<02:20,  2.07it/s, loss=0.78]\u001b[A\n",
      " 49%|████▊     | 275/566 [02:12<02:20,  2.07it/s, loss=0.494]\u001b[A\n",
      " 49%|████▉     | 276/566 [02:12<02:19,  2.07it/s, loss=0.494]\u001b[A\n",
      " 49%|████▉     | 276/566 [02:13<02:19,  2.07it/s, loss=0.995]\u001b[A\n",
      " 49%|████▉     | 277/566 [02:13<02:18,  2.08it/s, loss=0.995]\u001b[A\n",
      " 49%|████▉     | 277/566 [02:13<02:18,  2.08it/s, loss=0.304]\u001b[A\n",
      " 49%|████▉     | 278/566 [02:13<02:18,  2.09it/s, loss=0.304]\u001b[A\n",
      " 49%|████▉     | 278/566 [02:14<02:18,  2.09it/s, loss=0.585]\u001b[A\n",
      " 49%|████▉     | 279/566 [02:14<02:18,  2.08it/s, loss=0.585]\u001b[A\n",
      " 49%|████▉     | 279/566 [02:14<02:18,  2.08it/s, loss=0.516]\u001b[A\n",
      " 49%|████▉     | 280/566 [02:14<02:18,  2.07it/s, loss=0.516]\u001b[A\n",
      " 49%|████▉     | 280/566 [02:15<02:18,  2.07it/s, loss=0.517]\u001b[A\n",
      " 50%|████▉     | 281/566 [02:15<02:17,  2.07it/s, loss=0.517]\u001b[A\n",
      " 50%|████▉     | 281/566 [02:15<02:17,  2.07it/s, loss=0.34] \u001b[A\n",
      " 50%|████▉     | 282/566 [02:15<02:17,  2.07it/s, loss=0.34]\u001b[A\n",
      " 50%|████▉     | 282/566 [02:15<02:17,  2.07it/s, loss=0.388]\u001b[A\n",
      " 50%|█████     | 283/566 [02:15<02:15,  2.08it/s, loss=0.388]\u001b[A\n",
      " 50%|█████     | 283/566 [02:16<02:15,  2.08it/s, loss=0.63] \u001b[A\n",
      " 50%|█████     | 284/566 [02:16<02:15,  2.08it/s, loss=0.63]\u001b[A\n",
      " 50%|█████     | 284/566 [02:16<02:15,  2.08it/s, loss=0.39]\u001b[A\n",
      " 50%|█████     | 285/566 [02:16<02:15,  2.07it/s, loss=0.39]\u001b[A\n",
      " 50%|█████     | 285/566 [02:17<02:15,  2.07it/s, loss=0.816]\u001b[A\n",
      " 51%|█████     | 286/566 [02:17<02:15,  2.07it/s, loss=0.816]\u001b[A\n",
      " 51%|█████     | 286/566 [02:17<02:15,  2.07it/s, loss=0.751]\u001b[A\n",
      " 51%|█████     | 287/566 [02:17<02:14,  2.07it/s, loss=0.751]\u001b[A\n",
      " 51%|█████     | 287/566 [02:18<02:14,  2.07it/s, loss=0.354]\u001b[A\n",
      " 51%|█████     | 288/566 [02:18<02:14,  2.07it/s, loss=0.354]\u001b[A\n",
      " 51%|█████     | 288/566 [02:18<02:14,  2.07it/s, loss=0.365]\u001b[A\n",
      " 51%|█████     | 289/566 [02:18<02:13,  2.07it/s, loss=0.365]\u001b[A\n",
      " 51%|█████     | 289/566 [02:19<02:13,  2.07it/s, loss=0.448]\u001b[A\n",
      " 51%|█████     | 290/566 [02:19<02:13,  2.07it/s, loss=0.448]\u001b[A\n",
      " 51%|█████     | 290/566 [02:19<02:13,  2.07it/s, loss=0.404]\u001b[A\n",
      " 51%|█████▏    | 291/566 [02:19<02:12,  2.08it/s, loss=0.404]\u001b[A\n",
      " 51%|█████▏    | 291/566 [02:20<02:12,  2.08it/s, loss=0.855]\u001b[A\n",
      " 52%|█████▏    | 292/566 [02:20<02:11,  2.08it/s, loss=0.855]\u001b[A\n",
      " 52%|█████▏    | 292/566 [02:20<02:11,  2.08it/s, loss=1.08] \u001b[A\n",
      " 52%|█████▏    | 293/566 [02:20<02:11,  2.08it/s, loss=1.08]\u001b[A\n",
      " 52%|█████▏    | 293/566 [02:21<02:11,  2.08it/s, loss=0.875]\u001b[A\n",
      " 52%|█████▏    | 294/566 [02:21<02:10,  2.08it/s, loss=0.875]\u001b[A\n",
      " 52%|█████▏    | 294/566 [02:21<02:10,  2.08it/s, loss=0.267]\u001b[A\n",
      " 52%|█████▏    | 295/566 [02:21<02:10,  2.08it/s, loss=0.267]\u001b[A\n",
      " 52%|█████▏    | 295/566 [02:22<02:10,  2.08it/s, loss=0.905]\u001b[A\n",
      " 52%|█████▏    | 296/566 [02:22<02:10,  2.08it/s, loss=0.905]\u001b[A\n",
      " 52%|█████▏    | 296/566 [02:22<02:10,  2.08it/s, loss=0.582]\u001b[A\n",
      " 52%|█████▏    | 297/566 [02:22<02:09,  2.07it/s, loss=0.582]\u001b[A\n",
      " 52%|█████▏    | 297/566 [02:23<02:09,  2.07it/s, loss=0.502]\u001b[A\n",
      " 53%|█████▎    | 298/566 [02:23<02:09,  2.07it/s, loss=0.502]\u001b[A\n",
      " 53%|█████▎    | 298/566 [02:23<02:09,  2.07it/s, loss=0.364]\u001b[A\n",
      " 53%|█████▎    | 299/566 [02:23<02:08,  2.07it/s, loss=0.364]\u001b[A\n",
      " 53%|█████▎    | 299/566 [02:24<02:08,  2.07it/s, loss=0.388]\u001b[A\n",
      " 53%|█████▎    | 300/566 [02:24<02:08,  2.07it/s, loss=0.388]\u001b[A\n",
      " 53%|█████▎    | 300/566 [02:24<02:08,  2.07it/s, loss=0.401]\u001b[A\n",
      " 53%|█████▎    | 301/566 [02:24<02:08,  2.06it/s, loss=0.401]\u001b[A\n",
      " 53%|█████▎    | 301/566 [02:25<02:08,  2.06it/s, loss=1.06] \u001b[A\n",
      " 53%|█████▎    | 302/566 [02:25<02:08,  2.06it/s, loss=1.06]\u001b[A\n",
      " 53%|█████▎    | 302/566 [02:25<02:08,  2.06it/s, loss=0.402]\u001b[A\n",
      " 54%|█████▎    | 303/566 [02:25<02:07,  2.06it/s, loss=0.402]\u001b[A\n",
      " 54%|█████▎    | 303/566 [02:26<02:07,  2.06it/s, loss=0.557]\u001b[A\n",
      " 54%|█████▎    | 304/566 [02:26<02:06,  2.06it/s, loss=0.557]\u001b[A\n",
      " 54%|█████▎    | 304/566 [02:26<02:06,  2.06it/s, loss=0.546]\u001b[A\n",
      " 54%|█████▍    | 305/566 [02:26<02:06,  2.06it/s, loss=0.546]\u001b[A\n",
      " 54%|█████▍    | 305/566 [02:27<02:06,  2.06it/s, loss=0.516]\u001b[A\n",
      " 54%|█████▍    | 306/566 [02:27<02:06,  2.06it/s, loss=0.516]\u001b[A\n",
      " 54%|█████▍    | 306/566 [02:27<02:06,  2.06it/s, loss=0.572]\u001b[A\n",
      " 54%|█████▍    | 307/566 [02:27<02:05,  2.06it/s, loss=0.572]\u001b[A\n",
      " 54%|█████▍    | 307/566 [02:28<02:05,  2.06it/s, loss=0.833]\u001b[A\n",
      " 54%|█████▍    | 308/566 [02:28<02:04,  2.08it/s, loss=0.833]\u001b[A\n",
      " 54%|█████▍    | 308/566 [02:28<02:04,  2.08it/s, loss=0.367]\u001b[A\n",
      " 55%|█████▍    | 309/566 [02:28<02:03,  2.08it/s, loss=0.367]\u001b[A\n",
      " 55%|█████▍    | 309/566 [02:29<02:03,  2.08it/s, loss=0.6]  \u001b[A\n",
      " 55%|█████▍    | 310/566 [02:29<02:03,  2.08it/s, loss=0.6]\u001b[A\n",
      " 55%|█████▍    | 310/566 [02:29<02:03,  2.08it/s, loss=0.672]\u001b[A\n",
      " 55%|█████▍    | 311/566 [02:29<02:02,  2.07it/s, loss=0.672]\u001b[A\n",
      " 55%|█████▍    | 311/566 [02:29<02:02,  2.07it/s, loss=0.791]\u001b[A\n",
      " 55%|█████▌    | 312/566 [02:29<02:01,  2.09it/s, loss=0.791]\u001b[A\n",
      " 55%|█████▌    | 312/566 [02:30<02:01,  2.09it/s, loss=0.64] \u001b[A\n",
      " 55%|█████▌    | 313/566 [02:30<02:01,  2.08it/s, loss=0.64]\u001b[A\n",
      " 55%|█████▌    | 313/566 [02:30<02:01,  2.08it/s, loss=0.455]\u001b[A\n",
      " 55%|█████▌    | 314/566 [02:30<02:01,  2.08it/s, loss=0.455]\u001b[A\n",
      " 55%|█████▌    | 314/566 [02:31<02:01,  2.08it/s, loss=0.645]\u001b[A\n",
      " 56%|█████▌    | 315/566 [02:31<02:00,  2.07it/s, loss=0.645]\u001b[A\n",
      " 56%|█████▌    | 315/566 [02:31<02:00,  2.07it/s, loss=0.623]\u001b[A\n",
      " 56%|█████▌    | 316/566 [02:31<02:00,  2.07it/s, loss=0.623]\u001b[A\n",
      " 56%|█████▌    | 316/566 [02:32<02:00,  2.07it/s, loss=0.794]\u001b[A\n",
      " 56%|█████▌    | 317/566 [02:32<02:00,  2.07it/s, loss=0.794]\u001b[A\n",
      " 56%|█████▌    | 317/566 [02:32<02:00,  2.07it/s, loss=0.343]\u001b[A\n",
      " 56%|█████▌    | 318/566 [02:32<01:59,  2.08it/s, loss=0.343]\u001b[A\n",
      " 56%|█████▌    | 318/566 [02:33<01:59,  2.08it/s, loss=0.485]\u001b[A\n",
      " 56%|█████▋    | 319/566 [02:33<01:59,  2.07it/s, loss=0.485]\u001b[A\n",
      " 56%|█████▋    | 319/566 [02:33<01:59,  2.07it/s, loss=0.652]\u001b[A\n",
      " 57%|█████▋    | 320/566 [02:33<01:58,  2.07it/s, loss=0.652]\u001b[A\n",
      " 57%|█████▋    | 320/566 [02:34<01:58,  2.07it/s, loss=0.855]\u001b[A\n",
      " 57%|█████▋    | 321/566 [02:34<01:58,  2.07it/s, loss=0.855]\u001b[A\n",
      " 57%|█████▋    | 321/566 [02:34<01:58,  2.07it/s, loss=1.04] \u001b[A\n",
      " 57%|█████▋    | 322/566 [02:34<01:58,  2.07it/s, loss=1.04]\u001b[A\n",
      " 57%|█████▋    | 322/566 [02:35<01:58,  2.07it/s, loss=0.659]\u001b[A\n",
      " 57%|█████▋    | 323/566 [02:35<01:56,  2.08it/s, loss=0.659]\u001b[A\n",
      " 57%|█████▋    | 323/566 [02:35<01:56,  2.08it/s, loss=0.478]\u001b[A\n",
      " 57%|█████▋    | 324/566 [02:35<01:56,  2.08it/s, loss=0.478]\u001b[A\n",
      " 57%|█████▋    | 324/566 [02:36<01:56,  2.08it/s, loss=0.516]\u001b[A\n",
      " 57%|█████▋    | 325/566 [02:36<01:55,  2.09it/s, loss=0.516]\u001b[A\n",
      " 57%|█████▋    | 325/566 [02:36<01:55,  2.09it/s, loss=0.561]\u001b[A\n",
      " 58%|█████▊    | 326/566 [02:36<01:55,  2.08it/s, loss=0.561]\u001b[A\n",
      " 58%|█████▊    | 326/566 [02:37<01:55,  2.08it/s, loss=0.844]\u001b[A\n",
      " 58%|█████▊    | 327/566 [02:37<01:55,  2.07it/s, loss=0.844]\u001b[A\n",
      " 58%|█████▊    | 327/566 [02:37<01:55,  2.07it/s, loss=0.955]\u001b[A\n",
      " 58%|█████▊    | 328/566 [02:37<01:54,  2.07it/s, loss=0.955]\u001b[A\n",
      " 58%|█████▊    | 328/566 [02:38<01:54,  2.07it/s, loss=0.663]\u001b[A\n",
      " 58%|█████▊    | 329/566 [02:38<01:54,  2.07it/s, loss=0.663]\u001b[A\n",
      " 58%|█████▊    | 329/566 [02:38<01:54,  2.07it/s, loss=0.574]\u001b[A\n",
      " 58%|█████▊    | 330/566 [02:38<01:54,  2.07it/s, loss=0.574]\u001b[A\n",
      " 58%|█████▊    | 330/566 [02:39<01:54,  2.07it/s, loss=0.8]  \u001b[A\n",
      " 58%|█████▊    | 331/566 [02:39<01:54,  2.06it/s, loss=0.8]\u001b[A\n",
      " 58%|█████▊    | 331/566 [02:39<01:54,  2.06it/s, loss=0.566]\u001b[A\n",
      " 59%|█████▊    | 332/566 [02:39<01:53,  2.06it/s, loss=0.566]\u001b[A\n",
      " 59%|█████▊    | 332/566 [02:40<01:53,  2.06it/s, loss=0.439]\u001b[A\n",
      " 59%|█████▉    | 333/566 [02:40<01:52,  2.06it/s, loss=0.439]\u001b[A\n",
      " 59%|█████▉    | 333/566 [02:40<01:52,  2.06it/s, loss=0.481]\u001b[A\n",
      " 59%|█████▉    | 334/566 [02:40<01:51,  2.07it/s, loss=0.481]\u001b[A\n",
      " 59%|█████▉    | 334/566 [02:41<01:51,  2.07it/s, loss=0.824]\u001b[A\n",
      " 59%|█████▉    | 335/566 [02:41<01:51,  2.07it/s, loss=0.824]\u001b[A\n",
      " 59%|█████▉    | 335/566 [02:41<01:51,  2.07it/s, loss=0.525]\u001b[A\n",
      " 59%|█████▉    | 336/566 [02:41<01:50,  2.08it/s, loss=0.525]\u001b[A\n",
      " 59%|█████▉    | 336/566 [02:42<01:50,  2.08it/s, loss=0.517]\u001b[A\n",
      " 60%|█████▉    | 337/566 [02:42<01:50,  2.07it/s, loss=0.517]\u001b[A\n",
      " 60%|█████▉    | 337/566 [02:42<01:50,  2.07it/s, loss=0.627]\u001b[A\n",
      " 60%|█████▉    | 338/566 [02:42<01:50,  2.06it/s, loss=0.627]\u001b[A\n",
      " 60%|█████▉    | 338/566 [02:43<01:50,  2.06it/s, loss=0.556]\u001b[A\n",
      " 60%|█████▉    | 339/566 [02:43<01:49,  2.07it/s, loss=0.556]\u001b[A\n",
      " 60%|█████▉    | 339/566 [02:43<01:49,  2.07it/s, loss=0.57] \u001b[A\n",
      " 60%|██████    | 340/566 [02:43<01:49,  2.06it/s, loss=0.57]\u001b[A\n",
      " 60%|██████    | 340/566 [02:43<01:49,  2.06it/s, loss=0.85]\u001b[A\n",
      " 60%|██████    | 341/566 [02:43<01:48,  2.07it/s, loss=0.85]\u001b[A\n",
      " 60%|██████    | 341/566 [02:44<01:48,  2.07it/s, loss=0.992]\u001b[A\n",
      " 60%|██████    | 342/566 [02:44<01:48,  2.06it/s, loss=0.992]\u001b[A\n",
      " 60%|██████    | 342/566 [02:44<01:48,  2.06it/s, loss=0.406]\u001b[A\n",
      " 61%|██████    | 343/566 [02:44<01:48,  2.06it/s, loss=0.406]\u001b[A\n",
      " 61%|██████    | 343/566 [02:45<01:48,  2.06it/s, loss=0.539]\u001b[A\n",
      " 61%|██████    | 344/566 [02:45<01:48,  2.06it/s, loss=0.539]\u001b[A\n",
      " 61%|██████    | 344/566 [02:45<01:48,  2.06it/s, loss=0.257]\u001b[A\n",
      " 61%|██████    | 345/566 [02:45<01:47,  2.06it/s, loss=0.257]\u001b[A\n",
      " 61%|██████    | 345/566 [02:46<01:47,  2.06it/s, loss=0.386]\u001b[A\n",
      " 61%|██████    | 346/566 [02:46<01:46,  2.06it/s, loss=0.386]\u001b[A\n",
      " 61%|██████    | 346/566 [02:46<01:46,  2.06it/s, loss=0.703]\u001b[A\n",
      " 61%|██████▏   | 347/566 [02:46<01:46,  2.05it/s, loss=0.703]\u001b[A\n",
      " 61%|██████▏   | 347/566 [02:47<01:46,  2.05it/s, loss=0.903]\u001b[A\n",
      " 61%|██████▏   | 348/566 [02:47<01:46,  2.05it/s, loss=0.903]\u001b[A\n",
      " 61%|██████▏   | 348/566 [02:47<01:46,  2.05it/s, loss=0.353]\u001b[A\n",
      " 62%|██████▏   | 349/566 [02:47<01:45,  2.06it/s, loss=0.353]\u001b[A\n",
      " 62%|██████▏   | 349/566 [02:48<01:45,  2.06it/s, loss=0.661]\u001b[A\n",
      " 62%|██████▏   | 350/566 [02:48<01:45,  2.06it/s, loss=0.661]\u001b[A\n",
      " 62%|██████▏   | 350/566 [02:48<01:45,  2.06it/s, loss=0.74] \u001b[A\n",
      " 62%|██████▏   | 351/566 [02:48<01:44,  2.06it/s, loss=0.74]\u001b[A\n",
      " 62%|██████▏   | 351/566 [02:49<01:44,  2.06it/s, loss=0.738]\u001b[A\n",
      " 62%|██████▏   | 352/566 [02:49<01:43,  2.06it/s, loss=0.738]\u001b[A\n",
      " 62%|██████▏   | 352/566 [02:49<01:43,  2.06it/s, loss=1]    \u001b[A\n",
      " 62%|██████▏   | 353/566 [02:49<01:43,  2.06it/s, loss=1]\u001b[A\n",
      " 62%|██████▏   | 353/566 [02:50<01:43,  2.06it/s, loss=0.425]\u001b[A\n",
      " 63%|██████▎   | 354/566 [02:50<01:42,  2.06it/s, loss=0.425]\u001b[A\n",
      " 63%|██████▎   | 354/566 [02:50<01:42,  2.06it/s, loss=0.276]\u001b[A\n",
      " 63%|██████▎   | 355/566 [02:50<01:42,  2.07it/s, loss=0.276]\u001b[A\n",
      " 63%|██████▎   | 355/566 [02:51<01:42,  2.07it/s, loss=0.353]\u001b[A\n",
      " 63%|██████▎   | 356/566 [02:51<01:41,  2.06it/s, loss=0.353]\u001b[A\n",
      " 63%|██████▎   | 356/566 [02:51<01:41,  2.06it/s, loss=0.679]\u001b[A\n",
      " 63%|██████▎   | 357/566 [02:51<01:41,  2.06it/s, loss=0.679]\u001b[A\n",
      " 63%|██████▎   | 357/566 [02:52<01:41,  2.06it/s, loss=0.709]\u001b[A\n",
      " 63%|██████▎   | 358/566 [02:52<01:40,  2.06it/s, loss=0.709]\u001b[A\n",
      " 63%|██████▎   | 358/566 [02:52<01:40,  2.06it/s, loss=0.308]\u001b[A\n",
      " 63%|██████▎   | 359/566 [02:52<01:40,  2.06it/s, loss=0.308]\u001b[A\n",
      " 63%|██████▎   | 359/566 [02:53<01:40,  2.06it/s, loss=0.696]\u001b[A\n",
      " 64%|██████▎   | 360/566 [02:53<01:40,  2.06it/s, loss=0.696]\u001b[A\n",
      " 64%|██████▎   | 360/566 [02:53<01:40,  2.06it/s, loss=0.712]\u001b[A\n",
      " 64%|██████▍   | 361/566 [02:53<01:39,  2.06it/s, loss=0.712]\u001b[A\n",
      " 64%|██████▍   | 361/566 [02:54<01:39,  2.06it/s, loss=0.869]\u001b[A\n",
      " 64%|██████▍   | 362/566 [02:54<01:39,  2.06it/s, loss=0.869]\u001b[A\n",
      " 64%|██████▍   | 362/566 [02:54<01:39,  2.06it/s, loss=0.847]\u001b[A\n",
      " 64%|██████▍   | 363/566 [02:54<01:38,  2.06it/s, loss=0.847]\u001b[A\n",
      " 64%|██████▍   | 363/566 [02:55<01:38,  2.06it/s, loss=0.457]\u001b[A\n",
      " 64%|██████▍   | 364/566 [02:55<01:37,  2.06it/s, loss=0.457]\u001b[A\n",
      " 64%|██████▍   | 364/566 [02:55<01:37,  2.06it/s, loss=0.65] \u001b[A\n",
      " 64%|██████▍   | 365/566 [02:55<01:37,  2.06it/s, loss=0.65]\u001b[A\n",
      " 64%|██████▍   | 365/566 [02:56<01:37,  2.06it/s, loss=0.401]\u001b[A\n",
      " 65%|██████▍   | 366/566 [02:56<01:36,  2.07it/s, loss=0.401]\u001b[A\n",
      " 65%|██████▍   | 366/566 [02:56<01:36,  2.07it/s, loss=0.285]\u001b[A\n",
      " 65%|██████▍   | 367/566 [02:56<01:36,  2.06it/s, loss=0.285]\u001b[A\n",
      " 65%|██████▍   | 367/566 [02:57<01:36,  2.06it/s, loss=0.409]\u001b[A\n",
      " 65%|██████▌   | 368/566 [02:57<01:36,  2.06it/s, loss=0.409]\u001b[A\n",
      " 65%|██████▌   | 368/566 [02:57<01:36,  2.06it/s, loss=0.473]\u001b[A\n",
      " 65%|██████▌   | 369/566 [02:57<01:36,  2.05it/s, loss=0.473]\u001b[A\n",
      " 65%|██████▌   | 369/566 [02:58<01:36,  2.05it/s, loss=0.533]\u001b[A\n",
      " 65%|██████▌   | 370/566 [02:58<01:35,  2.04it/s, loss=0.533]\u001b[A\n",
      " 65%|██████▌   | 370/566 [02:58<01:35,  2.04it/s, loss=0.684]\u001b[A\n",
      " 66%|██████▌   | 371/566 [02:58<01:35,  2.04it/s, loss=0.684]\u001b[A\n",
      " 66%|██████▌   | 371/566 [02:59<01:35,  2.04it/s, loss=0.38] \u001b[A\n",
      " 66%|██████▌   | 372/566 [02:59<01:34,  2.05it/s, loss=0.38]\u001b[A\n",
      " 66%|██████▌   | 372/566 [02:59<01:34,  2.05it/s, loss=0.922]\u001b[A\n",
      " 66%|██████▌   | 373/566 [02:59<01:34,  2.05it/s, loss=0.922]\u001b[A\n",
      " 66%|██████▌   | 373/566 [03:00<01:34,  2.05it/s, loss=0.275]\u001b[A\n",
      " 66%|██████▌   | 374/566 [03:00<01:33,  2.05it/s, loss=0.275]\u001b[A\n",
      " 66%|██████▌   | 374/566 [03:00<01:33,  2.05it/s, loss=0.657]\u001b[A\n",
      " 66%|██████▋   | 375/566 [03:00<01:33,  2.05it/s, loss=0.657]\u001b[A\n",
      " 66%|██████▋   | 375/566 [03:00<01:33,  2.05it/s, loss=0.588]\u001b[A\n",
      " 66%|██████▋   | 376/566 [03:01<01:32,  2.05it/s, loss=0.588]\u001b[A\n",
      " 66%|██████▋   | 376/566 [03:01<01:32,  2.05it/s, loss=0.469]\u001b[A\n",
      " 67%|██████▋   | 377/566 [03:01<01:32,  2.04it/s, loss=0.469]\u001b[A\n",
      " 67%|██████▋   | 377/566 [03:01<01:32,  2.04it/s, loss=0.516]\u001b[A\n",
      " 67%|██████▋   | 378/566 [03:01<01:32,  2.04it/s, loss=0.516]\u001b[A\n",
      " 67%|██████▋   | 378/566 [03:02<01:32,  2.04it/s, loss=0.874]\u001b[A\n",
      " 67%|██████▋   | 379/566 [03:02<01:31,  2.04it/s, loss=0.874]\u001b[A\n",
      " 67%|██████▋   | 379/566 [03:02<01:31,  2.04it/s, loss=0.436]\u001b[A\n",
      " 67%|██████▋   | 380/566 [03:02<01:30,  2.05it/s, loss=0.436]\u001b[A\n",
      " 67%|██████▋   | 380/566 [03:03<01:30,  2.05it/s, loss=0.434]\u001b[A\n",
      " 67%|██████▋   | 381/566 [03:03<01:29,  2.06it/s, loss=0.434]\u001b[A\n",
      " 67%|██████▋   | 381/566 [03:03<01:29,  2.06it/s, loss=0.529]\u001b[A\n",
      " 67%|██████▋   | 382/566 [03:03<01:29,  2.05it/s, loss=0.529]\u001b[A\n",
      " 67%|██████▋   | 382/566 [03:04<01:29,  2.05it/s, loss=0.656]\u001b[A\n",
      " 68%|██████▊   | 383/566 [03:04<01:28,  2.06it/s, loss=0.656]\u001b[A\n",
      " 68%|██████▊   | 383/566 [03:04<01:28,  2.06it/s, loss=0.858]\u001b[A\n",
      " 68%|██████▊   | 384/566 [03:04<01:28,  2.05it/s, loss=0.858]\u001b[A\n",
      " 68%|██████▊   | 384/566 [03:05<01:28,  2.05it/s, loss=0.713]\u001b[A\n",
      " 68%|██████▊   | 385/566 [03:05<01:28,  2.06it/s, loss=0.713]\u001b[A\n",
      " 68%|██████▊   | 385/566 [03:05<01:28,  2.06it/s, loss=0.658]\u001b[A\n",
      " 68%|██████▊   | 386/566 [03:05<01:27,  2.06it/s, loss=0.658]\u001b[A\n",
      " 68%|██████▊   | 386/566 [03:06<01:27,  2.06it/s, loss=0.552]\u001b[A\n",
      " 68%|██████▊   | 387/566 [03:06<01:27,  2.04it/s, loss=0.552]\u001b[A\n",
      " 68%|██████▊   | 387/566 [03:06<01:27,  2.04it/s, loss=0.655]\u001b[A\n",
      " 69%|██████▊   | 388/566 [03:06<01:26,  2.05it/s, loss=0.655]\u001b[A\n",
      " 69%|██████▊   | 388/566 [03:07<01:26,  2.05it/s, loss=0.392]\u001b[A\n",
      " 69%|██████▊   | 389/566 [03:07<01:26,  2.05it/s, loss=0.392]\u001b[A\n",
      " 69%|██████▊   | 389/566 [03:07<01:26,  2.05it/s, loss=0.608]\u001b[A\n",
      " 69%|██████▉   | 390/566 [03:07<01:26,  2.04it/s, loss=0.608]\u001b[A\n",
      " 69%|██████▉   | 390/566 [03:08<01:26,  2.04it/s, loss=0.506]\u001b[A\n",
      " 69%|██████▉   | 391/566 [03:08<01:25,  2.04it/s, loss=0.506]\u001b[A\n",
      " 69%|██████▉   | 391/566 [03:08<01:25,  2.04it/s, loss=0.521]\u001b[A\n",
      " 69%|██████▉   | 392/566 [03:08<01:25,  2.04it/s, loss=0.521]\u001b[A\n",
      " 69%|██████▉   | 392/566 [03:09<01:25,  2.04it/s, loss=0.661]\u001b[A\n",
      " 69%|██████▉   | 393/566 [03:09<01:24,  2.05it/s, loss=0.661]\u001b[A\n",
      " 69%|██████▉   | 393/566 [03:09<01:24,  2.05it/s, loss=1.05] \u001b[A\n",
      " 70%|██████▉   | 394/566 [03:09<01:23,  2.05it/s, loss=1.05]\u001b[A\n",
      " 70%|██████▉   | 394/566 [03:10<01:23,  2.05it/s, loss=0.369]\u001b[A\n",
      " 70%|██████▉   | 395/566 [03:10<01:23,  2.05it/s, loss=0.369]\u001b[A\n",
      " 70%|██████▉   | 395/566 [03:10<01:23,  2.05it/s, loss=0.384]\u001b[A\n",
      " 70%|██████▉   | 396/566 [03:10<01:22,  2.05it/s, loss=0.384]\u001b[A\n",
      " 70%|██████▉   | 396/566 [03:11<01:22,  2.05it/s, loss=0.498]\u001b[A\n",
      " 70%|███████   | 397/566 [03:11<01:22,  2.06it/s, loss=0.498]\u001b[A\n",
      " 70%|███████   | 397/566 [03:11<01:22,  2.06it/s, loss=0.653]\u001b[A\n",
      " 70%|███████   | 398/566 [03:11<01:21,  2.05it/s, loss=0.653]\u001b[A\n",
      " 70%|███████   | 398/566 [03:12<01:21,  2.05it/s, loss=0.472]\u001b[A\n",
      " 70%|███████   | 399/566 [03:12<01:21,  2.06it/s, loss=0.472]\u001b[A\n",
      " 70%|███████   | 399/566 [03:12<01:21,  2.06it/s, loss=0.731]\u001b[A\n",
      " 71%|███████   | 400/566 [03:12<01:20,  2.06it/s, loss=0.731]\u001b[A\n",
      " 71%|███████   | 400/566 [03:13<01:20,  2.06it/s, loss=0.752]\u001b[A\n",
      " 71%|███████   | 401/566 [03:13<01:20,  2.06it/s, loss=0.752]\u001b[A\n",
      " 71%|███████   | 401/566 [03:13<01:20,  2.06it/s, loss=0.345]\u001b[A\n",
      " 71%|███████   | 402/566 [03:13<01:19,  2.06it/s, loss=0.345]\u001b[A\n",
      " 71%|███████   | 402/566 [03:14<01:19,  2.06it/s, loss=0.791]\u001b[A\n",
      " 71%|███████   | 403/566 [03:14<01:18,  2.06it/s, loss=0.791]\u001b[A\n",
      " 71%|███████   | 403/566 [03:14<01:18,  2.06it/s, loss=0.357]\u001b[A\n",
      " 71%|███████▏  | 404/566 [03:14<01:18,  2.06it/s, loss=0.357]\u001b[A\n",
      " 71%|███████▏  | 404/566 [03:15<01:18,  2.06it/s, loss=0.405]\u001b[A\n",
      " 72%|███████▏  | 405/566 [03:15<01:18,  2.05it/s, loss=0.405]\u001b[A\n",
      " 72%|███████▏  | 405/566 [03:15<01:18,  2.05it/s, loss=0.616]\u001b[A\n",
      " 72%|███████▏  | 406/566 [03:15<01:17,  2.06it/s, loss=0.616]\u001b[A\n",
      " 72%|███████▏  | 406/566 [03:16<01:17,  2.06it/s, loss=0.458]\u001b[A\n",
      " 72%|███████▏  | 407/566 [03:16<01:17,  2.06it/s, loss=0.458]\u001b[A\n",
      " 72%|███████▏  | 407/566 [03:16<01:17,  2.06it/s, loss=0.548]\u001b[A\n",
      " 72%|███████▏  | 408/566 [03:16<01:16,  2.06it/s, loss=0.548]\u001b[A\n",
      " 72%|███████▏  | 408/566 [03:17<01:16,  2.06it/s, loss=0.606]\u001b[A\n",
      " 72%|███████▏  | 409/566 [03:17<01:16,  2.07it/s, loss=0.606]\u001b[A\n",
      " 72%|███████▏  | 409/566 [03:17<01:16,  2.07it/s, loss=0.819]\u001b[A\n",
      " 72%|███████▏  | 410/566 [03:17<01:15,  2.07it/s, loss=0.819]\u001b[A\n",
      " 72%|███████▏  | 410/566 [03:18<01:15,  2.07it/s, loss=0.502]\u001b[A\n",
      " 73%|███████▎  | 411/566 [03:18<01:15,  2.06it/s, loss=0.502]\u001b[A\n",
      " 73%|███████▎  | 411/566 [03:18<01:15,  2.06it/s, loss=0.612]\u001b[A\n",
      " 73%|███████▎  | 412/566 [03:18<01:14,  2.06it/s, loss=0.612]\u001b[A\n",
      " 73%|███████▎  | 412/566 [03:19<01:14,  2.06it/s, loss=0.584]\u001b[A\n",
      " 73%|███████▎  | 413/566 [03:19<01:14,  2.06it/s, loss=0.584]\u001b[A\n",
      " 73%|███████▎  | 413/566 [03:19<01:14,  2.06it/s, loss=0.338]\u001b[A\n",
      " 73%|███████▎  | 414/566 [03:19<01:13,  2.06it/s, loss=0.338]\u001b[A\n",
      " 73%|███████▎  | 414/566 [03:19<01:13,  2.06it/s, loss=0.403]\u001b[A\n",
      " 73%|███████▎  | 415/566 [03:19<01:13,  2.06it/s, loss=0.403]\u001b[A\n",
      " 73%|███████▎  | 415/566 [03:20<01:13,  2.06it/s, loss=0.602]\u001b[A\n",
      " 73%|███████▎  | 416/566 [03:20<01:13,  2.05it/s, loss=0.602]\u001b[A\n",
      " 73%|███████▎  | 416/566 [03:20<01:13,  2.05it/s, loss=0.345]\u001b[A\n",
      " 74%|███████▎  | 417/566 [03:20<01:12,  2.06it/s, loss=0.345]\u001b[A\n",
      " 74%|███████▎  | 417/566 [03:21<01:12,  2.06it/s, loss=0.694]\u001b[A\n",
      " 74%|███████▍  | 418/566 [03:21<01:11,  2.07it/s, loss=0.694]\u001b[A\n",
      " 74%|███████▍  | 418/566 [03:21<01:11,  2.07it/s, loss=0.874]\u001b[A\n",
      " 74%|███████▍  | 419/566 [03:21<01:11,  2.06it/s, loss=0.874]\u001b[A\n",
      " 74%|███████▍  | 419/566 [03:22<01:11,  2.06it/s, loss=0.674]\u001b[A\n",
      " 74%|███████▍  | 420/566 [03:22<01:10,  2.07it/s, loss=0.674]\u001b[A\n",
      " 74%|███████▍  | 420/566 [03:22<01:10,  2.07it/s, loss=0.577]\u001b[A\n",
      " 74%|███████▍  | 421/566 [03:22<01:10,  2.06it/s, loss=0.577]\u001b[A\n",
      " 74%|███████▍  | 421/566 [03:23<01:10,  2.06it/s, loss=0.451]\u001b[A\n",
      " 75%|███████▍  | 422/566 [03:23<01:09,  2.06it/s, loss=0.451]\u001b[A\n",
      " 75%|███████▍  | 422/566 [03:23<01:09,  2.06it/s, loss=0.73] \u001b[A\n",
      " 75%|███████▍  | 423/566 [03:23<01:09,  2.06it/s, loss=0.73]\u001b[A\n",
      " 75%|███████▍  | 423/566 [03:24<01:09,  2.06it/s, loss=0.789]\u001b[A\n",
      " 75%|███████▍  | 424/566 [03:24<01:08,  2.06it/s, loss=0.789]\u001b[A\n",
      " 75%|███████▍  | 424/566 [03:24<01:08,  2.06it/s, loss=0.733]\u001b[A\n",
      " 75%|███████▌  | 425/566 [03:24<01:08,  2.06it/s, loss=0.733]\u001b[A\n",
      " 75%|███████▌  | 425/566 [03:25<01:08,  2.06it/s, loss=0.477]\u001b[A\n",
      " 75%|███████▌  | 426/566 [03:25<01:07,  2.06it/s, loss=0.477]\u001b[A\n",
      " 75%|███████▌  | 426/566 [03:25<01:07,  2.06it/s, loss=0.787]\u001b[A\n",
      " 75%|███████▌  | 427/566 [03:25<01:07,  2.06it/s, loss=0.787]\u001b[A\n",
      " 75%|███████▌  | 427/566 [03:26<01:07,  2.06it/s, loss=0.824]\u001b[A\n",
      " 76%|███████▌  | 428/566 [03:26<01:07,  2.06it/s, loss=0.824]\u001b[A\n",
      " 76%|███████▌  | 428/566 [03:26<01:07,  2.06it/s, loss=0.887]\u001b[A\n",
      " 76%|███████▌  | 429/566 [03:26<01:06,  2.05it/s, loss=0.887]\u001b[A\n",
      " 76%|███████▌  | 429/566 [03:27<01:06,  2.05it/s, loss=0.504]\u001b[A\n",
      " 76%|███████▌  | 430/566 [03:27<01:06,  2.06it/s, loss=0.504]\u001b[A\n",
      " 76%|███████▌  | 430/566 [03:27<01:06,  2.06it/s, loss=0.496]\u001b[A\n",
      " 76%|███████▌  | 431/566 [03:27<01:05,  2.07it/s, loss=0.496]\u001b[A\n",
      " 76%|███████▌  | 431/566 [03:28<01:05,  2.07it/s, loss=0.496]\u001b[A\n",
      " 76%|███████▋  | 432/566 [03:28<01:04,  2.07it/s, loss=0.496]\u001b[A\n",
      " 76%|███████▋  | 432/566 [03:28<01:04,  2.07it/s, loss=0.861]\u001b[A\n",
      " 77%|███████▋  | 433/566 [03:28<01:04,  2.05it/s, loss=0.861]\u001b[A\n",
      " 77%|███████▋  | 433/566 [03:29<01:04,  2.05it/s, loss=0.334]\u001b[A\n",
      " 77%|███████▋  | 434/566 [03:29<01:04,  2.06it/s, loss=0.334]\u001b[A\n",
      " 77%|███████▋  | 434/566 [03:29<01:04,  2.06it/s, loss=0.296]\u001b[A\n",
      " 77%|███████▋  | 435/566 [03:29<01:03,  2.07it/s, loss=0.296]\u001b[A\n",
      " 77%|███████▋  | 435/566 [03:30<01:03,  2.07it/s, loss=0.793]\u001b[A\n",
      " 77%|███████▋  | 436/566 [03:30<01:02,  2.06it/s, loss=0.793]\u001b[A\n",
      " 77%|███████▋  | 436/566 [03:30<01:02,  2.06it/s, loss=0.336]\u001b[A\n",
      " 77%|███████▋  | 437/566 [03:30<01:02,  2.06it/s, loss=0.336]\u001b[A\n",
      " 77%|███████▋  | 437/566 [03:31<01:02,  2.06it/s, loss=0.479]\u001b[A\n",
      " 77%|███████▋  | 438/566 [03:31<01:02,  2.06it/s, loss=0.479]\u001b[A\n",
      " 77%|███████▋  | 438/566 [03:31<01:02,  2.06it/s, loss=0.587]\u001b[A\n",
      " 78%|███████▊  | 439/566 [03:31<01:01,  2.06it/s, loss=0.587]\u001b[A\n",
      " 78%|███████▊  | 439/566 [03:32<01:01,  2.06it/s, loss=0.41] \u001b[A\n",
      " 78%|███████▊  | 440/566 [03:32<01:01,  2.05it/s, loss=0.41]\u001b[A\n",
      " 78%|███████▊  | 440/566 [03:32<01:01,  2.05it/s, loss=0.979]\u001b[A\n",
      " 78%|███████▊  | 441/566 [03:32<01:00,  2.05it/s, loss=0.979]\u001b[A\n",
      " 78%|███████▊  | 441/566 [03:33<01:00,  2.05it/s, loss=0.459]\u001b[A\n",
      " 78%|███████▊  | 442/566 [03:33<01:00,  2.05it/s, loss=0.459]\u001b[A\n",
      " 78%|███████▊  | 442/566 [03:33<01:00,  2.05it/s, loss=0.752]\u001b[A\n",
      " 78%|███████▊  | 443/566 [03:33<00:59,  2.06it/s, loss=0.752]\u001b[A\n",
      " 78%|███████▊  | 443/566 [03:34<00:59,  2.06it/s, loss=0.314]\u001b[A\n",
      " 78%|███████▊  | 444/566 [03:34<00:59,  2.06it/s, loss=0.314]\u001b[A\n",
      " 78%|███████▊  | 444/566 [03:34<00:59,  2.06it/s, loss=0.77] \u001b[A\n",
      " 79%|███████▊  | 445/566 [03:34<00:58,  2.06it/s, loss=0.77]\u001b[A\n",
      " 79%|███████▊  | 445/566 [03:35<00:58,  2.06it/s, loss=0.387]\u001b[A\n",
      " 79%|███████▉  | 446/566 [03:35<00:58,  2.07it/s, loss=0.387]\u001b[A\n",
      " 79%|███████▉  | 446/566 [03:35<00:58,  2.07it/s, loss=0.672]\u001b[A\n",
      " 79%|███████▉  | 447/566 [03:35<00:57,  2.06it/s, loss=0.672]\u001b[A\n",
      " 79%|███████▉  | 447/566 [03:35<00:57,  2.06it/s, loss=1.07] \u001b[A\n",
      " 79%|███████▉  | 448/566 [03:36<00:57,  2.06it/s, loss=1.07]\u001b[A\n",
      " 79%|███████▉  | 448/566 [03:36<00:57,  2.06it/s, loss=0.892]\u001b[A\n",
      " 79%|███████▉  | 449/566 [03:36<00:56,  2.06it/s, loss=0.892]\u001b[A\n",
      " 79%|███████▉  | 449/566 [03:36<00:56,  2.06it/s, loss=0.918]\u001b[A\n",
      " 80%|███████▉  | 450/566 [03:36<00:56,  2.05it/s, loss=0.918]\u001b[A\n",
      " 80%|███████▉  | 450/566 [03:37<00:56,  2.05it/s, loss=0.904]\u001b[A\n",
      " 80%|███████▉  | 451/566 [03:37<00:55,  2.06it/s, loss=0.904]\u001b[A\n",
      " 80%|███████▉  | 451/566 [03:37<00:55,  2.06it/s, loss=0.752]\u001b[A\n",
      " 80%|███████▉  | 452/566 [03:37<00:55,  2.07it/s, loss=0.752]\u001b[A\n",
      " 80%|███████▉  | 452/566 [03:38<00:55,  2.07it/s, loss=0.49] \u001b[A\n",
      " 80%|████████  | 453/566 [03:38<00:54,  2.06it/s, loss=0.49]\u001b[A\n",
      " 80%|████████  | 453/566 [03:38<00:54,  2.06it/s, loss=0.941]\u001b[A\n",
      " 80%|████████  | 454/566 [03:38<00:54,  2.06it/s, loss=0.941]\u001b[A\n",
      " 80%|████████  | 454/566 [03:39<00:54,  2.06it/s, loss=0.773]\u001b[A\n",
      " 80%|████████  | 455/566 [03:39<00:53,  2.06it/s, loss=0.773]\u001b[A\n",
      " 80%|████████  | 455/566 [03:39<00:53,  2.06it/s, loss=0.88] \u001b[A\n",
      " 81%|████████  | 456/566 [03:39<00:53,  2.06it/s, loss=0.88]\u001b[A\n",
      " 81%|████████  | 456/566 [03:40<00:53,  2.06it/s, loss=0.855]\u001b[A\n",
      " 81%|████████  | 457/566 [03:40<00:52,  2.06it/s, loss=0.855]\u001b[A\n",
      " 81%|████████  | 457/566 [03:40<00:52,  2.06it/s, loss=0.619]\u001b[A\n",
      " 81%|████████  | 458/566 [03:40<00:52,  2.06it/s, loss=0.619]\u001b[A\n",
      " 81%|████████  | 458/566 [03:41<00:52,  2.06it/s, loss=0.586]\u001b[A\n",
      " 81%|████████  | 459/566 [03:41<00:51,  2.07it/s, loss=0.586]\u001b[A\n",
      " 81%|████████  | 459/566 [03:41<00:51,  2.07it/s, loss=0.639]\u001b[A\n",
      " 81%|████████▏ | 460/566 [03:41<00:51,  2.07it/s, loss=0.639]\u001b[A\n",
      " 81%|████████▏ | 460/566 [03:42<00:51,  2.07it/s, loss=0.745]\u001b[A\n",
      " 81%|████████▏ | 461/566 [03:42<00:50,  2.07it/s, loss=0.745]\u001b[A\n",
      " 81%|████████▏ | 461/566 [03:42<00:50,  2.07it/s, loss=0.558]\u001b[A\n",
      " 82%|████████▏ | 462/566 [03:42<00:50,  2.07it/s, loss=0.558]\u001b[A\n",
      " 82%|████████▏ | 462/566 [03:43<00:50,  2.07it/s, loss=0.581]\u001b[A\n",
      " 82%|████████▏ | 463/566 [03:43<00:50,  2.06it/s, loss=0.581]\u001b[A\n",
      " 82%|████████▏ | 463/566 [03:43<00:50,  2.06it/s, loss=0.441]\u001b[A\n",
      " 82%|████████▏ | 464/566 [03:43<00:49,  2.06it/s, loss=0.441]\u001b[A\n",
      " 82%|████████▏ | 464/566 [03:44<00:49,  2.06it/s, loss=0.648]\u001b[A\n",
      " 82%|████████▏ | 465/566 [03:44<00:48,  2.06it/s, loss=0.648]\u001b[A\n",
      " 82%|████████▏ | 465/566 [03:44<00:48,  2.06it/s, loss=0.631]\u001b[A\n",
      " 82%|████████▏ | 466/566 [03:44<00:48,  2.06it/s, loss=0.631]\u001b[A\n",
      " 82%|████████▏ | 466/566 [03:45<00:48,  2.06it/s, loss=0.381]\u001b[A\n",
      " 83%|████████▎ | 467/566 [03:45<00:48,  2.06it/s, loss=0.381]\u001b[A\n",
      " 83%|████████▎ | 467/566 [03:45<00:48,  2.06it/s, loss=0.252]\u001b[A\n",
      " 83%|████████▎ | 468/566 [03:45<00:47,  2.06it/s, loss=0.252]\u001b[A\n",
      " 83%|████████▎ | 468/566 [03:46<00:47,  2.06it/s, loss=0.517]\u001b[A\n",
      " 83%|████████▎ | 469/566 [03:46<00:46,  2.07it/s, loss=0.517]\u001b[A\n",
      " 83%|████████▎ | 469/566 [03:46<00:46,  2.07it/s, loss=0.508]\u001b[A\n",
      " 83%|████████▎ | 470/566 [03:46<00:46,  2.06it/s, loss=0.508]\u001b[A\n",
      " 83%|████████▎ | 470/566 [03:47<00:46,  2.06it/s, loss=0.716]\u001b[A\n",
      " 83%|████████▎ | 471/566 [03:47<00:46,  2.06it/s, loss=0.716]\u001b[A\n",
      " 83%|████████▎ | 471/566 [03:47<00:46,  2.06it/s, loss=0.36] \u001b[A\n",
      " 83%|████████▎ | 472/566 [03:47<00:45,  2.05it/s, loss=0.36]\u001b[A\n",
      " 83%|████████▎ | 472/566 [03:48<00:45,  2.05it/s, loss=0.846]\u001b[A\n",
      " 84%|████████▎ | 473/566 [03:48<00:45,  2.05it/s, loss=0.846]\u001b[A\n",
      " 84%|████████▎ | 473/566 [03:48<00:45,  2.05it/s, loss=0.65] \u001b[A\n",
      " 84%|████████▎ | 474/566 [03:48<00:44,  2.06it/s, loss=0.65]\u001b[A\n",
      " 84%|████████▎ | 474/566 [03:49<00:44,  2.06it/s, loss=0.405]\u001b[A\n",
      " 84%|████████▍ | 475/566 [03:49<00:44,  2.06it/s, loss=0.405]\u001b[A\n",
      " 84%|████████▍ | 475/566 [03:49<00:44,  2.06it/s, loss=0.443]\u001b[A\n",
      " 84%|████████▍ | 476/566 [03:49<00:43,  2.06it/s, loss=0.443]\u001b[A\n",
      " 84%|████████▍ | 476/566 [03:50<00:43,  2.06it/s, loss=0.549]\u001b[A\n",
      " 84%|████████▍ | 477/566 [03:50<00:43,  2.06it/s, loss=0.549]\u001b[A\n",
      " 84%|████████▍ | 477/566 [03:50<00:43,  2.06it/s, loss=0.657]\u001b[A\n",
      " 84%|████████▍ | 478/566 [03:50<00:42,  2.06it/s, loss=0.657]\u001b[A\n",
      " 84%|████████▍ | 478/566 [03:51<00:42,  2.06it/s, loss=0.803]\u001b[A\n",
      " 85%|████████▍ | 479/566 [03:51<00:42,  2.06it/s, loss=0.803]\u001b[A\n",
      " 85%|████████▍ | 479/566 [03:51<00:42,  2.06it/s, loss=0.843]\u001b[A\n",
      " 85%|████████▍ | 480/566 [03:51<00:41,  2.06it/s, loss=0.843]\u001b[A\n",
      " 85%|████████▍ | 480/566 [03:52<00:41,  2.06it/s, loss=0.378]\u001b[A\n",
      " 85%|████████▍ | 481/566 [03:52<00:41,  2.07it/s, loss=0.378]\u001b[A\n",
      " 85%|████████▍ | 481/566 [03:52<00:41,  2.07it/s, loss=0.577]\u001b[A\n",
      " 85%|████████▌ | 482/566 [03:52<00:40,  2.07it/s, loss=0.577]\u001b[A\n",
      " 85%|████████▌ | 482/566 [03:52<00:40,  2.07it/s, loss=0.345]\u001b[A\n",
      " 85%|████████▌ | 483/566 [03:52<00:40,  2.06it/s, loss=0.345]\u001b[A\n",
      " 85%|████████▌ | 483/566 [03:53<00:40,  2.06it/s, loss=0.442]\u001b[A\n",
      " 86%|████████▌ | 484/566 [03:53<00:39,  2.06it/s, loss=0.442]\u001b[A\n",
      " 86%|████████▌ | 484/566 [03:53<00:39,  2.06it/s, loss=0.484]\u001b[A\n",
      " 86%|████████▌ | 485/566 [03:53<00:39,  2.06it/s, loss=0.484]\u001b[A\n",
      " 86%|████████▌ | 485/566 [03:54<00:39,  2.06it/s, loss=0.423]\u001b[A\n",
      " 86%|████████▌ | 486/566 [03:54<00:38,  2.05it/s, loss=0.423]\u001b[A\n",
      " 86%|████████▌ | 486/566 [03:54<00:38,  2.05it/s, loss=0.697]\u001b[A\n",
      " 86%|████████▌ | 487/566 [03:54<00:38,  2.05it/s, loss=0.697]\u001b[A\n",
      " 86%|████████▌ | 487/566 [03:55<00:38,  2.05it/s, loss=0.886]\u001b[A\n",
      " 86%|████████▌ | 488/566 [03:55<00:37,  2.06it/s, loss=0.886]\u001b[A\n",
      " 86%|████████▌ | 488/566 [03:55<00:37,  2.06it/s, loss=0.564]\u001b[A\n",
      " 86%|████████▋ | 489/566 [03:55<00:37,  2.05it/s, loss=0.564]\u001b[A\n",
      " 86%|████████▋ | 489/566 [03:56<00:37,  2.05it/s, loss=0.664]\u001b[A\n",
      " 87%|████████▋ | 490/566 [03:56<00:36,  2.06it/s, loss=0.664]\u001b[A\n",
      " 87%|████████▋ | 490/566 [03:56<00:36,  2.06it/s, loss=0.607]\u001b[A\n",
      " 87%|████████▋ | 491/566 [03:56<00:36,  2.06it/s, loss=0.607]\u001b[A\n",
      " 87%|████████▋ | 491/566 [03:57<00:36,  2.06it/s, loss=0.551]\u001b[A\n",
      " 87%|████████▋ | 492/566 [03:57<00:35,  2.06it/s, loss=0.551]\u001b[A\n",
      " 87%|████████▋ | 492/566 [03:57<00:35,  2.06it/s, loss=0.56] \u001b[A\n",
      " 87%|████████▋ | 493/566 [03:57<00:35,  2.06it/s, loss=0.56]\u001b[A\n",
      " 87%|████████▋ | 493/566 [03:58<00:35,  2.06it/s, loss=0.404]\u001b[A\n",
      " 87%|████████▋ | 494/566 [03:58<00:34,  2.07it/s, loss=0.404]\u001b[A\n",
      " 87%|████████▋ | 494/566 [03:58<00:34,  2.07it/s, loss=0.705]\u001b[A\n",
      " 87%|████████▋ | 495/566 [03:58<00:34,  2.06it/s, loss=0.705]\u001b[A\n",
      " 87%|████████▋ | 495/566 [03:59<00:34,  2.06it/s, loss=0.759]\u001b[A\n",
      " 88%|████████▊ | 496/566 [03:59<00:33,  2.06it/s, loss=0.759]\u001b[A\n",
      " 88%|████████▊ | 496/566 [03:59<00:33,  2.06it/s, loss=0.278]\u001b[A\n",
      " 88%|████████▊ | 497/566 [03:59<00:33,  2.06it/s, loss=0.278]\u001b[A\n",
      " 88%|████████▊ | 497/566 [04:00<00:33,  2.06it/s, loss=0.586]\u001b[A\n",
      " 88%|████████▊ | 498/566 [04:00<00:32,  2.06it/s, loss=0.586]\u001b[A\n",
      " 88%|████████▊ | 498/566 [04:00<00:32,  2.06it/s, loss=0.821]\u001b[A\n",
      " 88%|████████▊ | 499/566 [04:00<00:32,  2.06it/s, loss=0.821]\u001b[A\n",
      " 88%|████████▊ | 499/566 [04:01<00:32,  2.06it/s, loss=0.475]\u001b[A\n",
      " 88%|████████▊ | 500/566 [04:01<00:32,  2.06it/s, loss=0.475]\u001b[A\n",
      " 88%|████████▊ | 500/566 [04:01<00:32,  2.06it/s, loss=0.727]\u001b[A\n",
      " 89%|████████▊ | 501/566 [04:01<00:31,  2.06it/s, loss=0.727]\u001b[A\n",
      " 89%|████████▊ | 501/566 [04:02<00:31,  2.06it/s, loss=0.561]\u001b[A\n",
      " 89%|████████▊ | 502/566 [04:02<00:31,  2.06it/s, loss=0.561]\u001b[A\n",
      " 89%|████████▊ | 502/566 [04:02<00:31,  2.06it/s, loss=0.286]\u001b[A\n",
      " 89%|████████▉ | 503/566 [04:02<00:30,  2.07it/s, loss=0.286]\u001b[A\n",
      " 89%|████████▉ | 503/566 [04:03<00:30,  2.07it/s, loss=0.737]\u001b[A\n",
      " 89%|████████▉ | 504/566 [04:03<00:30,  2.06it/s, loss=0.737]\u001b[A\n",
      " 89%|████████▉ | 504/566 [04:03<00:30,  2.06it/s, loss=1.28] \u001b[A\n",
      " 89%|████████▉ | 505/566 [04:03<00:29,  2.07it/s, loss=1.28]\u001b[A\n",
      " 89%|████████▉ | 505/566 [04:04<00:29,  2.07it/s, loss=0.896]\u001b[A\n",
      " 89%|████████▉ | 506/566 [04:04<00:28,  2.08it/s, loss=0.896]\u001b[A\n",
      " 89%|████████▉ | 506/566 [04:04<00:28,  2.08it/s, loss=0.424]\u001b[A\n",
      " 90%|████████▉ | 507/566 [04:04<00:28,  2.08it/s, loss=0.424]\u001b[A\n",
      " 90%|████████▉ | 507/566 [04:05<00:28,  2.08it/s, loss=0.7]  \u001b[A\n",
      " 90%|████████▉ | 508/566 [04:05<00:28,  2.07it/s, loss=0.7]\u001b[A\n",
      " 90%|████████▉ | 508/566 [04:05<00:28,  2.07it/s, loss=0.818]\u001b[A\n",
      " 90%|████████▉ | 509/566 [04:05<00:27,  2.07it/s, loss=0.818]\u001b[A\n",
      " 90%|████████▉ | 509/566 [04:06<00:27,  2.07it/s, loss=0.522]\u001b[A\n",
      " 90%|█████████ | 510/566 [04:06<00:27,  2.06it/s, loss=0.522]\u001b[A\n",
      " 90%|█████████ | 510/566 [04:06<00:27,  2.06it/s, loss=0.789]\u001b[A\n",
      " 90%|█████████ | 511/566 [04:06<00:26,  2.06it/s, loss=0.789]\u001b[A\n",
      " 90%|█████████ | 511/566 [04:07<00:26,  2.06it/s, loss=0.819]\u001b[A\n",
      " 90%|█████████ | 512/566 [04:07<00:26,  2.06it/s, loss=0.819]\u001b[A\n",
      " 90%|█████████ | 512/566 [04:07<00:26,  2.06it/s, loss=0.611]\u001b[A\n",
      " 91%|█████████ | 513/566 [04:07<00:25,  2.06it/s, loss=0.611]\u001b[A\n",
      " 91%|█████████ | 513/566 [04:08<00:25,  2.06it/s, loss=0.547]\u001b[A\n",
      " 91%|█████████ | 514/566 [04:08<00:25,  2.06it/s, loss=0.547]\u001b[A\n",
      " 91%|█████████ | 514/566 [04:08<00:25,  2.06it/s, loss=0.418]\u001b[A\n",
      " 91%|█████████ | 515/566 [04:08<00:24,  2.06it/s, loss=0.418]\u001b[A\n",
      " 91%|█████████ | 515/566 [04:08<00:24,  2.06it/s, loss=0.716]\u001b[A\n",
      " 91%|█████████ | 516/566 [04:08<00:24,  2.06it/s, loss=0.716]\u001b[A\n",
      " 91%|█████████ | 516/566 [04:09<00:24,  2.06it/s, loss=1.28] \u001b[A\n",
      " 91%|█████████▏| 517/566 [04:09<00:23,  2.06it/s, loss=1.28]\u001b[A\n",
      " 91%|█████████▏| 517/566 [04:09<00:23,  2.06it/s, loss=0.525]\u001b[A\n",
      " 92%|█████████▏| 518/566 [04:09<00:23,  2.06it/s, loss=0.525]\u001b[A\n",
      " 92%|█████████▏| 518/566 [04:10<00:23,  2.06it/s, loss=0.569]\u001b[A\n",
      " 92%|█████████▏| 519/566 [04:10<00:22,  2.07it/s, loss=0.569]\u001b[A\n",
      " 92%|█████████▏| 519/566 [04:10<00:22,  2.07it/s, loss=0.276]\u001b[A\n",
      " 92%|█████████▏| 520/566 [04:10<00:22,  2.08it/s, loss=0.276]\u001b[A\n",
      " 92%|█████████▏| 520/566 [04:11<00:22,  2.08it/s, loss=0.88] \u001b[A\n",
      " 92%|█████████▏| 521/566 [04:11<00:21,  2.08it/s, loss=0.88]\u001b[A\n",
      " 92%|█████████▏| 521/566 [04:11<00:21,  2.08it/s, loss=0.476]\u001b[A\n",
      " 92%|█████████▏| 522/566 [04:11<00:21,  2.07it/s, loss=0.476]\u001b[A\n",
      " 92%|█████████▏| 522/566 [04:12<00:21,  2.07it/s, loss=1.5]  \u001b[A\n",
      " 92%|█████████▏| 523/566 [04:12<00:20,  2.07it/s, loss=1.5]\u001b[A\n",
      " 92%|█████████▏| 523/566 [04:12<00:20,  2.07it/s, loss=0.805]\u001b[A\n",
      " 93%|█████████▎| 524/566 [04:12<00:20,  2.07it/s, loss=0.805]\u001b[A\n",
      " 93%|█████████▎| 524/566 [04:13<00:20,  2.07it/s, loss=0.412]\u001b[A\n",
      " 93%|█████████▎| 525/566 [04:13<00:19,  2.07it/s, loss=0.412]\u001b[A\n",
      " 93%|█████████▎| 525/566 [04:13<00:19,  2.07it/s, loss=0.389]\u001b[A\n",
      " 93%|█████████▎| 526/566 [04:13<00:19,  2.06it/s, loss=0.389]\u001b[A\n",
      " 93%|█████████▎| 526/566 [04:14<00:19,  2.06it/s, loss=0.347]\u001b[A\n",
      " 93%|█████████▎| 527/566 [04:14<00:18,  2.06it/s, loss=0.347]\u001b[A\n",
      " 93%|█████████▎| 527/566 [04:14<00:18,  2.06it/s, loss=0.91] \u001b[A\n",
      " 93%|█████████▎| 528/566 [04:14<00:18,  2.06it/s, loss=0.91]\u001b[A\n",
      " 93%|█████████▎| 528/566 [04:15<00:18,  2.06it/s, loss=0.674]\u001b[A\n",
      " 93%|█████████▎| 529/566 [04:15<00:18,  2.05it/s, loss=0.674]\u001b[A\n",
      " 93%|█████████▎| 529/566 [04:15<00:18,  2.05it/s, loss=0.644]\u001b[A\n",
      " 94%|█████████▎| 530/566 [04:15<00:17,  2.07it/s, loss=0.644]\u001b[A\n",
      " 94%|█████████▎| 530/566 [04:16<00:17,  2.07it/s, loss=0.524]\u001b[A\n",
      " 94%|█████████▍| 531/566 [04:16<00:17,  2.06it/s, loss=0.524]\u001b[A\n",
      " 94%|█████████▍| 531/566 [04:16<00:17,  2.06it/s, loss=0.886]\u001b[A\n",
      " 94%|█████████▍| 532/566 [04:16<00:16,  2.07it/s, loss=0.886]\u001b[A\n",
      " 94%|█████████▍| 532/566 [04:17<00:16,  2.07it/s, loss=0.406]\u001b[A\n",
      " 94%|█████████▍| 533/566 [04:17<00:15,  2.08it/s, loss=0.406]\u001b[A\n",
      " 94%|█████████▍| 533/566 [04:17<00:15,  2.08it/s, loss=0.841]\u001b[A\n",
      " 94%|█████████▍| 534/566 [04:17<00:15,  2.08it/s, loss=0.841]\u001b[A\n",
      " 94%|█████████▍| 534/566 [04:18<00:15,  2.08it/s, loss=1.08] \u001b[A\n",
      " 95%|█████████▍| 535/566 [04:18<00:14,  2.07it/s, loss=1.08]\u001b[A\n",
      " 95%|█████████▍| 535/566 [04:18<00:14,  2.07it/s, loss=0.439]\u001b[A\n",
      " 95%|█████████▍| 536/566 [04:18<00:14,  2.07it/s, loss=0.439]\u001b[A\n",
      " 95%|█████████▍| 536/566 [04:19<00:14,  2.07it/s, loss=0.827]\u001b[A\n",
      " 95%|█████████▍| 537/566 [04:19<00:14,  2.07it/s, loss=0.827]\u001b[A\n",
      " 95%|█████████▍| 537/566 [04:19<00:14,  2.07it/s, loss=0.39] \u001b[A\n",
      " 95%|█████████▌| 538/566 [04:19<00:13,  2.06it/s, loss=0.39]\u001b[A\n",
      " 95%|█████████▌| 538/566 [04:20<00:13,  2.06it/s, loss=0.485]\u001b[A\n",
      " 95%|█████████▌| 539/566 [04:20<00:13,  2.07it/s, loss=0.485]\u001b[A\n",
      " 95%|█████████▌| 539/566 [04:20<00:13,  2.07it/s, loss=0.211]\u001b[A\n",
      " 95%|█████████▌| 540/566 [04:20<00:12,  2.07it/s, loss=0.211]\u001b[A\n",
      " 95%|█████████▌| 540/566 [04:21<00:12,  2.07it/s, loss=0.754]\u001b[A\n",
      " 96%|█████████▌| 541/566 [04:21<00:12,  2.07it/s, loss=0.754]\u001b[A\n",
      " 96%|█████████▌| 541/566 [04:21<00:12,  2.07it/s, loss=0.537]\u001b[A\n",
      " 96%|█████████▌| 542/566 [04:21<00:11,  2.06it/s, loss=0.537]\u001b[A\n",
      " 96%|█████████▌| 542/566 [04:22<00:11,  2.06it/s, loss=0.56] \u001b[A\n",
      " 96%|█████████▌| 543/566 [04:22<00:11,  2.06it/s, loss=0.56]\u001b[A\n",
      " 96%|█████████▌| 543/566 [04:22<00:11,  2.06it/s, loss=0.56]\u001b[A\n",
      " 96%|█████████▌| 544/566 [04:22<00:10,  2.06it/s, loss=0.56]\u001b[A\n",
      " 96%|█████████▌| 544/566 [04:23<00:10,  2.06it/s, loss=0.53]\u001b[A\n",
      " 96%|█████████▋| 545/566 [04:23<00:10,  2.07it/s, loss=0.53]\u001b[A\n",
      " 96%|█████████▋| 545/566 [04:23<00:10,  2.07it/s, loss=0.578]\u001b[A\n",
      " 96%|█████████▋| 546/566 [04:23<00:09,  2.08it/s, loss=0.578]\u001b[A\n",
      " 96%|█████████▋| 546/566 [04:23<00:09,  2.08it/s, loss=0.531]\u001b[A\n",
      " 97%|█████████▋| 547/566 [04:23<00:09,  2.07it/s, loss=0.531]\u001b[A\n",
      " 97%|█████████▋| 547/566 [04:24<00:09,  2.07it/s, loss=0.665]\u001b[A\n",
      " 97%|█████████▋| 548/566 [04:24<00:08,  2.07it/s, loss=0.665]\u001b[A\n",
      " 97%|█████████▋| 548/566 [04:24<00:08,  2.07it/s, loss=0.848]\u001b[A\n",
      " 97%|█████████▋| 549/566 [04:24<00:08,  2.07it/s, loss=0.848]\u001b[A\n",
      " 97%|█████████▋| 549/566 [04:25<00:08,  2.07it/s, loss=0.912]\u001b[A\n",
      " 97%|█████████▋| 550/566 [04:25<00:07,  2.07it/s, loss=0.912]\u001b[A\n",
      " 97%|█████████▋| 550/566 [04:25<00:07,  2.07it/s, loss=0.38] \u001b[A\n",
      " 97%|█████████▋| 551/566 [04:25<00:07,  2.07it/s, loss=0.38]\u001b[A\n",
      " 97%|█████████▋| 551/566 [04:26<00:07,  2.07it/s, loss=0.804]\u001b[A\n",
      " 98%|█████████▊| 552/566 [04:26<00:06,  2.06it/s, loss=0.804]\u001b[A\n",
      " 98%|█████████▊| 552/566 [04:26<00:06,  2.06it/s, loss=0.515]\u001b[A\n",
      " 98%|█████████▊| 553/566 [04:26<00:06,  2.07it/s, loss=0.515]\u001b[A\n",
      " 98%|█████████▊| 553/566 [04:27<00:06,  2.07it/s, loss=0.339]\u001b[A\n",
      " 98%|█████████▊| 554/566 [04:27<00:05,  2.06it/s, loss=0.339]\u001b[A\n",
      " 98%|█████████▊| 554/566 [04:27<00:05,  2.06it/s, loss=0.73] \u001b[A\n",
      " 98%|█████████▊| 555/566 [04:27<00:05,  2.05it/s, loss=0.73]\u001b[A\n",
      " 98%|█████████▊| 555/566 [04:28<00:05,  2.05it/s, loss=0.317]\u001b[A\n",
      " 98%|█████████▊| 556/566 [04:28<00:04,  2.06it/s, loss=0.317]\u001b[A\n",
      " 98%|█████████▊| 556/566 [04:28<00:04,  2.06it/s, loss=0.465]\u001b[A\n",
      " 98%|█████████▊| 557/566 [04:28<00:04,  2.06it/s, loss=0.465]\u001b[A\n",
      " 98%|█████████▊| 557/566 [04:29<00:04,  2.06it/s, loss=1.02] \u001b[A\n",
      " 99%|█████████▊| 558/566 [04:29<00:03,  2.05it/s, loss=1.02]\u001b[A\n",
      " 99%|█████████▊| 558/566 [04:29<00:03,  2.05it/s, loss=0.649]\u001b[A\n",
      " 99%|█████████▉| 559/566 [04:29<00:03,  2.05it/s, loss=0.649]\u001b[A\n",
      " 99%|█████████▉| 559/566 [04:30<00:03,  2.05it/s, loss=0.443]\u001b[A\n",
      " 99%|█████████▉| 560/566 [04:30<00:02,  2.06it/s, loss=0.443]\u001b[A\n",
      " 99%|█████████▉| 560/566 [04:30<00:02,  2.06it/s, loss=0.921]\u001b[A\n",
      " 99%|█████████▉| 561/566 [04:30<00:02,  2.07it/s, loss=0.921]\u001b[A\n",
      " 99%|█████████▉| 561/566 [04:31<00:02,  2.07it/s, loss=0.561]\u001b[A\n",
      " 99%|█████████▉| 562/566 [04:31<00:01,  2.07it/s, loss=0.561]\u001b[A\n",
      " 99%|█████████▉| 562/566 [04:31<00:01,  2.07it/s, loss=0.571]\u001b[A\n",
      " 99%|█████████▉| 563/566 [04:31<00:01,  2.06it/s, loss=0.571]\u001b[A\n",
      " 99%|█████████▉| 563/566 [04:32<00:01,  2.06it/s, loss=0.961]\u001b[A\n",
      "100%|█████████▉| 564/566 [04:32<00:00,  2.05it/s, loss=0.961]\u001b[A\n",
      "100%|█████████▉| 564/566 [04:32<00:00,  2.05it/s, loss=0.632]\u001b[A\n",
      "100%|█████████▉| 565/566 [04:32<00:00,  2.06it/s, loss=0.632]\u001b[A\n",
      "100%|█████████▉| 565/566 [04:32<00:00,  2.06it/s, loss=0.131]\u001b[A\n",
      "100%|██████████| 566/566 [04:32<00:00,  2.07it/s, loss=0.131]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=0.561]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=0.0178]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=2.23]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=0.011]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=3.01]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=0.28]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:32<00:00,  2.08it/s, loss=0.00815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: {'accuracy': 0.7532338308457711, 'precision': 0.7572237429541271, 'recall': 0.7532338308457711, 'f1': 0.751809190038524}\n",
      "Test: {'accuracy': 0.7452229299363057, 'precision': 0.7546749292638254, 'recall': 0.7452229299363057, 'f1': 0.7436910163360136}\n"
     ]
    }
   ],
   "source": [
    "# 📦 Install dependencies (only needed if running on Colab)\n",
    "!pip install -q transformers datasets nltk\n",
    "\n",
    "# 🔧 Imports\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ⚙️ Device config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load your dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\", quotechar='\"', engine=\"python\", on_bad_lines='skip')\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "# ✨ Clean text\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# 🔀 Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Convert to HuggingFace Datasets\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "\n",
    "# 🧠 Tokenize\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 📊 Model & Dataloaders\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=3).to(device)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "# 🔧 Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 🎯 Train\n",
    "for epoch in range(8):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# 📈 Evaluate\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**batch)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"\\nValidation:\", evaluate(val_loader))\n",
    "print(\"Test:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5DPM5A1U30F",
    "outputId": "d7b042ee-3138-4c7a-e870-b263c5131cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets nltk scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW8elab20kQT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2a6cafc27cb7429cadc5aa00a0d3957e",
      "943ede5bf4724d0ba46dbc7213f23c2d",
      "6e27bc27da754ae8a27fdc2a32e461c3",
      "7a13a72a47174aecbe0abc4998966b7a",
      "077c0beb758643fa9232677b1f2d1f60",
      "16f5912934e342a8b2b0c11d5084d239",
      "0c97da9ef5de4dea8d37cc7a17666b4f",
      "28af22da83f44091b28044cf088f2061",
      "b7038e1935b746aca6779b155e9e8b0b",
      "737082fb4cc1498cab488d846551e187",
      "66b8e314836b4f79b4e50cca779619e9",
      "db87adfdb225476eb35170593572150b",
      "928c93ae95f841e0b8a1bfed001c835f",
      "c31aa636f30f4f72b27fc48b23768650",
      "fa5bdfc1bc1f4345a01914475a6c1082",
      "d76b5c1fc6d34bbe82f7bc83fcd9d53b",
      "2f45d6ee3462454cac53a9b2b1bb6388",
      "5441a6e92440420ca1286152962adcb8",
      "d37f35e0f93d4fb1a662bfad21d2de70",
      "232424620de747b097c3bcc798847ce0",
      "93c32c6804a846f495b5ead570fb0d59",
      "778bdf487c1b47b198f280d5fe89090b",
      "9d31052b1df74a72bb9e66c2730b836c",
      "7b56ae4351c5400e92f4690c20e9250f",
      "85812525cc8544cab77411bdb9361bec",
      "ac5f8d4c28074544a2dcb0192934f620",
      "d094fbd8dc9f40ac913ec8c859d0783f",
      "b0e02c5878184b65abbf37cfb9146465",
      "cb16e1013f46495988e2232980df6bf1",
      "9010baf9eb4442ff8b406e7b0e56e89a",
      "9f593a86c2dd428f806e1c94b167ac88",
      "b76afda74dd040db841e7cfeb37a0be7",
      "11a14784bc6541428c9f60e586177845",
      "2fd2cce4579544f0967936f15697c104",
      "bf89cbf3490a4ee09e271b562be39fa4",
      "12d3bd246e0d495eb92c9a20ef0a68db",
      "2f771d44059e42d8bef50a4dfe8ccd4d",
      "e5e2feb11639403b9dbfb9ccb42ff1fb",
      "039dd70345f64196bd4459030e687372",
      "ac61f466819c42c0b56e0bbc37d25549",
      "2a8670a142804ed4bf6d90379ca2c087",
      "d6c16370c860432abe3c5602bcdb8ebb",
      "5ce178bdf5794d29adcf76b3f5fa3862",
      "7f7099833de14694b026451a527f879c",
      "6f116bae87534bf2a21407a157ba771a",
      "90e5e00f1062494ab22640507a5e01f5",
      "835d6998d4be4c618a802d4dec3fe752",
      "d97c5ff183254b2e88b29b17df6d40ae",
      "083f01fc78d94a879104c34f73fa3489",
      "9098f4b7c01c4672b76cb0b1933c823f",
      "e99c67402e254e109665c2cc9a55dae7",
      "17d9fc7e7c294a76b04e516c35206d93",
      "7cd30976e09c4d13a8fe1ab6bd21ab42",
      "ae81069c43b04be9a9e0537e267263c9",
      "dff21c728c5b45e9bca47f7bd8bfc820",
      "d88cd5b4bc7e4665aa98555db4fc4832",
      "19f0a83023844a749167903c3733d9c0",
      "2dc961c3e585400489c006c3dd475150",
      "abddb234383d4ff5887e2eeb131c71f7",
      "d53bd362a9234da288e0ca53650eac23",
      "646ab096bb5540a3a47d5301356bd5b5",
      "dc67b2af2680402bb764604f834a9381",
      "1028645f824f4fc2befffa5d6085182f",
      "bef7ee827a4b4435922e5c8b13930ccd",
      "18de9670d7414cc595025f93421dde7a",
      "f529aa494f044e62b1aceac7f42c7952",
      "8a55e80ec1a2463ba0118cec38715379",
      "e5231a23b88f4e29a46253030c2ff7d7",
      "054d5f2d6de84bb3852a4dc8a8c99616",
      "2ed22e17ec83442d9fd40844884cbfc7",
      "bb6f8795c1644a02850958585faa165f",
      "c81533e22b614d4a87d48300092cb156",
      "54c85bd371524f61b19bcb13ac6bf74e",
      "44d67357b004475fb13c6b19a650a5d3",
      "adeed70d8234484594f8ad7929ba0787",
      "8065370d41414604b09b539684926c93",
      "af6d1412c8ae4fb789c3d4ae0df0a8d8",
      "608cf4c921e74ed9be671bbf665406e2",
      "efd0f615017f409eada53cd85f2d6843",
      "6a58a18ce0a844e8bdc0d47dcfb7f7a4",
      "1c290c12873743468ab943e9643d7d05",
      "6ef2f3240610498b9fcf29b9af199dc6",
      "1390ec7872f94e559982520a296bb87e",
      "c41f4d48d1fa4b5590239143c04274bd",
      "9cb6ed64d66b4711961039691ec0ae30",
      "448a3974102e48ec98dedd96a213ff75",
      "d39391c2d3ec45b4b92c1c031ff644b9",
      "5b90bbee74ec4dcbbb7d1a026ded3924"
     ]
    },
    "id": "Pls6TeHkU1Z5",
    "outputId": "f5e66c46-fbe9-4636-a8e4-9cffe6901f2f"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6cafc27cb7429cadc5aa00a0d3957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db87adfdb225476eb35170593572150b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d31052b1df74a72bb9e66c2730b836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd2cce4579544f0967936f15697c104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f116bae87534bf2a21407a157ba771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88cd5b4bc7e4665aa98555db4fc4832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a55e80ec1a2463ba0118cec38715379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608cf4c921e74ed9be671bbf665406e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/566 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/566 [00:02<25:32,  2.71s/it]\u001b[A\n",
      "  0%|          | 2/566 [00:03<15:06,  1.61s/it]\u001b[A\n",
      "  1%|          | 3/566 [00:03<09:59,  1.06s/it]\u001b[A\n",
      "  1%|          | 4/566 [00:04<07:36,  1.23it/s]\u001b[A\n",
      "  1%|          | 5/566 [00:04<06:16,  1.49it/s]\u001b[A\n",
      "  1%|          | 6/566 [00:05<05:29,  1.70it/s]\u001b[A\n",
      "  1%|          | 7/566 [00:05<04:57,  1.88it/s]\u001b[A\n",
      "  1%|▏         | 8/566 [00:06<04:39,  1.99it/s]\u001b[A\n",
      "  2%|▏         | 9/566 [00:06<04:26,  2.09it/s]\u001b[A\n",
      "  2%|▏         | 10/566 [00:06<04:15,  2.17it/s]\u001b[A\n",
      "  2%|▏         | 11/566 [00:07<04:09,  2.22it/s]\u001b[A\n",
      "  2%|▏         | 12/566 [00:07<04:04,  2.27it/s]\u001b[A\n",
      "  2%|▏         | 13/566 [00:08<04:00,  2.30it/s]\u001b[A\n",
      "  2%|▏         | 14/566 [00:08<03:58,  2.32it/s]\u001b[A\n",
      "  3%|▎         | 15/566 [00:09<03:57,  2.32it/s]\u001b[A\n",
      "  3%|▎         | 16/566 [00:09<03:55,  2.33it/s]\u001b[A\n",
      "  3%|▎         | 17/566 [00:09<03:54,  2.34it/s]\u001b[A\n",
      "  3%|▎         | 18/566 [00:10<03:53,  2.35it/s]\u001b[A\n",
      "  3%|▎         | 19/566 [00:10<03:53,  2.34it/s]\u001b[A\n",
      "  4%|▎         | 20/566 [00:11<03:52,  2.35it/s]\u001b[A\n",
      "  4%|▎         | 21/566 [00:11<03:52,  2.35it/s]\u001b[A\n",
      "  4%|▍         | 22/566 [00:12<03:51,  2.35it/s]\u001b[A\n",
      "  4%|▍         | 23/566 [00:12<03:51,  2.34it/s]\u001b[A\n",
      "  4%|▍         | 24/566 [00:12<03:50,  2.35it/s]\u001b[A\n",
      "  4%|▍         | 25/566 [00:13<03:50,  2.35it/s]\u001b[A\n",
      "  5%|▍         | 26/566 [00:13<03:50,  2.34it/s]\u001b[A\n",
      "  5%|▍         | 27/566 [00:14<03:50,  2.34it/s]\u001b[A\n",
      "  5%|▍         | 28/566 [00:14<03:49,  2.35it/s]\u001b[A\n",
      "  5%|▌         | 29/566 [00:15<03:49,  2.34it/s]\u001b[A\n",
      "  5%|▌         | 30/566 [00:15<03:48,  2.34it/s]\u001b[A\n",
      "  5%|▌         | 31/566 [00:15<03:48,  2.34it/s]\u001b[A\n",
      "  6%|▌         | 32/566 [00:16<03:48,  2.34it/s]\u001b[A\n",
      "  6%|▌         | 33/566 [00:16<03:47,  2.34it/s]\u001b[A\n",
      "  6%|▌         | 34/566 [00:17<03:46,  2.35it/s]\u001b[A\n",
      "  6%|▌         | 35/566 [00:17<03:46,  2.35it/s]\u001b[A\n",
      "  6%|▋         | 36/566 [00:18<03:46,  2.34it/s]\u001b[A\n",
      "  7%|▋         | 37/566 [00:18<03:45,  2.34it/s]\u001b[A\n",
      "  7%|▋         | 38/566 [00:18<03:45,  2.34it/s]\u001b[A\n",
      "  7%|▋         | 39/566 [00:19<03:44,  2.35it/s]\u001b[A\n",
      "  7%|▋         | 40/566 [00:19<03:44,  2.34it/s]\u001b[A\n",
      "  7%|▋         | 41/566 [00:20<03:43,  2.35it/s]\u001b[A\n",
      "  7%|▋         | 42/566 [00:20<03:43,  2.34it/s]\u001b[A\n",
      "  8%|▊         | 43/566 [00:20<03:42,  2.35it/s]\u001b[A\n",
      "  8%|▊         | 44/566 [00:21<03:42,  2.34it/s]\u001b[A\n",
      "  8%|▊         | 45/566 [00:21<03:43,  2.33it/s]\u001b[A\n",
      "  8%|▊         | 46/566 [00:22<03:43,  2.33it/s]\u001b[A\n",
      "  8%|▊         | 47/566 [00:22<03:43,  2.32it/s]\u001b[A\n",
      "  8%|▊         | 48/566 [00:23<03:42,  2.33it/s]\u001b[A\n",
      "  9%|▊         | 49/566 [00:23<03:41,  2.33it/s]\u001b[A\n",
      "  9%|▉         | 50/566 [00:24<03:41,  2.33it/s]\u001b[A\n",
      "  9%|▉         | 51/566 [00:24<03:40,  2.34it/s]\u001b[A\n",
      "  9%|▉         | 52/566 [00:24<03:40,  2.33it/s]\u001b[A\n",
      "  9%|▉         | 53/566 [00:25<03:40,  2.33it/s]\u001b[A\n",
      " 10%|▉         | 54/566 [00:25<03:39,  2.33it/s]\u001b[A\n",
      " 10%|▉         | 55/566 [00:26<03:39,  2.33it/s]\u001b[A\n",
      " 10%|▉         | 56/566 [00:26<03:38,  2.33it/s]\u001b[A\n",
      " 10%|█         | 57/566 [00:27<03:38,  2.33it/s]\u001b[A\n",
      " 10%|█         | 58/566 [00:27<03:39,  2.32it/s]\u001b[A\n",
      " 10%|█         | 59/566 [00:27<03:38,  2.32it/s]\u001b[A\n",
      " 11%|█         | 60/566 [00:28<03:37,  2.33it/s]\u001b[A\n",
      " 11%|█         | 61/566 [00:28<03:37,  2.33it/s]\u001b[A\n",
      " 11%|█         | 62/566 [00:29<03:36,  2.33it/s]\u001b[A\n",
      " 11%|█         | 63/566 [00:29<03:36,  2.33it/s]\u001b[A\n",
      " 11%|█▏        | 64/566 [00:30<03:35,  2.33it/s]\u001b[A\n",
      " 11%|█▏        | 65/566 [00:30<03:35,  2.32it/s]\u001b[A\n",
      " 12%|█▏        | 66/566 [00:30<03:35,  2.32it/s]\u001b[A\n",
      " 12%|█▏        | 67/566 [00:31<03:34,  2.33it/s]\u001b[A\n",
      " 12%|█▏        | 68/566 [00:31<03:33,  2.33it/s]\u001b[A\n",
      " 12%|█▏        | 69/566 [00:32<03:34,  2.32it/s]\u001b[A\n",
      " 12%|█▏        | 70/566 [00:32<03:33,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 71/566 [00:33<03:33,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 72/566 [00:33<03:32,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 73/566 [00:33<03:32,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 74/566 [00:34<03:32,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 75/566 [00:34<03:31,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 76/566 [00:35<03:31,  2.32it/s]\u001b[A\n",
      " 14%|█▎        | 77/566 [00:35<03:30,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 78/566 [00:36<03:30,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 79/566 [00:36<03:29,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 80/566 [00:36<03:29,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 81/566 [00:37<03:28,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 82/566 [00:37<03:28,  2.32it/s]\u001b[A\n",
      " 15%|█▍        | 83/566 [00:38<03:28,  2.32it/s]\u001b[A\n",
      " 15%|█▍        | 84/566 [00:38<03:27,  2.32it/s]\u001b[A\n",
      " 15%|█▌        | 85/566 [00:39<03:27,  2.32it/s]\u001b[A\n",
      " 15%|█▌        | 86/566 [00:39<03:27,  2.32it/s]\u001b[A\n",
      " 15%|█▌        | 87/566 [00:39<03:26,  2.32it/s]\u001b[A\n",
      " 16%|█▌        | 88/566 [00:40<03:26,  2.32it/s]\u001b[A\n",
      " 16%|█▌        | 89/566 [00:40<03:25,  2.32it/s]\u001b[A\n",
      " 16%|█▌        | 90/566 [00:41<03:25,  2.32it/s]\u001b[A\n",
      " 16%|█▌        | 91/566 [00:41<03:25,  2.31it/s]\u001b[A\n",
      " 16%|█▋        | 92/566 [00:42<03:25,  2.31it/s]\u001b[A\n",
      " 16%|█▋        | 93/566 [00:42<03:25,  2.30it/s]\u001b[A\n",
      " 17%|█▋        | 94/566 [00:42<03:25,  2.30it/s]\u001b[A\n",
      " 17%|█▋        | 95/566 [00:43<03:24,  2.30it/s]\u001b[A\n",
      " 17%|█▋        | 96/566 [00:43<03:24,  2.30it/s]\u001b[A\n",
      " 17%|█▋        | 97/566 [00:44<03:22,  2.31it/s]\u001b[A\n",
      " 17%|█▋        | 98/566 [00:44<03:22,  2.31it/s]\u001b[A\n",
      " 17%|█▋        | 99/566 [00:45<03:22,  2.30it/s]\u001b[A\n",
      " 18%|█▊        | 100/566 [00:45<03:22,  2.30it/s]\u001b[A\n",
      " 18%|█▊        | 101/566 [00:46<03:21,  2.31it/s]\u001b[A\n",
      " 18%|█▊        | 102/566 [00:46<03:22,  2.30it/s]\u001b[A\n",
      " 18%|█▊        | 103/566 [00:46<03:21,  2.30it/s]\u001b[A\n",
      " 18%|█▊        | 104/566 [00:47<03:20,  2.30it/s]\u001b[A\n",
      " 19%|█▊        | 105/566 [00:47<03:20,  2.29it/s]\u001b[A\n",
      " 19%|█▊        | 106/566 [00:48<03:20,  2.30it/s]\u001b[A\n",
      " 19%|█▉        | 107/566 [00:48<03:19,  2.31it/s]\u001b[A\n",
      " 19%|█▉        | 108/566 [00:49<03:18,  2.30it/s]\u001b[A\n",
      " 19%|█▉        | 109/566 [00:49<03:18,  2.30it/s]\u001b[A\n",
      " 19%|█▉        | 110/566 [00:49<03:18,  2.30it/s]\u001b[A\n",
      " 20%|█▉        | 111/566 [00:50<03:17,  2.31it/s]\u001b[A\n",
      " 20%|█▉        | 112/566 [00:50<03:17,  2.30it/s]\u001b[A\n",
      " 20%|█▉        | 113/566 [00:51<03:16,  2.30it/s]\u001b[A\n",
      " 20%|██        | 114/566 [00:51<03:17,  2.29it/s]\u001b[A\n",
      " 20%|██        | 115/566 [00:52<03:16,  2.30it/s]\u001b[A\n",
      " 20%|██        | 116/566 [00:52<03:15,  2.30it/s]\u001b[A\n",
      " 21%|██        | 117/566 [00:52<03:15,  2.30it/s]\u001b[A\n",
      " 21%|██        | 118/566 [00:53<03:15,  2.30it/s]\u001b[A\n",
      " 21%|██        | 119/566 [00:53<03:14,  2.30it/s]\u001b[A\n",
      " 21%|██        | 120/566 [00:54<03:13,  2.30it/s]\u001b[A\n",
      " 21%|██▏       | 121/566 [00:54<03:13,  2.31it/s]\u001b[A\n",
      " 22%|██▏       | 122/566 [00:55<03:13,  2.29it/s]\u001b[A\n",
      " 22%|██▏       | 123/566 [00:55<03:12,  2.30it/s]\u001b[A\n",
      " 22%|██▏       | 124/566 [00:56<03:12,  2.29it/s]\u001b[A\n",
      " 22%|██▏       | 125/566 [00:56<03:12,  2.29it/s]\u001b[A\n",
      " 22%|██▏       | 126/566 [00:56<03:11,  2.29it/s]\u001b[A\n",
      " 22%|██▏       | 127/566 [00:57<03:12,  2.28it/s]\u001b[A\n",
      " 23%|██▎       | 128/566 [00:57<03:12,  2.28it/s]\u001b[A\n",
      " 23%|██▎       | 129/566 [00:58<03:12,  2.27it/s]\u001b[A\n",
      " 23%|██▎       | 130/566 [00:58<03:12,  2.26it/s]\u001b[A\n",
      " 23%|██▎       | 131/566 [00:59<03:12,  2.26it/s]\u001b[A\n",
      " 23%|██▎       | 132/566 [00:59<03:10,  2.28it/s]\u001b[A\n",
      " 23%|██▎       | 133/566 [00:59<03:09,  2.28it/s]\u001b[A\n",
      " 24%|██▎       | 134/566 [01:00<03:09,  2.28it/s]\u001b[A\n",
      " 24%|██▍       | 135/566 [01:00<03:08,  2.28it/s]\u001b[A\n",
      " 24%|██▍       | 136/566 [01:01<03:07,  2.29it/s]\u001b[A\n",
      " 24%|██▍       | 137/566 [01:01<03:07,  2.29it/s]\u001b[A\n",
      " 24%|██▍       | 138/566 [01:02<03:06,  2.29it/s]\u001b[A\n",
      " 25%|██▍       | 139/566 [01:02<03:07,  2.28it/s]\u001b[A\n",
      " 25%|██▍       | 140/566 [01:03<03:06,  2.28it/s]\u001b[A\n",
      " 25%|██▍       | 141/566 [01:03<03:05,  2.29it/s]\u001b[A\n",
      " 25%|██▌       | 142/566 [01:03<03:05,  2.28it/s]\u001b[A\n",
      " 25%|██▌       | 143/566 [01:04<03:05,  2.29it/s]\u001b[A\n",
      " 25%|██▌       | 144/566 [01:04<03:05,  2.28it/s]\u001b[A\n",
      " 26%|██▌       | 145/566 [01:05<03:04,  2.28it/s]\u001b[A\n",
      " 26%|██▌       | 146/566 [01:05<03:04,  2.28it/s]\u001b[A\n",
      " 26%|██▌       | 147/566 [01:06<03:03,  2.28it/s]\u001b[A\n",
      " 26%|██▌       | 148/566 [01:06<03:02,  2.29it/s]\u001b[A\n",
      " 26%|██▋       | 149/566 [01:06<03:02,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 150/566 [01:07<03:02,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 151/566 [01:07<03:01,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 152/566 [01:08<03:01,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 153/566 [01:08<03:01,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 154/566 [01:09<03:01,  2.28it/s]\u001b[A\n",
      " 27%|██▋       | 155/566 [01:09<02:59,  2.28it/s]\u001b[A\n",
      " 28%|██▊       | 156/566 [01:10<03:00,  2.28it/s]\u001b[A\n",
      " 28%|██▊       | 157/566 [01:10<02:59,  2.27it/s]\u001b[A\n",
      " 28%|██▊       | 158/566 [01:10<03:00,  2.26it/s]\u001b[A\n",
      " 28%|██▊       | 159/566 [01:11<02:59,  2.26it/s]\u001b[A\n",
      " 28%|██▊       | 160/566 [01:11<02:59,  2.26it/s]\u001b[A\n",
      " 28%|██▊       | 161/566 [01:12<02:58,  2.27it/s]\u001b[A\n",
      " 29%|██▊       | 162/566 [01:12<02:57,  2.27it/s]\u001b[A\n",
      " 29%|██▉       | 163/566 [01:13<02:57,  2.27it/s]\u001b[A\n",
      " 29%|██▉       | 164/566 [01:13<02:57,  2.27it/s]\u001b[A\n",
      " 29%|██▉       | 165/566 [01:14<02:56,  2.27it/s]\u001b[A\n",
      " 29%|██▉       | 166/566 [01:14<02:56,  2.27it/s]\u001b[A\n",
      " 30%|██▉       | 167/566 [01:14<02:55,  2.27it/s]\u001b[A\n",
      " 30%|██▉       | 168/566 [01:15<02:55,  2.27it/s]\u001b[A\n",
      " 30%|██▉       | 169/566 [01:15<02:55,  2.27it/s]\u001b[A\n",
      " 30%|███       | 170/566 [01:16<02:54,  2.26it/s]\u001b[A\n",
      " 30%|███       | 171/566 [01:16<02:54,  2.27it/s]\u001b[A\n",
      " 30%|███       | 172/566 [01:17<02:53,  2.27it/s]\u001b[A\n",
      " 31%|███       | 173/566 [01:17<02:53,  2.27it/s]\u001b[A\n",
      " 31%|███       | 174/566 [01:17<02:53,  2.26it/s]\u001b[A\n",
      " 31%|███       | 175/566 [01:18<02:53,  2.26it/s]\u001b[A\n",
      " 31%|███       | 176/566 [01:18<02:53,  2.25it/s]\u001b[A\n",
      " 31%|███▏      | 177/566 [01:19<02:55,  2.22it/s]\u001b[A\n",
      " 31%|███▏      | 178/566 [01:19<02:54,  2.23it/s]\u001b[A\n",
      " 32%|███▏      | 179/566 [01:20<02:53,  2.23it/s]\u001b[A\n",
      " 32%|███▏      | 180/566 [01:20<02:53,  2.22it/s]\u001b[A\n",
      " 32%|███▏      | 181/566 [01:21<02:53,  2.22it/s]\u001b[A\n",
      " 32%|███▏      | 182/566 [01:21<02:57,  2.16it/s]\u001b[A\n",
      " 32%|███▏      | 183/566 [01:22<02:57,  2.15it/s]\u001b[A\n",
      " 33%|███▎      | 184/566 [01:22<02:56,  2.17it/s]\u001b[A\n",
      " 33%|███▎      | 185/566 [01:23<02:54,  2.19it/s]\u001b[A\n",
      " 33%|███▎      | 186/566 [01:23<02:52,  2.20it/s]\u001b[A\n",
      " 33%|███▎      | 187/566 [01:23<02:51,  2.22it/s]\u001b[A\n",
      " 33%|███▎      | 188/566 [01:24<02:49,  2.23it/s]\u001b[A\n",
      " 33%|███▎      | 189/566 [01:24<02:48,  2.23it/s]\u001b[A\n",
      " 34%|███▎      | 190/566 [01:25<02:47,  2.24it/s]\u001b[A\n",
      " 34%|███▎      | 191/566 [01:25<02:47,  2.24it/s]\u001b[A\n",
      " 34%|███▍      | 192/566 [01:26<02:46,  2.24it/s]\u001b[A\n",
      " 34%|███▍      | 193/566 [01:26<02:46,  2.24it/s]\u001b[A\n",
      " 34%|███▍      | 194/566 [01:27<02:45,  2.24it/s]\u001b[A\n",
      " 34%|███▍      | 195/566 [01:27<02:45,  2.24it/s]\u001b[A\n",
      " 35%|███▍      | 196/566 [01:27<02:44,  2.25it/s]\u001b[A\n",
      " 35%|███▍      | 197/566 [01:28<02:44,  2.24it/s]\u001b[A\n",
      " 35%|███▍      | 198/566 [01:28<02:43,  2.24it/s]\u001b[A\n",
      " 35%|███▌      | 199/566 [01:29<02:43,  2.25it/s]\u001b[A\n",
      " 35%|███▌      | 200/566 [01:29<02:42,  2.25it/s]\u001b[A\n",
      " 36%|███▌      | 201/566 [01:30<02:42,  2.25it/s]\u001b[A\n",
      " 36%|███▌      | 202/566 [01:30<02:41,  2.25it/s]\u001b[A\n",
      " 36%|███▌      | 203/566 [01:31<02:41,  2.25it/s]\u001b[A\n",
      " 36%|███▌      | 204/566 [01:31<02:41,  2.25it/s]\u001b[A\n",
      " 36%|███▌      | 205/566 [01:31<02:40,  2.25it/s]\u001b[A\n",
      " 36%|███▋      | 206/566 [01:32<02:40,  2.24it/s]\u001b[A\n",
      " 37%|███▋      | 207/566 [01:32<02:40,  2.24it/s]\u001b[A\n",
      " 37%|███▋      | 208/566 [01:33<02:39,  2.24it/s]\u001b[A\n",
      " 37%|███▋      | 209/566 [01:33<02:39,  2.24it/s]\u001b[A\n",
      " 37%|███▋      | 210/566 [01:34<02:39,  2.23it/s]\u001b[A\n",
      " 37%|███▋      | 211/566 [01:34<02:39,  2.23it/s]\u001b[A\n",
      " 37%|███▋      | 212/566 [01:35<02:38,  2.23it/s]\u001b[A\n",
      " 38%|███▊      | 213/566 [01:35<02:38,  2.23it/s]\u001b[A\n",
      " 38%|███▊      | 214/566 [01:35<02:38,  2.22it/s]\u001b[A\n",
      " 38%|███▊      | 215/566 [01:36<02:37,  2.23it/s]\u001b[A\n",
      " 38%|███▊      | 216/566 [01:36<02:37,  2.23it/s]\u001b[A\n",
      " 38%|███▊      | 217/566 [01:37<02:36,  2.23it/s]\u001b[A\n",
      " 39%|███▊      | 218/566 [01:37<02:35,  2.23it/s]\u001b[A\n",
      " 39%|███▊      | 219/566 [01:38<02:35,  2.23it/s]\u001b[A\n",
      " 39%|███▉      | 220/566 [01:38<02:34,  2.24it/s]\u001b[A\n",
      " 39%|███▉      | 221/566 [01:39<02:34,  2.24it/s]\u001b[A\n",
      " 39%|███▉      | 222/566 [01:39<02:33,  2.24it/s]\u001b[A\n",
      " 39%|███▉      | 223/566 [01:39<02:33,  2.23it/s]\u001b[A\n",
      " 40%|███▉      | 224/566 [01:40<02:33,  2.23it/s]\u001b[A\n",
      " 40%|███▉      | 225/566 [01:40<02:32,  2.23it/s]\u001b[A\n",
      " 40%|███▉      | 226/566 [01:41<02:32,  2.23it/s]\u001b[A\n",
      " 40%|████      | 227/566 [01:41<02:31,  2.24it/s]\u001b[A\n",
      " 40%|████      | 228/566 [01:42<02:31,  2.24it/s]\u001b[A\n",
      " 40%|████      | 229/566 [01:42<02:30,  2.24it/s]\u001b[A\n",
      " 41%|████      | 230/566 [01:43<02:29,  2.24it/s]\u001b[A\n",
      " 41%|████      | 231/566 [01:43<02:29,  2.24it/s]\u001b[A\n",
      " 41%|████      | 232/566 [01:44<02:29,  2.23it/s]\u001b[A\n",
      " 41%|████      | 233/566 [01:44<02:29,  2.23it/s]\u001b[A\n",
      " 41%|████▏     | 234/566 [01:44<02:28,  2.24it/s]\u001b[A\n",
      " 42%|████▏     | 235/566 [01:45<02:28,  2.23it/s]\u001b[A\n",
      " 42%|████▏     | 236/566 [01:45<02:28,  2.23it/s]\u001b[A\n",
      " 42%|████▏     | 237/566 [01:46<02:28,  2.22it/s]\u001b[A\n",
      " 42%|████▏     | 238/566 [01:46<02:27,  2.23it/s]\u001b[A\n",
      " 42%|████▏     | 239/566 [01:47<02:27,  2.22it/s]\u001b[A\n",
      " 42%|████▏     | 240/566 [01:47<02:27,  2.22it/s]\u001b[A\n",
      " 43%|████▎     | 241/566 [01:48<02:27,  2.20it/s]\u001b[A\n",
      " 43%|████▎     | 242/566 [01:48<02:29,  2.17it/s]\u001b[A\n",
      " 43%|████▎     | 243/566 [01:49<02:29,  2.16it/s]\u001b[A\n",
      " 43%|████▎     | 244/566 [01:49<02:28,  2.18it/s]\u001b[A\n",
      " 43%|████▎     | 245/566 [01:49<02:26,  2.19it/s]\u001b[A\n",
      " 43%|████▎     | 246/566 [01:50<02:25,  2.21it/s]\u001b[A\n",
      " 44%|████▎     | 247/566 [01:50<02:24,  2.21it/s]\u001b[A\n",
      " 44%|████▍     | 248/566 [01:51<02:23,  2.21it/s]\u001b[A\n",
      " 44%|████▍     | 249/566 [01:51<02:23,  2.21it/s]\u001b[A\n",
      " 44%|████▍     | 250/566 [01:52<02:22,  2.22it/s]\u001b[A\n",
      " 44%|████▍     | 251/566 [01:52<02:22,  2.22it/s]\u001b[A\n",
      " 45%|████▍     | 252/566 [01:53<02:21,  2.22it/s]\u001b[A\n",
      " 45%|████▍     | 253/566 [01:53<02:20,  2.22it/s]\u001b[A\n",
      " 45%|████▍     | 254/566 [01:53<02:21,  2.21it/s]\u001b[A\n",
      " 45%|████▌     | 255/566 [01:54<02:20,  2.21it/s]\u001b[A\n",
      " 45%|████▌     | 256/566 [01:54<02:20,  2.21it/s]\u001b[A\n",
      " 45%|████▌     | 257/566 [01:55<02:19,  2.21it/s]\u001b[A\n",
      " 46%|████▌     | 258/566 [01:55<02:19,  2.21it/s]\u001b[A\n",
      " 46%|████▌     | 259/566 [01:56<02:19,  2.20it/s]\u001b[A\n",
      " 46%|████▌     | 260/566 [01:56<02:18,  2.21it/s]\u001b[A\n",
      " 46%|████▌     | 261/566 [01:57<02:17,  2.22it/s]\u001b[A\n",
      " 46%|████▋     | 262/566 [01:57<02:17,  2.21it/s]\u001b[A\n",
      " 46%|████▋     | 263/566 [01:58<02:18,  2.19it/s]\u001b[A\n",
      " 47%|████▋     | 264/566 [01:58<02:17,  2.20it/s]\u001b[A\n",
      " 47%|████▋     | 265/566 [01:58<02:17,  2.19it/s]\u001b[A\n",
      " 47%|████▋     | 266/566 [01:59<02:16,  2.20it/s]\u001b[A\n",
      " 47%|████▋     | 267/566 [01:59<02:15,  2.21it/s]\u001b[A\n",
      " 47%|████▋     | 268/566 [02:00<02:15,  2.20it/s]\u001b[A\n",
      " 48%|████▊     | 269/566 [02:00<02:14,  2.21it/s]\u001b[A\n",
      " 48%|████▊     | 270/566 [02:01<02:14,  2.21it/s]\u001b[A\n",
      " 48%|████▊     | 271/566 [02:01<02:13,  2.21it/s]\u001b[A\n",
      " 48%|████▊     | 272/566 [02:02<02:13,  2.21it/s]\u001b[A\n",
      " 48%|████▊     | 273/566 [02:02<02:13,  2.20it/s]\u001b[A\n",
      " 48%|████▊     | 274/566 [02:03<02:12,  2.21it/s]\u001b[A\n",
      " 49%|████▊     | 275/566 [02:03<02:12,  2.20it/s]\u001b[A\n",
      " 49%|████▉     | 276/566 [02:03<02:11,  2.21it/s]\u001b[A\n",
      " 49%|████▉     | 277/566 [02:04<02:10,  2.21it/s]\u001b[A\n",
      " 49%|████▉     | 278/566 [02:04<02:10,  2.20it/s]\u001b[A\n",
      " 49%|████▉     | 279/566 [02:05<02:10,  2.21it/s]\u001b[A\n",
      " 49%|████▉     | 280/566 [02:05<02:09,  2.21it/s]\u001b[A\n",
      " 50%|████▉     | 281/566 [02:06<02:09,  2.20it/s]\u001b[A\n",
      " 50%|████▉     | 282/566 [02:06<02:08,  2.20it/s]\u001b[A\n",
      " 50%|█████     | 283/566 [02:07<02:08,  2.21it/s]\u001b[A\n",
      " 50%|█████     | 284/566 [02:07<02:07,  2.21it/s]\u001b[A\n",
      " 50%|█████     | 285/566 [02:08<02:07,  2.21it/s]\u001b[A\n",
      " 51%|█████     | 286/566 [02:08<02:07,  2.20it/s]\u001b[A\n",
      " 51%|█████     | 287/566 [02:08<02:07,  2.19it/s]\u001b[A\n",
      " 51%|█████     | 288/566 [02:09<02:06,  2.19it/s]\u001b[A\n",
      " 51%|█████     | 289/566 [02:09<02:06,  2.19it/s]\u001b[A\n",
      " 51%|█████     | 290/566 [02:10<02:05,  2.20it/s]\u001b[A\n",
      " 51%|█████▏    | 291/566 [02:10<02:05,  2.19it/s]\u001b[A\n",
      " 52%|█████▏    | 292/566 [02:11<02:04,  2.20it/s]\u001b[A\n",
      " 52%|█████▏    | 293/566 [02:11<02:04,  2.19it/s]\u001b[A\n",
      " 52%|█████▏    | 294/566 [02:12<02:03,  2.19it/s]\u001b[A\n",
      " 52%|█████▏    | 295/566 [02:12<02:03,  2.19it/s]\u001b[A\n",
      " 52%|█████▏    | 296/566 [02:13<02:02,  2.20it/s]\u001b[A\n",
      " 52%|█████▏    | 297/566 [02:13<02:02,  2.20it/s]\u001b[A\n",
      " 53%|█████▎    | 298/566 [02:13<02:01,  2.20it/s]\u001b[A\n",
      " 53%|█████▎    | 299/566 [02:14<02:00,  2.21it/s]\u001b[A\n",
      " 53%|█████▎    | 300/566 [02:14<02:00,  2.21it/s]\u001b[A\n",
      " 53%|█████▎    | 301/566 [02:15<01:59,  2.21it/s]\u001b[A\n",
      " 53%|█████▎    | 302/566 [02:15<02:00,  2.19it/s]\u001b[A\n",
      " 54%|█████▎    | 303/566 [02:16<02:00,  2.19it/s]\u001b[A\n",
      " 54%|█████▎    | 304/566 [02:16<01:59,  2.20it/s]\u001b[A\n",
      " 54%|█████▍    | 305/566 [02:17<01:59,  2.19it/s]\u001b[A\n",
      " 54%|█████▍    | 306/566 [02:17<01:58,  2.20it/s]\u001b[A\n",
      " 54%|█████▍    | 307/566 [02:18<01:57,  2.21it/s]\u001b[A\n",
      " 54%|█████▍    | 308/566 [02:18<01:57,  2.19it/s]\u001b[A\n",
      " 55%|█████▍    | 309/566 [02:18<01:57,  2.19it/s]\u001b[A\n",
      " 55%|█████▍    | 310/566 [02:19<01:56,  2.19it/s]\u001b[A\n",
      " 55%|█████▍    | 311/566 [02:19<01:56,  2.19it/s]\u001b[A\n",
      " 55%|█████▌    | 312/566 [02:20<01:55,  2.19it/s]\u001b[A\n",
      " 55%|█████▌    | 313/566 [02:20<01:55,  2.19it/s]\u001b[A\n",
      " 55%|█████▌    | 314/566 [02:21<01:54,  2.19it/s]\u001b[A\n",
      " 56%|█████▌    | 315/566 [02:21<01:54,  2.19it/s]\u001b[A\n",
      " 56%|█████▌    | 316/566 [02:22<01:53,  2.20it/s]\u001b[A\n",
      " 56%|█████▌    | 317/566 [02:22<01:53,  2.19it/s]\u001b[A\n",
      " 56%|█████▌    | 318/566 [02:23<01:53,  2.18it/s]\u001b[A\n",
      " 56%|█████▋    | 319/566 [02:23<01:52,  2.19it/s]\u001b[A\n",
      " 57%|█████▋    | 320/566 [02:23<01:52,  2.19it/s]\u001b[A\n",
      " 57%|█████▋    | 321/566 [02:24<01:51,  2.20it/s]\u001b[A\n",
      " 57%|█████▋    | 322/566 [02:24<01:51,  2.20it/s]\u001b[A\n",
      " 57%|█████▋    | 323/566 [02:25<01:50,  2.19it/s]\u001b[A\n",
      " 57%|█████▋    | 324/566 [02:25<01:50,  2.19it/s]\u001b[A\n",
      " 57%|█████▋    | 325/566 [02:26<01:49,  2.19it/s]\u001b[A\n",
      " 58%|█████▊    | 326/566 [02:26<01:49,  2.19it/s]\u001b[A\n",
      " 58%|█████▊    | 327/566 [02:27<01:48,  2.20it/s]\u001b[A\n",
      " 58%|█████▊    | 328/566 [02:27<01:48,  2.20it/s]\u001b[A\n",
      " 58%|█████▊    | 329/566 [02:28<01:47,  2.21it/s]\u001b[A\n",
      " 58%|█████▊    | 330/566 [02:28<01:47,  2.20it/s]\u001b[A\n",
      " 58%|█████▊    | 331/566 [02:28<01:46,  2.20it/s]\u001b[A\n",
      " 59%|█████▊    | 332/566 [02:29<01:46,  2.20it/s]\u001b[A\n",
      " 59%|█████▉    | 333/566 [02:29<01:46,  2.20it/s]\u001b[A\n",
      " 59%|█████▉    | 334/566 [02:30<01:45,  2.20it/s]\u001b[A\n",
      " 59%|█████▉    | 335/566 [02:30<01:45,  2.19it/s]\u001b[A\n",
      " 59%|█████▉    | 336/566 [02:31<01:45,  2.19it/s]\u001b[A\n",
      " 60%|█████▉    | 337/566 [02:31<01:44,  2.19it/s]\u001b[A\n",
      " 60%|█████▉    | 338/566 [02:32<01:44,  2.18it/s]\u001b[A\n",
      " 60%|█████▉    | 339/566 [02:32<01:44,  2.17it/s]\u001b[A\n",
      " 60%|██████    | 340/566 [02:33<01:43,  2.18it/s]\u001b[A\n",
      " 60%|██████    | 341/566 [02:33<01:43,  2.18it/s]\u001b[A\n",
      " 60%|██████    | 342/566 [02:34<01:42,  2.18it/s]\u001b[A\n",
      " 61%|██████    | 343/566 [02:34<01:42,  2.17it/s]\u001b[A\n",
      " 61%|██████    | 344/566 [02:34<01:42,  2.18it/s]\u001b[A\n",
      " 61%|██████    | 345/566 [02:35<01:41,  2.17it/s]\u001b[A\n",
      " 61%|██████    | 346/566 [02:35<01:41,  2.17it/s]\u001b[A\n",
      " 61%|██████▏   | 347/566 [02:36<01:40,  2.17it/s]\u001b[A\n",
      " 61%|██████▏   | 348/566 [02:36<01:40,  2.18it/s]\u001b[A\n",
      " 62%|██████▏   | 349/566 [02:37<01:39,  2.18it/s]\u001b[A\n",
      " 62%|██████▏   | 350/566 [02:37<01:38,  2.19it/s]\u001b[A\n",
      " 62%|██████▏   | 351/566 [02:38<01:38,  2.19it/s]\u001b[A\n",
      " 62%|██████▏   | 352/566 [02:38<01:37,  2.18it/s]\u001b[A\n",
      " 62%|██████▏   | 353/566 [02:39<01:37,  2.19it/s]\u001b[A\n",
      " 63%|██████▎   | 354/566 [02:39<01:37,  2.18it/s]\u001b[A\n",
      " 63%|██████▎   | 355/566 [02:39<01:36,  2.18it/s]\u001b[A\n",
      " 63%|██████▎   | 356/566 [02:40<01:35,  2.19it/s]\u001b[A\n",
      " 63%|██████▎   | 357/566 [02:40<01:35,  2.19it/s]\u001b[A\n",
      " 63%|██████▎   | 358/566 [02:41<01:34,  2.19it/s]\u001b[A\n",
      " 63%|██████▎   | 359/566 [02:41<01:34,  2.18it/s]\u001b[A\n",
      " 64%|██████▎   | 360/566 [02:42<01:34,  2.18it/s]\u001b[A\n",
      " 64%|██████▍   | 361/566 [02:42<01:34,  2.17it/s]\u001b[A\n",
      " 64%|██████▍   | 362/566 [02:43<01:33,  2.18it/s]\u001b[A\n",
      " 64%|██████▍   | 363/566 [02:43<01:33,  2.17it/s]\u001b[A\n",
      " 64%|██████▍   | 364/566 [02:44<01:32,  2.17it/s]\u001b[A\n",
      " 64%|██████▍   | 365/566 [02:44<01:32,  2.17it/s]\u001b[A\n",
      " 65%|██████▍   | 366/566 [02:45<01:32,  2.16it/s]\u001b[A\n",
      " 65%|██████▍   | 367/566 [02:45<01:32,  2.16it/s]\u001b[A\n",
      " 65%|██████▌   | 368/566 [02:45<01:32,  2.15it/s]\u001b[A\n",
      " 65%|██████▌   | 369/566 [02:46<01:31,  2.16it/s]\u001b[A\n",
      " 65%|██████▌   | 370/566 [02:46<01:31,  2.15it/s]\u001b[A\n",
      " 66%|██████▌   | 371/566 [02:47<01:30,  2.16it/s]\u001b[A\n",
      " 66%|██████▌   | 372/566 [02:47<01:29,  2.17it/s]\u001b[A\n",
      " 66%|██████▌   | 373/566 [02:48<01:29,  2.16it/s]\u001b[A\n",
      " 66%|██████▌   | 374/566 [02:48<01:28,  2.16it/s]\u001b[A\n",
      " 66%|██████▋   | 375/566 [02:49<01:28,  2.17it/s]\u001b[A\n",
      " 66%|██████▋   | 376/566 [02:49<01:27,  2.16it/s]\u001b[A\n",
      " 67%|██████▋   | 377/566 [02:50<01:27,  2.16it/s]\u001b[A\n",
      " 67%|██████▋   | 378/566 [02:50<01:26,  2.17it/s]\u001b[A\n",
      " 67%|██████▋   | 379/566 [02:51<01:26,  2.17it/s]\u001b[A\n",
      " 67%|██████▋   | 380/566 [02:51<01:25,  2.17it/s]\u001b[A\n",
      " 67%|██████▋   | 381/566 [02:51<01:25,  2.16it/s]\u001b[A\n",
      " 67%|██████▋   | 382/566 [02:52<01:25,  2.16it/s]\u001b[A\n",
      " 68%|██████▊   | 383/566 [02:52<01:25,  2.15it/s]\u001b[A\n",
      " 68%|██████▊   | 384/566 [02:53<01:24,  2.15it/s]\u001b[A\n",
      " 68%|██████▊   | 385/566 [02:53<01:23,  2.16it/s]\u001b[A\n",
      " 68%|██████▊   | 386/566 [02:54<01:23,  2.15it/s]\u001b[A\n",
      " 68%|██████▊   | 387/566 [02:54<01:23,  2.16it/s]\u001b[A\n",
      " 69%|██████▊   | 388/566 [02:55<01:22,  2.16it/s]\u001b[A\n",
      " 69%|██████▊   | 389/566 [02:55<01:21,  2.16it/s]\u001b[A\n",
      " 69%|██████▉   | 390/566 [02:56<01:21,  2.16it/s]\u001b[A\n",
      " 69%|██████▉   | 391/566 [02:56<01:21,  2.16it/s]\u001b[A\n",
      " 69%|██████▉   | 392/566 [02:57<01:20,  2.16it/s]\u001b[A\n",
      " 69%|██████▉   | 393/566 [02:57<01:20,  2.16it/s]\u001b[A\n",
      " 70%|██████▉   | 394/566 [02:58<01:19,  2.16it/s]\u001b[A\n",
      " 70%|██████▉   | 395/566 [02:58<01:19,  2.15it/s]\u001b[A\n",
      " 70%|██████▉   | 396/566 [02:58<01:19,  2.15it/s]\u001b[A\n",
      " 70%|███████   | 397/566 [02:59<01:18,  2.15it/s]\u001b[A\n",
      " 70%|███████   | 398/566 [02:59<01:17,  2.16it/s]\u001b[A\n",
      " 70%|███████   | 399/566 [03:00<01:17,  2.15it/s]\u001b[A\n",
      " 71%|███████   | 400/566 [03:00<01:16,  2.16it/s]\u001b[A\n",
      " 71%|███████   | 401/566 [03:01<01:16,  2.16it/s]\u001b[A\n",
      " 71%|███████   | 402/566 [03:01<01:15,  2.16it/s]\u001b[A\n",
      " 71%|███████   | 403/566 [03:02<01:15,  2.16it/s]\u001b[A\n",
      " 71%|███████▏  | 404/566 [03:02<01:14,  2.17it/s]\u001b[A\n",
      " 72%|███████▏  | 405/566 [03:03<01:14,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 406/566 [03:03<01:14,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 407/566 [03:04<01:13,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 408/566 [03:04<01:13,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 409/566 [03:04<01:12,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 410/566 [03:05<01:12,  2.16it/s]\u001b[A\n",
      " 73%|███████▎  | 411/566 [03:05<01:11,  2.17it/s]\u001b[A\n",
      " 73%|███████▎  | 412/566 [03:06<01:10,  2.17it/s]\u001b[A\n",
      " 73%|███████▎  | 413/566 [03:06<01:10,  2.16it/s]\u001b[A\n",
      " 73%|███████▎  | 414/566 [03:07<01:10,  2.16it/s]\u001b[A\n",
      " 73%|███████▎  | 415/566 [03:07<01:10,  2.16it/s]\u001b[A\n",
      " 73%|███████▎  | 416/566 [03:08<01:09,  2.15it/s]\u001b[A\n",
      " 74%|███████▎  | 417/566 [03:08<01:09,  2.15it/s]\u001b[A\n",
      " 74%|███████▍  | 418/566 [03:09<01:08,  2.15it/s]\u001b[A\n",
      " 74%|███████▍  | 419/566 [03:09<01:08,  2.16it/s]\u001b[A\n",
      " 74%|███████▍  | 420/566 [03:10<01:07,  2.15it/s]\u001b[A\n",
      " 74%|███████▍  | 421/566 [03:10<01:07,  2.16it/s]\u001b[A\n",
      " 75%|███████▍  | 422/566 [03:10<01:06,  2.16it/s]\u001b[A\n",
      " 75%|███████▍  | 423/566 [03:11<01:06,  2.16it/s]\u001b[A\n",
      " 75%|███████▍  | 424/566 [03:11<01:05,  2.16it/s]\u001b[A\n",
      " 75%|███████▌  | 425/566 [03:12<01:05,  2.16it/s]\u001b[A\n",
      " 75%|███████▌  | 426/566 [03:12<01:04,  2.16it/s]\u001b[A\n",
      " 75%|███████▌  | 427/566 [03:13<01:04,  2.16it/s]\u001b[A\n",
      " 76%|███████▌  | 428/566 [03:13<01:03,  2.16it/s]\u001b[A\n",
      " 76%|███████▌  | 429/566 [03:14<01:03,  2.15it/s]\u001b[A\n",
      " 76%|███████▌  | 430/566 [03:14<01:03,  2.15it/s]\u001b[A\n",
      " 76%|███████▌  | 431/566 [03:15<01:02,  2.15it/s]\u001b[A\n",
      " 76%|███████▋  | 432/566 [03:15<01:02,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 433/566 [03:16<01:01,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 434/566 [03:16<01:01,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 435/566 [03:17<01:01,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 436/566 [03:17<01:00,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 437/566 [03:17<01:00,  2.15it/s]\u001b[A\n",
      " 77%|███████▋  | 438/566 [03:18<00:59,  2.15it/s]\u001b[A\n",
      " 78%|███████▊  | 439/566 [03:18<00:59,  2.15it/s]\u001b[A\n",
      " 78%|███████▊  | 440/566 [03:19<00:58,  2.15it/s]\u001b[A\n",
      " 78%|███████▊  | 441/566 [03:19<00:58,  2.15it/s]\u001b[A\n",
      " 78%|███████▊  | 442/566 [03:20<00:57,  2.15it/s]\u001b[A\n",
      " 78%|███████▊  | 443/566 [03:20<00:57,  2.16it/s]\u001b[A\n",
      " 78%|███████▊  | 444/566 [03:21<00:56,  2.15it/s]\u001b[A\n",
      " 79%|███████▊  | 445/566 [03:21<00:55,  2.16it/s]\u001b[A\n",
      " 79%|███████▉  | 446/566 [03:22<00:55,  2.16it/s]\u001b[A\n",
      " 79%|███████▉  | 447/566 [03:22<00:54,  2.17it/s]\u001b[A\n",
      " 79%|███████▉  | 448/566 [03:23<00:54,  2.16it/s]\u001b[A\n",
      " 79%|███████▉  | 449/566 [03:23<00:54,  2.16it/s]\u001b[A\n",
      " 80%|███████▉  | 450/566 [03:23<00:53,  2.17it/s]\u001b[A\n",
      " 80%|███████▉  | 451/566 [03:24<00:53,  2.17it/s]\u001b[A\n",
      " 80%|███████▉  | 452/566 [03:24<00:52,  2.17it/s]\u001b[A\n",
      " 80%|████████  | 453/566 [03:25<00:52,  2.17it/s]\u001b[A\n",
      " 80%|████████  | 454/566 [03:25<00:51,  2.16it/s]\u001b[A\n",
      " 80%|████████  | 455/566 [03:26<00:51,  2.16it/s]\u001b[A\n",
      " 81%|████████  | 456/566 [03:26<00:50,  2.17it/s]\u001b[A\n",
      " 81%|████████  | 457/566 [03:27<00:50,  2.17it/s]\u001b[A\n",
      " 81%|████████  | 458/566 [03:27<00:49,  2.17it/s]\u001b[A\n",
      " 81%|████████  | 459/566 [03:28<00:49,  2.17it/s]\u001b[A\n",
      " 81%|████████▏ | 460/566 [03:28<00:49,  2.16it/s]\u001b[A\n",
      " 81%|████████▏ | 461/566 [03:29<00:48,  2.16it/s]\u001b[A\n",
      " 82%|████████▏ | 462/566 [03:29<00:48,  2.16it/s]\u001b[A\n",
      " 82%|████████▏ | 463/566 [03:29<00:47,  2.18it/s]\u001b[A\n",
      " 82%|████████▏ | 464/566 [03:30<00:46,  2.17it/s]\u001b[A\n",
      " 82%|████████▏ | 465/566 [03:30<00:46,  2.16it/s]\u001b[A\n",
      " 82%|████████▏ | 466/566 [03:31<00:46,  2.17it/s]\u001b[A\n",
      " 83%|████████▎ | 467/566 [03:31<00:45,  2.16it/s]\u001b[A\n",
      " 83%|████████▎ | 468/566 [03:32<00:45,  2.17it/s]\u001b[A\n",
      " 83%|████████▎ | 469/566 [03:32<00:44,  2.17it/s]\u001b[A\n",
      " 83%|████████▎ | 470/566 [03:33<00:44,  2.16it/s]\u001b[A\n",
      " 83%|████████▎ | 471/566 [03:33<00:43,  2.17it/s]\u001b[A\n",
      " 83%|████████▎ | 472/566 [03:34<00:43,  2.16it/s]\u001b[A\n",
      " 84%|████████▎ | 473/566 [03:34<00:43,  2.15it/s]\u001b[A\n",
      " 84%|████████▎ | 474/566 [03:35<00:43,  2.10it/s]\u001b[A\n",
      " 84%|████████▍ | 475/566 [03:35<00:43,  2.09it/s]\u001b[A\n",
      " 84%|████████▍ | 476/566 [03:36<00:43,  2.08it/s]\u001b[A\n",
      " 84%|████████▍ | 477/566 [03:36<00:42,  2.12it/s]\u001b[A\n",
      " 84%|████████▍ | 478/566 [03:36<00:41,  2.13it/s]\u001b[A\n",
      " 85%|████████▍ | 479/566 [03:37<00:40,  2.15it/s]\u001b[A\n",
      " 85%|████████▍ | 480/566 [03:37<00:40,  2.15it/s]\u001b[A\n",
      " 85%|████████▍ | 481/566 [03:38<00:39,  2.16it/s]\u001b[A\n",
      " 85%|████████▌ | 482/566 [03:38<00:38,  2.16it/s]\u001b[A\n",
      " 85%|████████▌ | 483/566 [03:39<00:38,  2.16it/s]\u001b[A\n",
      " 86%|████████▌ | 484/566 [03:39<00:37,  2.17it/s]\u001b[A\n",
      " 86%|████████▌ | 485/566 [03:40<00:37,  2.17it/s]\u001b[A\n",
      " 86%|████████▌ | 486/566 [03:40<00:36,  2.17it/s]\u001b[A\n",
      " 86%|████████▌ | 487/566 [03:41<00:36,  2.17it/s]\u001b[A\n",
      " 86%|████████▌ | 488/566 [03:41<00:35,  2.18it/s]\u001b[A\n",
      " 86%|████████▋ | 489/566 [03:42<00:35,  2.18it/s]\u001b[A\n",
      " 87%|████████▋ | 490/566 [03:42<00:34,  2.17it/s]\u001b[A\n",
      " 87%|████████▋ | 491/566 [03:42<00:34,  2.17it/s]\u001b[A\n",
      " 87%|████████▋ | 492/566 [03:43<00:34,  2.17it/s]\u001b[A\n",
      " 87%|████████▋ | 493/566 [03:43<00:33,  2.18it/s]\u001b[A\n",
      " 87%|████████▋ | 494/566 [03:44<00:33,  2.17it/s]\u001b[A\n",
      " 87%|████████▋ | 495/566 [03:44<00:32,  2.17it/s]\u001b[A\n",
      " 88%|████████▊ | 496/566 [03:45<00:32,  2.17it/s]\u001b[A\n",
      " 88%|████████▊ | 497/566 [03:45<00:31,  2.17it/s]\u001b[A\n",
      " 88%|████████▊ | 498/566 [03:46<00:31,  2.18it/s]\u001b[A\n",
      " 88%|████████▊ | 499/566 [03:46<00:30,  2.17it/s]\u001b[A\n",
      " 88%|████████▊ | 500/566 [03:47<00:30,  2.16it/s]\u001b[A\n",
      " 89%|████████▊ | 501/566 [03:47<00:30,  2.16it/s]\u001b[A\n",
      " 89%|████████▊ | 502/566 [03:48<00:29,  2.15it/s]\u001b[A\n",
      " 89%|████████▉ | 503/566 [03:48<00:29,  2.15it/s]\u001b[A\n",
      " 89%|████████▉ | 504/566 [03:48<00:28,  2.15it/s]\u001b[A\n",
      " 89%|████████▉ | 505/566 [03:49<00:28,  2.16it/s]\u001b[A\n",
      " 89%|████████▉ | 506/566 [03:49<00:27,  2.16it/s]\u001b[A\n",
      " 90%|████████▉ | 507/566 [03:50<00:27,  2.18it/s]\u001b[A\n",
      " 90%|████████▉ | 508/566 [03:50<00:26,  2.17it/s]\u001b[A\n",
      " 90%|████████▉ | 509/566 [03:51<00:26,  2.17it/s]\u001b[A\n",
      " 90%|█████████ | 510/566 [03:51<00:25,  2.18it/s]\u001b[A\n",
      " 90%|█████████ | 511/566 [03:52<00:25,  2.18it/s]\u001b[A\n",
      " 90%|█████████ | 512/566 [03:52<00:24,  2.18it/s]\u001b[A\n",
      " 91%|█████████ | 513/566 [03:53<00:24,  2.18it/s]\u001b[A\n",
      " 91%|█████████ | 514/566 [03:53<00:23,  2.18it/s]\u001b[A\n",
      " 91%|█████████ | 515/566 [03:54<00:23,  2.18it/s]\u001b[A\n",
      " 91%|█████████ | 516/566 [03:54<00:22,  2.19it/s]\u001b[A\n",
      " 91%|█████████▏| 517/566 [03:54<00:22,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 518/566 [03:55<00:22,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 519/566 [03:55<00:21,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 520/566 [03:56<00:21,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 521/566 [03:56<00:20,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 522/566 [03:57<00:20,  2.17it/s]\u001b[A\n",
      " 92%|█████████▏| 523/566 [03:57<00:19,  2.17it/s]\u001b[A\n",
      " 93%|█████████▎| 524/566 [03:58<00:19,  2.17it/s]\u001b[A\n",
      " 93%|█████████▎| 525/566 [03:58<00:18,  2.16it/s]\u001b[A\n",
      " 93%|█████████▎| 526/566 [03:59<00:18,  2.16it/s]\u001b[A\n",
      " 93%|█████████▎| 527/566 [03:59<00:17,  2.17it/s]\u001b[A\n",
      " 93%|█████████▎| 528/566 [04:00<00:17,  2.16it/s]\u001b[A\n",
      " 93%|█████████▎| 529/566 [04:00<00:17,  2.16it/s]\u001b[A\n",
      " 94%|█████████▎| 530/566 [04:00<00:16,  2.16it/s]\u001b[A\n",
      " 94%|█████████▍| 531/566 [04:01<00:16,  2.16it/s]\u001b[A\n",
      " 94%|█████████▍| 532/566 [04:01<00:15,  2.17it/s]\u001b[A\n",
      " 94%|█████████▍| 533/566 [04:02<00:15,  2.17it/s]\u001b[A\n",
      " 94%|█████████▍| 534/566 [04:02<00:14,  2.16it/s]\u001b[A\n",
      " 95%|█████████▍| 535/566 [04:03<00:14,  2.16it/s]\u001b[A\n",
      " 95%|█████████▍| 536/566 [04:03<00:13,  2.16it/s]\u001b[A\n",
      " 95%|█████████▍| 537/566 [04:04<00:13,  2.16it/s]\u001b[A\n",
      " 95%|█████████▌| 538/566 [04:04<00:12,  2.18it/s]\u001b[A\n",
      " 95%|█████████▌| 539/566 [04:05<00:12,  2.17it/s]\u001b[A\n",
      " 95%|█████████▌| 540/566 [04:05<00:12,  2.17it/s]\u001b[A\n",
      " 96%|█████████▌| 541/566 [04:06<00:11,  2.16it/s]\u001b[A\n",
      " 96%|█████████▌| 542/566 [04:06<00:11,  2.16it/s]\u001b[A\n",
      " 96%|█████████▌| 543/566 [04:06<00:10,  2.17it/s]\u001b[A\n",
      " 96%|█████████▌| 544/566 [04:07<00:10,  2.17it/s]\u001b[A\n",
      " 96%|█████████▋| 545/566 [04:07<00:09,  2.17it/s]\u001b[A\n",
      " 96%|█████████▋| 546/566 [04:08<00:09,  2.17it/s]\u001b[A\n",
      " 97%|█████████▋| 547/566 [04:08<00:08,  2.17it/s]\u001b[A\n",
      " 97%|█████████▋| 548/566 [04:09<00:08,  2.18it/s]\u001b[A\n",
      " 97%|█████████▋| 549/566 [04:09<00:07,  2.17it/s]\u001b[A\n",
      " 97%|█████████▋| 550/566 [04:10<00:07,  2.17it/s]\u001b[A\n",
      " 97%|█████████▋| 551/566 [04:10<00:06,  2.16it/s]\u001b[A\n",
      " 98%|█████████▊| 552/566 [04:11<00:06,  2.16it/s]\u001b[A\n",
      " 98%|█████████▊| 553/566 [04:11<00:06,  2.16it/s]\u001b[A\n",
      " 98%|█████████▊| 554/566 [04:12<00:05,  2.16it/s]\u001b[A\n",
      " 98%|█████████▊| 555/566 [04:12<00:05,  2.17it/s]\u001b[A\n",
      " 98%|█████████▊| 556/566 [04:12<00:04,  2.17it/s]\u001b[A\n",
      " 98%|█████████▊| 557/566 [04:13<00:04,  2.17it/s]\u001b[A\n",
      " 99%|█████████▊| 558/566 [04:13<00:03,  2.17it/s]\u001b[A\n",
      " 99%|█████████▉| 559/566 [04:14<00:03,  2.16it/s]\u001b[A\n",
      " 99%|█████████▉| 560/566 [04:14<00:02,  2.18it/s]\u001b[A\n",
      " 99%|█████████▉| 561/566 [04:15<00:02,  2.17it/s]\u001b[A\n",
      " 99%|█████████▉| 562/566 [04:15<00:01,  2.17it/s]\u001b[A\n",
      " 99%|█████████▉| 563/566 [04:16<00:01,  2.16it/s]\u001b[A\n",
      "100%|█████████▉| 564/566 [04:16<00:00,  2.17it/s]\u001b[A\n",
      "100%|█████████▉| 565/566 [04:17<00:00,  2.18it/s]\u001b[A\n",
      "100%|██████████| 566/566 [04:17<00:00,  2.20it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7544760812245073\n",
      "Validation F1: 0.7252518073413595\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:20<00:00,  2.17it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5691870914462809\n",
      "Validation F1: 0.7808433965376683\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:20<00:00,  2.18it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.44737648106979816\n",
      "Validation F1: 0.7831666113122704\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:20<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3328586884876285\n",
      "Validation F1: 0.7769109309668432\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:19<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24033034006100767\n",
      "Validation F1: 0.7782751395139056\n",
      "Early stopping triggered!\n",
      "\n",
      "✅ Final Validation: {'accuracy': 0.7810945273631841, 'precision': 0.7861305053160718, 'recall': 0.7810945273631841, 'f1': 0.7831666113122704}\n",
      "✅ Final Test: {'accuracy': 0.7726910828025477, 'precision': 0.7799084005874735, 'recall': 0.7726910828025477, 'f1': 0.77597675851106}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "# 📥 Download NLTK Stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ⚙️ Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\", quotechar='\"', engine=\"python\", on_bad_lines='skip')\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# 🧪 Train/Val/Test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Convert to Hugging Face Datasets\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "\n",
    "# 🧠 Tokenization\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 🔢 Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "# 📊 Class Weights (to handle imbalance)\n",
    "class_counts = train_df[\"label\"].value_counts().sort_index().values\n",
    "class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# 🧱 Model\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\", num_labels=3\n",
    ").to(device)\n",
    "\n",
    "# 🎯 Optimizer & Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 10  # for 10 epochs\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# 🛑 Early stopping setup\n",
    "best_val_f1 = 0\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "# 🚂 Training loop\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    print(\"Train loss:\", total_loss / len(train_loader))\n",
    "\n",
    "    # 📈 Validation\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            b = {k: v.to(device) for k, v in b.items()}\n",
    "            out = model(**b)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += b[\"labels\"].cpu().tolist()\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    print(\"Validation F1:\", f)\n",
    "\n",
    "    # Early stopping\n",
    "    if f > best_val_f1:\n",
    "        best_val_f1 = f\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# 📊 Evaluation\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = {k: v.to(device) for k, v in b.items()}\n",
    "            o = model(**b)\n",
    "            pred = torch.argmax(o.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += b[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "print(\"\\n✅ Final Validation:\", evaluate(val_loader))\n",
    "print(\"✅ Final Test:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "dTIJEVz-0k-8",
    "outputId": "b1d5f479-22ca-4d0b-b735-b08c890c3b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ImportError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a471d7f5bab7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDebertaV2Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDebertaV2ForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Install required packages\n",
    "!pip install -q transformers datasets nltk scikit-learn nlpaug\n",
    "\n",
    "# 📚 Imports\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, AdamW, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import nlpaug.augmenter.word as naw\n",
    "import torch.nn as nn\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ⚙️ Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")  # Upload this file to Colab\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# 🔁 Data augmentation (30% of dataset)\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented = df.sample(frac=0.3, random_state=42).copy()\n",
    "augmented[\"cleaned\"] = augmented[\"cleaned\"].apply(lambda x: aug.augment(x))\n",
    "df = pd.concat([df, augmented], ignore_index=True)\n",
    "\n",
    "# ✂️ Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Tokenization\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 🔥 Focal Loss Definition\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = torch.nn.functional.cross_entropy(input, target, weight=self.weight, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# 🧠 Model Setup\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=3).to(device)\n",
    "class_counts = train_df[\"label\"].value_counts().sort_index().values\n",
    "class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float).to(device)\n",
    "loss_fn = FocalLoss(weight=class_weights)\n",
    "\n",
    "# 🔁 Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "test_loader = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "# 🎯 Optimizer & Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*10)\n",
    "\n",
    "# 🛑 Early Stopping and Training Loop\n",
    "best_val_f1, patience, counter = 0, 3, 0\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # 🔍 Validation\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            pred = torch.argmax(outputs.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    print(\"Validation F1:\", f)\n",
    "    if f > best_val_f1:\n",
    "        best_val_f1 = f\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# ✅ Evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "def evaluate(loader):\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            pred = torch.argmax(outputs.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"✅ Final Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5663b32a7e9e4e178c114697d975b1de",
      "db8b880aaaf841b2bb5583d69346d2c7",
      "1c60b18a1c4947bd92089cbe60d83c80",
      "4702c4b002e347969732de24f597c02b",
      "afc66af8d66a4a139d40a63b6400f447",
      "74f68cfb1bbf433e890e75533a920805",
      "6007e735f3954c6dbe7c5530fa89596f",
      "ae8e3d186a994924bbefced5d8cd4809",
      "73e6b0ef509d4093a997226c02d5d5b5",
      "cb4d70c0bdd4495b85f7ef528bc96717",
      "3d5f1a391ec34bbbbc09b2fc5f7146a8",
      "e027c1d156ae436fb8c6882b799a1fc2",
      "4d1d8a8b711c423a8652cbe5b06d4c32",
      "e8190f584b3548b3873f570f77d0bc6f",
      "b4f6a7ba8a2644698c68b3648ecfa0de",
      "1d8522f83e54468e8f465a1f054f7f13",
      "e6133fccbbde42b6bc394c0735356169",
      "5ea60f341b8e4292a6a0e056c7bc990d",
      "92ca199d12514a2d8e365dafc78ea0b7",
      "1d5a488b276944078fb86f4ab01fa4ef",
      "4f029247298a415f8af892d1c5e1a493",
      "f9d65ec7a78d45a18ee6828122c061df",
      "d3e7a5851f1745248e3d8366bf391ed3",
      "72a96303dd1543f6ab80c08e309939db",
      "3549d2ef0b604b68b298381054346fc8",
      "02dcd5ff1f754447aa7a77a273ca02f7",
      "4d6ed71334934bc992e0bd1a5fe950f6",
      "76e155e63124470a96bedda77bb9f765",
      "09c373bf97c349edb5f097bfccdc0418",
      "27200f45d0b247b0bcac6503938e54dc",
      "7195d1a4fdc744cf87cc9b0d640770a3",
      "86f4de22cc154885a2bd2edddb41bc76",
      "cc2759199e254965951fcecdb38969a5",
      "5f347759f3d44dffacda1155e93b7a71",
      "4147efcc494e458897fe9a6882e41ade",
      "5e388b5363b24b34892bd92fba963e14",
      "a9d9608484c146808af4be4d095aa132",
      "420028e9884b46ae9b7238388665edeb",
      "e46e0554ba9e4f9487511e031036ab86",
      "65ee85305bcf4e3a8d4095046657b732",
      "2d2900d7797e491c972e413a76cdcbc9",
      "5861daca310948f28aa9905eadc26694",
      "806b4dccbe8a4b57a931a680518593ec",
      "b1b9d4fd0fda45e483ef97ed3ef49216",
      "f634bceb81b84cfdbbd0e63d95de9466",
      "b82ea689092b489f92a2835af30ab237",
      "0b20f5bb1500450cb52f7720c79e09e4",
      "148c153b38e94060b64fc3960a635578",
      "9011661a8b7849d69f1d4371ffa63910",
      "d4d1ebb3a8aa4ec0ba34534f60ee7dc2",
      "34df1b30a1b54ad499383983fe68adf8",
      "f1b45983aeb2422c9c71399403e9d827",
      "48bce99e637a4b0d92b8856cf072e548",
      "bafa7064afb44a11bf1914b8f424d6f9",
      "afc263a87a3e427caf2fa921d823236a",
      "0924224d0bce480fab447b751e903051",
      "5fbf041c19234d8ba09deeca88d15490",
      "c294448cb0f044599e57789c2fd121d0",
      "9002407ca9d44346b63909d0c9a06324",
      "5c045da788c2480b85bc4a81b26f2919",
      "2d1d929974684057ba3a2696b052b942",
      "6b0f43ad1af346f4ad69415edcf80800",
      "f117ae9201e34f528a4a73d505ea3562",
      "e4c778bc536c48b8bad5ac4fc024a11d",
      "7a73746e522e4e16b1c9118b709ca0c3",
      "76ee4f58f1d74fbb8464bb5af9aef51a",
      "f9704d60250d4401b3d1ee642bb775a8",
      "1ae3a0eae7f84ad1b59cbcad6aec9557",
      "7973fdcfbe0c4e0982c8a6007ef26047",
      "7b0488e1e94d41f7b7b7c10d7ec77d0b",
      "5b4bfb9a321943de97f4d62b9f55d623",
      "649c6f720d48409a99f8b1c4ead0b1c8",
      "2ed2e4f2f6194684badbb3544c173cff",
      "d0ae9a2e38e649b5a80ad3aecb026d42",
      "a9995161d099452db4b77a8162867455",
      "b942153425284ce69f7d8575c8c08be1",
      "3aeab325f5ad494c99a9e6304b95c381",
      "09bce3731b10443bb3fead441da8494d",
      "c53ccc9b7a4b421baadc63000a281e89",
      "7f6ab07be26140ca9dd14c877c0edd01",
      "c159b5ce57b24d4c8bd50addf7b6ef97",
      "b7382d7f835b4d2695700d40c0781bdd",
      "a4522d0e11864427ae05e37e7df6d39a",
      "56df4278e3f443d6b2368088350d6de8",
      "3a68ee8ebdd045e9a824478f1e39ae6b",
      "4d47033c7189471eb6cae5b3688dcdf8",
      "571690b30b1e43b4a09346bc3325f127",
      "bc035b1837cd4c61ad42a7e0014fd42f"
     ]
    },
    "id": "psytHPIxU3zf",
    "outputId": "42f8c78e-08e3-4f71-db31-ea062d1a4f3e"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5663b32a7e9e4e178c114697d975b1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e027c1d156ae436fb8c6882b799a1fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e7a5851f1745248e3d8366bf391ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f347759f3d44dffacda1155e93b7a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f634bceb81b84cfdbbd0e63d95de9466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0924224d0bce480fab447b751e903051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9704d60250d4401b3d1ee642bb775a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/566 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bce3731b10443bb3fead441da8494d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:30<00:00,  2.09it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.3240\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:27<00:00,  2.11it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.3240\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:27<00:00,  2.12it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.3240\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [04:28<00:00,  2.11it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.3240\n",
      "Early stopping triggered.\n",
      "✅ Final Test Results: {'accuracy': 0.4912420382165605, 'precision': 0.24131874011116067, 'recall': 0.4912420382165605, 'f1': 0.3236479846018343}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Install required packages\n",
    "!pip install -q transformers datasets nltk scikit-learn\n",
    "\n",
    "# 📚 Imports\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "# 📥 Download NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# ⚙️ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load and clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# ✂️ Train/Val/Test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Tokenization\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 🔥 Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = nn.functional.cross_entropy(input, target, weight=self.weight, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        return ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# 🧠 Model and optimizer\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=3).to(device)\n",
    "class_counts = train_df[\"label\"].value_counts().sort_index().values\n",
    "class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float).to(device)\n",
    "loss_fn = FocalLoss(weight=class_weights)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 10)\n",
    "\n",
    "# 🛠 Training Loop\n",
    "best_val_f1, patience, counter = 0, 3, 0\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        loss = loss_fn(out.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # 📈 Validation\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**batch)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    print(f\"Validation F1: {f:.4f}\")\n",
    "    if f > best_val_f1:\n",
    "        best_val_f1 = f\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# ✅ Evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**batch)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"✅ Final Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac0l6pZJ_bTs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950,
     "referenced_widgets": [
      "c529694460174e75bc58498260a7afcc",
      "ce036c766547441e828116be8a3ec095",
      "8fea879abf3e432f9070057fd6e779cd",
      "2d7820ba94b94cd78ef6328025c8a694",
      "c233da3fd6d24dfe997ca8c2c6e6d658",
      "cd1087f1550d4967bb7e68167716a3d5",
      "22e59da12e5a4e9b82ea3b5b86ff3b86",
      "19b1e995e891435ab3cc5946dfa6b672",
      "f1c6413eca0845dfb4b0b85a0bf308ee",
      "d5b25d4a92ac4bdfac6e6ba36de34072",
      "d5d04ceda14b486a89745b86c6c8ccdc",
      "517d542b92ee414181eb7cc36880ca01",
      "bd0b527988d64341901ec876cbca7a99",
      "f5b11d73baa94864acdb94481c1e7958",
      "df7bf227cc6c41adb81b0f450eb6355f",
      "cd4234b65ab84f2da4b139c7eb0dcea4",
      "cf82259af5fe43e0a2e24691a28b30f3",
      "4ac4293d3f564ec7a72648d10990dab6",
      "a67bb429f318457ba244e702dfd242fc",
      "56660eae48434c618df6838aaca52799",
      "fcb0dd42dd23472881088cde3734ebca",
      "c7dd05fea2b24f9e8aa22f09b8ef43e4",
      "d7ef48feb1f04080adcceb1e053c2153",
      "292faa9b91a94100875ad65dee75f7f9",
      "f8904d0731d4403a8d6e17e6b0a68ff6",
      "a3b2c4b3d5174e4eb1ccc1b8bd767723",
      "a6f14d0b95664b16ad8b4f317a0a1444",
      "edbd85109bfa46f1bb430b9842c653aa",
      "7e46c0555fed490f876e2bc2861e6b7e",
      "aca881005e6145dda1bb541d6d1ae769",
      "11cdb5741a9044329cd48e7e3b641e85",
      "fd9c767a07d24b5da7d91d7e44b7101b",
      "d08bd3e552974d38a12defa6c6875b3c",
      "7fcaee03746b4940b66658c3ee0efd47",
      "7ab8d8d64ca34c06a8c9ee1cf118f666",
      "515363df9afd48c4973614829a23ee5a",
      "f636e742ecd24c75aab19ab17a0e592b",
      "393d3418bd6f4d27b8b5ffafddd85022",
      "7c81f5ae18124a5fb08f20d4f84878b8",
      "0b2235b354df47f8bb1a2d02ee48f957",
      "6df9f0a88bb7493a975fd55163d07207",
      "0e855540e22e42569d5d966af732275c",
      "4ef7b45a7f694726bbdc248c303a315e",
      "0ea460c7739c4a94950f3d10827e9412",
      "2b87a7e1b6c941b18939d99abf6cd741",
      "79bb46c18ca4447cab3d45dbb404a88c",
      "d4d502d10bf54fe394082e321146e4b3",
      "338163ab53144e2eb63971d16468aff9",
      "7b7dd44a32404818b2ea0caad7fdaace",
      "b1a719b97b884317ac3e872a2d4d10b7",
      "88fcd4b3fb5749f5876a8187f55df2c7",
      "13a0383a366340728e59cec5337c81c7",
      "c1f35415c4f641e1b158c36697aca397",
      "7bf3bfb2f2cc4ef68075ab268ca20759",
      "dcea9973125247c8b10f6fe9f1f00dab",
      "7ef3671ee3fb40dd98791da0ea856fe9",
      "8a0dc1bce2e7447d91f30970b2f7eda2",
      "5314d6a8075c46dab5ed868a5ebdfd4d",
      "5799ed6e5da44635a8af15668af333c4",
      "2dd72ab647144f5cbabd8f1973d33396",
      "f8125f7eac6e42a1b31a3cbd7a4ae3df",
      "6672f843b5aa45f3ad89c5651c621716",
      "768ee3f1b68c44d0a517c12f152dfcc0",
      "bcf044eb7fee460a8e3ba879a37b5e69",
      "afab170f98fc4944b9b576a82d1133ae",
      "6f7e6fc0da48492c9f75a18b126a16d0",
      "b392076fb4a44966ae511c058e97c01b",
      "9210da81074247e08b290c0ee96c033d",
      "ebf2bb7ee4ab4ca3a3b748f17cbcf2d0",
      "ce3ece50733349f5aa04493279f98550",
      "97957a644f424de38ecbed24c3d191c1",
      "166457a106d24809bb8317f2ece4e110",
      "480c816765f9438d8a4f94c577cc9cff",
      "de208d73c444477fa17153e775bdd179",
      "42bd6936d7f64e1f9a3d1489b389fd9c",
      "970f01107b3e46649884590cf1f65883",
      "e2f2af0be7d244bb959bf8d15d0a61ac",
      "226b925f948f42adb1c53d0ca7a41683",
      "c0ca131eef0440d38c2ddd6a79476739",
      "be46b38a9a2040f2b6fa826fd6a10fb6",
      "cc31eecc8ac740779f36808b4f5573c6",
      "2bdcdea7f718480bb69c984bbc3bf840",
      "8a56aa58aad549cf8c1a2cdbd5ffd259",
      "a18139703d814b99a1cdf882bbe06c4e",
      "80f66e9e2d6946b6b53b9d58588531cc",
      "9a559bea58a54f19b51d1e7bb7470380",
      "749b9171d9f94b9faf9eeb9f202f7c57",
      "c40ca5bd2ddb4fb1ad666be57c115335",
      "1651acec4a62478db7e7662ddf1ef636",
      "bde489057a3949879eb16a5c84390fb1",
      "9f29dbc03e45419eaa3f87237765bd59",
      "e6ef3f43800e45cf92cd477d5cb7c12c",
      "6fe289eb6539446888c11f3a96eba273",
      "e034fd51e1da488d868505778a2aa5c0",
      "a532d50dfd42407ea33ef72a887e9f77",
      "674b0d84a1174b16b938c29d3efd8003",
      "7e6ef7ad7a004c7f8108be00cdb5258d",
      "a4eb2a416ee74cd1ae898759a43385d9",
      "fed43c0b112a4d0d8bc13c9b06a62d43"
     ]
    },
    "id": "GWB7gnFM_bcy",
    "outputId": "02091897-0e1f-424e-b74d-cbef3f266b43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c529694460174e75bc58498260a7afcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517d542b92ee414181eb7cc36880ca01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ef48feb1f04080adcceb1e053c2153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcaee03746b4940b66658c3ee0efd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b87a7e1b6c941b18939d99abf6cd741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef3671ee3fb40dd98791da0ea856fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b392076fb4a44966ae511c058e97c01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226b925f948f42adb1c53d0ca7a41683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1651acec4a62478db7e7662ddf1ef636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:27<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.6952\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7498\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7578\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7613\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7563\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7557\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7558\n",
      "Early stopping triggered.\n",
      "✅ Final Test Results: {'accuracy': 0.759952229299363, 'precision': 0.7772359241083165, 'recall': 0.759952229299363, 'f1': 0.7665571794395611}\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Install required libraries\n",
    "# !pip install -q transformers datasets nltk scikit-learn\n",
    "\n",
    "# 📚 Imports\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "# 📥 Download NLTK stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# ⚙️ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load and lightly clean dataset\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# ✂️ Train/Val/Test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Tokenization with RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# 🧠 Model and optimizer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 10)\n",
    "\n",
    "# 🛠 Training Loop w/ Early Stopping\n",
    "best_val_f1, patience, counter = 0, 3, 0\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        loss = loss_fn(out.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # 📈 Validation\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**batch)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    print(f\"Validation F1: {f:.4f}\")\n",
    "    if f > best_val_f1:\n",
    "        best_val_f1 = f\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_roberta_model.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# ✅ Final Test Evaluation\n",
    "model.load_state_dict(torch.load(\"best_roberta_model.pt\"))\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**batch)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"✅ Final Test Results:\", evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D41MAQEGIqv9"
   },
   "source": [
    "wesome! Let's use a domain-specific model for sentiment analysis:\n",
    "\n",
    "cardiffnlp/twitter-roberta-base-sentiment\n",
    "It’s fine-tuned on millions of tweets, making it great for short reviews, informal language, and polarized opinions — just like your Apple vs. Samsung dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484,
     "referenced_widgets": [
      "5fd76c8f18a947b4a28dc205918737d0",
      "e8f007434e4e44fa932738e98f8ae859",
      "ba4675ede210444db45177eaa0db6a40",
      "741a20a2062a4169ac3d2f89a57e20fe",
      "7212ab86f02e4f048987eedb2461a4b1",
      "a2ac59c6e50f44f4bb4928c956071448",
      "b1b9d439b02142079169dc2e580fffbc",
      "0b4ce6f84a7047268f71d6370e2a37f1",
      "8ffe190adfa241c8ba95e18da9cf9429",
      "9126e6d83602499e83249b767af256cd",
      "87b98c23abd64805be1bee8144510ced",
      "1537195438324e0687b1a82e71d2e247",
      "b0dabdb6598d44758a119811233c1861",
      "3832c125874a43bb97c2d57e0aa5aa8e",
      "276b03fe0b8241a9983a4277c191bf67",
      "03f49d57ca7748d99048333c658f0ad0",
      "896c49016e12420a87e589f455b34992",
      "a2db6c26f3fd4378befeebe4fa07ae2d",
      "673bc1c09d2c4094be892c98dc32ddfd",
      "bc81ec61077b42de8d900edb1cd3467b",
      "03944ae8a74848dbb21a0be5a2ebd460",
      "9d08647de74d4ac7b4548ce1df69db65",
      "ea6e66e84fb148dea2351f8904920e20",
      "7230c11d3aee4198b90bf58cea02c540",
      "8e087fb6eccb4544b7ffdaad3f77de8e",
      "2bba187ead8249269b02ff616340d7e3",
      "e732a80a15ee44e4ae40026dd9575707",
      "a4b67ed9e45a42aba8691705331f0ee3",
      "4f58f41837b24af68141ff60a3e6a5b5",
      "830b50a80aa14815b6a333bab354a107",
      "16314956518f4b52b91f5cbaf6686041",
      "eea6171c901547128ab98269ca1710ad",
      "807b424f7fd045bfbf561bdc70dd71e6",
      "0b6ded6c88ef4df28456a005cfc615a3",
      "f945a7ed638043b887894d06247535ef",
      "06e36fd088ab4751a22ada78882e453a",
      "890f4db0fb4e4b9685e488437da20999",
      "661fddd867f145c8aa9b7a645e05f5c1",
      "1fa634ab9d204331af6a8e2b6bbd4b27",
      "71d9bbeddf2b410cbe8915b59f881778",
      "07cd40596e5f48be88059b7052b65cba",
      "3e0d6f6e12d341f18a53e77cec0fa04c",
      "5537b474268048918e9b2563172d7a7d",
      "82fec408ca9f49d389546b053c158811",
      "2d8c91b11f3a4d878a7d55910dbb3480",
      "b4e2b15f4b0143ef9dbfc494ccde9635",
      "2a0b251bc800445abbec06f5d1fe1db3",
      "b0d034c381d74d8287f387d2f140dff1",
      "ee24237c0e324dc8aed9eaf1b246393b",
      "a51acfc2e69b4a76a0748743a6b58341",
      "3a740e3d3dbc4ddfb116bffeeea0d091",
      "6d92db2ab9c3478d93cef91cdd5ab5f8",
      "3958198ee7d14d4f915c526b376dffbe",
      "8cae8b1caba54f7da4de464d436a091e",
      "5e04312ae1fd46af9f07e3d948e76552",
      "ccf483e2aff94c42b8028dc797e25e1c",
      "ffff2ee1642a4433b566c250c1608d36",
      "053168525c334eafb93930b0f8a887a0",
      "04910160b45a4d879a34c1748f422fa5",
      "b791e1093bd647af98e4c1c416aaea02",
      "b38140475ed94c5694e6e5cbf9eb8c8b",
      "cd44a63cfd12485aa75deafeb6241553",
      "a16e72bb5d6543ff8ec7be3ca3fde72d",
      "a8dfb425c4a5487c90b3026f34c307c9",
      "d13d835cdf204eb39dbb510f0a0b56f4",
      "d6295b5590a54d36a81d9fe41e65eadc",
      "b693e5e6467148f4847622df03b6e992",
      "22cacc4eb4bf46e0a7d0621c17a0d585",
      "41ee63fedd3f4b8e8d27446803a98a8b",
      "213b7a102dfd487ca7ef2747ba2a6f69",
      "22a8ad9e87584d13a8bce3ea236e9640",
      "9f50c9f6f92148d7b59737cefdc8d43b",
      "a3c5c40e7e9843aa93bc8a74b688b506",
      "b9ba94cc2c45495b9821d6fbc2de3cc6",
      "6f29dcab3a9946fd9781e3f6da7cd4f4",
      "93cb788b8cbe41b295dc9174eb64ba77",
      "7b3672292731487ba6998370f3ac44e7",
      "065bf1e81085462fb1d131cb30e9a965",
      "f6f15debec54439cb61e2e92948a7fd4",
      "7d6f3b7a02444d9ab53760d3041f813f",
      "886f5cab82cd4730b31798917f8c134c",
      "61b0fcf664ba415eae0f7ff28278a636",
      "7daffb77a70647c7ade32269eea013aa",
      "24e8cde4fbff460c857b16382feda2c1",
      "d55db3441263474c952be28529e3a700",
      "ad9cd4eae3ac4964b6f1af60c4de2b3f",
      "d83a5c6589094028a47d02c06de43909",
      "91b3824fa0c643ce900ab6c079b5984e",
      "acfcdb1aed9a4bbf8f94c64d527f0c89",
      "9e3c0c8139ac444eb445e3676b0456ea",
      "d2c908b055984a39955351d6c203afcf",
      "95403714a42e48d4a395e57372a1ba18",
      "e21c4531342041fd8c4ab7bfefb1bd6a",
      "54e30fe9323f438ea557b0acc5a3717b",
      "99e62b18509048629fbe23fbe4148a52",
      "60deca5ce32749629a18269be0adaa0b",
      "7c894ad9df564b179a051c6fcb0c14f1",
      "19b520f0aecb4ee0ad123dc9125af163",
      "0fe7393736694f858dcdb18d3555b38b"
     ]
    },
    "id": "KHfTeajKIsjQ",
    "outputId": "58c6ef63-1191-46c2-ed09-e4ba388c2fef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd76c8f18a947b4a28dc205918737d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1537195438324e0687b1a82e71d2e247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6e66e84fb148dea2351f8904920e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6ded6c88ef4df28456a005cfc615a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8c91b11f3a4d878a7d55910dbb3480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf483e2aff94c42b8028dc797e25e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b693e5e6467148f4847622df03b6e992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065bf1e81085462fb1d131cb30e9a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfcdb1aed9a4bbf8f94c64d527f0c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 566/566 [03:26<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7312\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 560/566 [03:23<00:02,  2.77it/s]"
     ]
    }
   ],
   "source": [
    "# 🚀 Install dependencies\n",
    "# !pip install -q transformers datasets nltk scikit-learn\n",
    "\n",
    "# 📚 Imports\n",
    "import pandas as pd, re, nltk, torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "# 📥 NLTK for stopword removal (optional)\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "# ⚙️ Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 📂 Load & clean data\n",
    "df = pd.read_csv(\"/content/apple_samsung_yelp_sentiment.csv\")\n",
    "df = df.rename(columns={\"review_text\": \"text\", \"sentiment\": \"label\"})\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return \" \".join([w for w in text.split() if w not in stop_words])\n",
    "df[\"cleaned\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"label\"] = df[\"label\"].map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "# 🧪 Train / Val / Test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "# 🤗 Load tokenizer and model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3).to(device)\n",
    "\n",
    "# Tokenize\n",
    "def tokenize_fn(ex): return tokenizer(ex[\"cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "def to_dataset(d): return Dataset.from_pandas(d[[\"cleaned\", \"label\"]], preserve_index=False)\n",
    "\n",
    "train_ds, val_ds, test_ds = map(to_dataset, [train_df, val_df, test_df])\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True).rename_column(\"label\", \"labels\").remove_columns([\"cleaned\"]).with_format(\"torch\")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 🔁 Train\n",
    "best_val_f1, patience, counter = 0, 3, 0\n",
    "for epoch in range(5):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        loss = loss_fn(out.logits, batch[\"labels\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # 🔍 Validate\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            b = {k: v.to(device) for k, v in b.items()}\n",
    "            out = model(**b)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += b[\"labels\"].cpu().tolist()\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    print(f\"Validation F1: {f:.4f}\")\n",
    "    if f > best_val_f1:\n",
    "        best_val_f1 = f\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_cardiff_model.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# 📊 Evaluate on test set\n",
    "model.load_state_dict(torch.load(\"best_cardiff_model.pt\"))\n",
    "model.eval()\n",
    "def evaluate(loader):\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = {k: v.to(device) for k, v in b.items()}\n",
    "            out = model(**b)\n",
    "            pred = torch.argmax(out.logits, dim=-1)\n",
    "            preds += pred.cpu().tolist()\n",
    "            labels += b[\"labels\"].cpu().tolist()\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "print(\"\\n✅ Final Test Results:\", evaluate(test_loader))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
